Rada nadzorcza krytykuje politykę
właściciela Meta dotyczące zmanipulowanych
mediów jako „niespójne” i niewystarczające do
dezinformacji online, która
już zaczęła atakować wybory na całym
na całym świecie.
Quasi-niezależna rada nadzorcza stwierdziła w tym tygodniu, że jej
przegląd zmienionego wideo prezydenta Joe Bidena
które rozprzestrzeniło się na Facebooku, ujawniło luki w
polityce. Rada stwierdziła, że Meta powinna rozszerzyć
skupić się nie tylko na filmach generowanych
za pomocą sztucznej inteligencji, ale także na mediach
niezależnie od tego, jak zostały stworzone. Obejmuje to
fałszywe nagrania audio, które już
przekonująco podszywały się pod kandydatów politycznych
w Stanach Zjednoczonych i innych krajach.
Firma powinna również wyjaśnić, jakim szkodom ił
stara się zapobiegać i powinna oznaczać obrazy,
wideo i klipy audio jako zmanipulowane zamiast
jako zmanipulowane, zamiast całkowicie je usuwać, stwierdziła Meta
Oversight Board.
Opinie rady odzwierciedlają intensywną
kontrolę, przed którą stoi wiele firm technologicznych
za ich postępowanie z fałszerstwami wyborczymi w
roku, kiedy wyborcy w ponad 50 krajach
pójdą do urn. Ponieważ zarówno generatywna sztuczna inteligencja
sztucznej inteligencji, jak i niższej jakości „tanie
podróbki” w mediach społecznościowych grożą wprowadzeniem w błąd
wyborców, platformy starają się nadrobić zaległości i
reagować na fałszywe posty, jednocześnie chroniąc
prawa do wolności słowa.
„W obecnej formie polityka ta nie ma większego sensu.
Współprzewodniczący Rady Nadzoru Michael McConnell
powiedział o polityce Meta w oświadczeniu. Powiedział
że firma powinna uzupełnić luki w
w polityce, zapewniając jednocześnie, że mowa polityczna jest
„niezachwianie chronione”.
Meta powiedziała, że ił analizuje wytyczne Rady ds.
i odpowie publicznie na zalecenia
zalecenia w ciągu 60 dni.
Rzecznik Corey Chambliss powiedział, że podczas gdy audio
deepfakes nie są wspomniane w polityce firmy/s
zmanipulowana polityka medialna, kwalifikują się one do
być sprawdzane pod kątem faktów i będą oznaczane lub obniżane
jeśli weryfikatorzy faktów ocenią je jako fałszywe lub
zmienione. Firma podejmuje również działania przeciwko
również działania przeciwko wszelkim rodzajom treści, jeśli naruszają one standardy społeczności Facebooka.
Standardy społeczności, powiedział.
Facebook, który w tym tygodniu spadł o 20 pkt,
pozostaje najpopularniejszym serwisem społecznościowym
dla Amerykanów, aby uzyskać wiadomości, zgodnie z
Pew. Jednak inne serwisy społecznościowe, w tym
Metas Instagram, WhatsApp i Threads, jak również
a także X, YouTube i TikTok, również są potencjalnymi
w których zwodnicze media mogą się rozprzestrzeniać i
oszukać wyborców.
Meta utworzyła radę nadzorczą iłs w 2020 roku, aby
służyć jako sędzia dla treści na platformach iłs.
Obecne zalecenia zostały wydane po tym, jak ił
przejrzeniu zmienionego zdjęcia prezydenta Bidena i jego dorosłej wnuczki, które
jego dorosłej wnuczki, które wprowadzało w błąd
ale nie przedstawiało konkretnych polityk firmy.
Materiał filmowy pokazywał, jak Biden umieszcza naklejkę „Głosowałem” na swoim wnuczku.
Voted” na klatce piersiowej swojej wnuczki,
na polecenie, a następnie całuje ją w policzek.
To, co się pojawiło, zostało
zmieniony, aby usunąć ważny tekst, dzięki czemu
wyglądało na to, że dotknął jej niewłaściwie.
Orzeczenie zarządu w poniedziałek podtrzymało decyzję Mety
2023 decyzję o pozostawieniu siedmiosekundowego zanurzenia
w górę na Facebooku, ponieważ ił nie naruszył
istniejącej polityki firmy dotyczącej zmanipulowanych mediów.
Obecna polityka firmy Meta mówi, że ił usunie filmy
stworzone przy użyciu narzędzi sztucznej inteligencji, które
fałszywie przedstawiają czyjąś wypowiedź.
„Ponieważ wideo w tym poście nie zostało zmienione
przy użyciu Al i ił pokazuje prezydenta Bidena robiącego
coś, czego nie zrobił (a nie coś, czego
nie powiedział), ił nie narusza istniejącej polityki”:
czytamy w orzeczeniu
Zarząd poradził firmie, aby zaktualizowała
i oznaczyć podobne filmy jako zmanipulowane
w przyszłości. Ił argumentował, że aby chronić prawa
użytkowników do wolności słowa, Meta powinna
oznaczać jako zmanipulowane, zamiast
usunąć ił z platformy, jeśli ił nie
narusza żadnych innych zasad.
Rada zauważyła również, że niektóre formy
manipulacji są tworzone dla humoru, parodii
lub satyry i powinny być chronione. Zamiast
skupiać się na tym, w jaki sposób zniekształcony obraz, wideo
audio, polityka firmy powinna skupiać się na szkodliwości zmanipulowanych postów.
powinna skupiać się na szkodach, jakie zmanipulowane posty
może spowodować, takie jak zakłócenie procesu wyborczego.
proces wyborczy.
Meta oświadczyła na swojej stronie internetowej, że z zadowoleniem przyjmuje orzeczenie Rady ds.
Oversight BoardS orzeczenie w sprawie postu Bidena i
zaktualizuje post po zapoznaniu się z zaleceniami zarządu
zaleceń.
Meta jest zobowiązana do przestrzegania orzeczeń Oversight Boards
w sprawie konkretnych decyzji dotyczących treści, choć
nie jest zobowiązana do przestrzegania
szerszych zaleceń. Mimo to zarząd
skłoniła firmę do wprowadzenia pewnych zmian
na przestrzeni lat, w tym wysyłanie wiadomości do
użytkowników, którzy naruszają zasady iłs, bardziej szczegółowe, aby
wyjaśnić im, co zrobili źle.
Jen, profesor na Uniwersytecie
Marylands College of Studies, powiedział
Meta jest wystarczająco duża, aby być liderem w oznaczaniu
zmanipulowanych treści, ale działania następcze są równie
równie ważne jak polityka.
„Jeśli wdrożą te zmiany, a następnie
a następnie egzekwują je w obliczu presji politycznej
ze strony ludzi, którzy chcą robić złe rzeczy?
To jest prawdziwe pytanie” - powiedziała. ”Jeśli wprowadzą te zmiany i ich nie zrealizują
zmiany i nie wprowadzają ich w życie, to
jeszcze bardziej przyczynia się do zniszczenia
zaufania, które wiąże się z wprowadzaniem w błąd.


Przetłumaczono z DeepL.com (wersja darmowa)