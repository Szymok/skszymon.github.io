<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="pl"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://szymok.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://szymok.github.io/" rel="alternate" type="text/html" hreflang="pl"/><updated>2023-09-22T22:50:19+00:00</updated><id>https://szymok.github.io/feed.xml</id><title type="html">blank</title><subtitle>Blog o computer vision i ogólnie rozumianej sztucznej inteligencji. To kluczowe narzędzia wspierające decyzje biznesowe i pozwalające na uzyskanie przewagi konkurencyjnej. </subtitle><entry><title type="html">Jak efektywnie czytać artykuły naukowe</title><link href="https://szymok.github.io/blog/2023/reading-papers/" rel="alternate" type="text/html" title="Jak efektywnie czytać artykuły naukowe"/><published>2023-09-19T04:01:45+00:00</published><updated>2023-09-19T04:01:45+00:00</updated><id>https://szymok.github.io/blog/2023/reading-papers</id><content type="html" xml:base="https://szymok.github.io/blog/2023/reading-papers/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/thebommel_collage_of_science_papers_and_measurements_383710fe-466e-4e7d-8218-0649915433dd-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/thebommel_collage_of_science_papers_and_measurements_383710fe-466e-4e7d-8218-0649915433dd-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/thebommel_collage_of_science_papers_and_measurements_383710fe-466e-4e7d-8218-0649915433dd-1400.webp"/> <img src="/assets/img/thebommel_collage_of_science_papers_and_measurements_383710fe-466e-4e7d-8218-0649915433dd.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Obraz wygenerowany przy pomocy Midjourney </div> <h1 id="skuteczne-odczytywanie-artykułów-naukowych-techniki-i-strategie">Skuteczne Odczytywanie Artykułów Naukowych: Techniki i Strategie</h1> <p>W dzisiejszym świecie nauki ogromna ilość informacji jest dostępna na wyciągnięcie ręki. Artykuły naukowe stanowią kluczowe źródło wiedzy dla badaczy, studentów i profesjonalistów, ale ich czytanie może być wyzwaniem. W tym artykule dowiesz się, jak efektywnie odczytywać artykuły naukowe, aby w pełni wykorzystać ich potencjał i zrozumieć zawarte w nich informacje.</p> <h2 id="zrozumienie-struktury-artykułu-naukowego">Zrozumienie Struktury Artykułu Naukowego</h2> <p>Kluczem do efektywnego czytania artykułów naukowych jest zrozumienie ich struktury. Większość artykułów naukowych składa się z następujących sekcji:</p> <h3 id="1-tytuł">1. Tytuł</h3> <p>Tytuł artykułu zawiera krótkie podsumowanie jego tematu. To pierwszy element, który przyciąga uwagę czytelnika, dlatego warto zwrócić na niego uwagę.</p> <h3 id="2-autorzy">2. Autorzy</h3> <p>Sekcja autorów zawiera informacje o osobach lub zespołach odpowiedzialnych za badania. To ważne, aby ocenić wiarygodność artykułu.</p> <h3 id="3-streszczenie-abstract">3. Streszczenie (Abstract)</h3> <p>Streszczenie to krótka prezentacja celów, metod, wyników i wniosków artykułu. To idealne miejsce, aby ocenić, czy artykuł jest związany z twoim obszarem zainteresowań.</p> <h3 id="4-wprowadzenie">4. Wprowadzenie</h3> <p>Sekcja wprowadzenia wyjaśnia, dlaczego badanie zostało przeprowadzone i jakie są jego cele. To ważne, aby zrozumieć kontekst i znaczenie badań.</p> <h3 id="5-metody">5. Metody</h3> <p>W tej sekcji autorzy opisują, jak przeprowadzili badania. To ważne, aby ocenić, czy metody były odpowiednie do uzyskania wyników.</p> <h3 id="6-wyniki">6. Wyniki</h3> <p>Sekcja wyników prezentuje uzyskane dane i obserwacje. To kluczowa część artykułu, która dostarcza faktów i dowodów.</p> <h3 id="7-dyskusja">7. Dyskusja</h3> <p>W sekcji dyskusji autorzy analizują swoje wyniki, porównują je z wcześniejszymi badaniami i wyciągają wnioski. To miejsce, gdzie powstają główne spostrzeżenia.</p> <h3 id="8-bibliografia">8. Bibliografia</h3> <p>Lista literatury zawiera odnośniki do źródeł, które autorzy wykorzystali w swoim artykule.</p> <h2 id="skupienie-na-kluczowych-elementach">Skupienie na Kluczowych Elementach</h2> <p>Czytanie artykułów naukowych może być czasochłonne, dlatego warto skupić się na kluczowych elementach. Oto kilka strategii, które pomogą ci w efektywnym czytaniu:</p> <h3 id="1-przeczytaj-tytuł-i-streszczenie">1. Przeczytaj Tytuł i Streszczenie</h3> <p>Rozpocznij od przeczytania tytułu i streszczenia. To pozwoli ci zrozumieć główny temat i cel badania.</p> <h3 id="2-przejrzyj-wprowadzenie-i-dyskusję">2. Przejrzyj Wprowadzenie i Dyskusję</h3> <p>Następnie przeczytaj wprowadzenie i dyskusję. Wprowadzenie pokaże ci, dlaczego badanie jest ważne, a dyskusja pomoże zrozumieć główne wnioski.</p> <h3 id="3-sprawdz-metody-i-wyniki">3. Sprawdz Metody i Wyniki</h3> <p>Sprawdz sekcje metod i wyników, aby zobaczyć, jak badanie zostało przeprowadzone i jakie wyniki uzyskano. Skoncentruj się na wykresach, tabelach i podsumowaniach wyników.</p> <h2 id="zastosowanie">Zastosowanie</h2> <h3 id="sprawdź-dostępność-danych-i-kodu-artykułu">Sprawdź dostępność danych i kodu artykułu:</h3> <p>Przejrzyj stronę artykułu w poszukiwaniu dostępu do kodu źródłowego i danych. Możesz także poszukać implementacji artykułu na platformach takich jak GitHub i Kaggle. Znalezienie implementacji artykułu ułatwi proces zrozumienia, jak został stworzony, co jest szczególnie pomocne, jeśli chcesz go dostosować do nowych danych. To oszczędzi Ci wiele czasu.</p> <h3 id="izoluj-sposób-budowy-modelu">Izoluj sposób budowy modelu</h3> <p>Jeśli kod źródłowy artykułu nie jest dostępny, będziesz musiał zaimplementować modele od podstaw. Możesz to zrobić, kierując się następującymi krokami:</p> <p>Architektura Modelu: Prawie każdy artykuł będzie zawierać diagram architektury modelu. Zrozumienie tego pomoże lepiej zrozumieć, jak działa model i co dokładnie robi.</p> <p>Wejścia i Wyjścia: Zrozumienie, jakie dane są podawane na wejściu i jakie wyniki są generowane na wyjściu modelu, pomoże w lepszym zrozumieniu, co dokładnie robi model. Przyjrzyj się wynikom, czy to prawdopodobieństwo, mapa segmentacji, ramki ograniczające itp.</p> <p>Nowe lub Niestandardowe Warstwy: Przyjrzyj się nowym technikom lub warstwom używanym w modelu, ponieważ mogą być one kluczowe dla zrozumienia, co autorzy artykułu dodali. Kod lub implementacja artykułu prawdopodobnie skupia się na tych nowych warstwach, więc warto dobrze zrozumieć, jak działają.</p> <p>Obliczenia Funkcji Straty: W artykule znajdziesz matematyczną formułę, która opisuje, jak obliczana jest funkcja straty. Jest to istotne do zrozumienia i zauważenia przed implementacją, ponieważ wpłynie to na wyniki. Musisz także zrozumieć, na jakiej podstawie została wybrana, ponieważ może być konieczne jej dostosowanie do Twojego projektu.</p> <p>Trenowanie Modelu: Zrozumienie, jak model był trenowany oraz jakie hiperparametry, rozmiar partii (batch size) i konfiguracje modelu zostały użyte.</p> <h3 id="rozpoznaj-co-nie-zostało-zrozumiane">Rozpoznaj, co nie zostało zrozumiane</h3> <p>Podkreśl punkty, które nie zostały zrozumiane i wymagają dalszego zgłębienia lub badania. Artykuły naukowe opierają się na sobie nawzajem. Dlatego oczekuje się, że masz pewne podstawowe tło i wiedzę związane z artykułem, który czytasz. Zaznacz i notuj te punkty, które pozostają niejasne, a następnie poszukaj odnośników i źródeł, które mogą Ci w tym pomóc. Mogą one być już cytowane w artykule, który czytasz.</p> <h3 id="wypróbuj-to-na-własnym-przykładzie">Wypróbuj to na własnym przykładzie</h3> <p>Aby naprawdę zrozumieć model, możesz go wytrenować na dostępnych danych z artykułu i spróbować odtworzyć wyniki, jeśli to możliwe. Pomoże to zrozumieć, jak dokładnie model działa i rozwijać umiejętność tworzenia niestandardowych warstw i definiowania własnych metryk straty, które są odpowiednie dla Twojego zadania i danych. Czasami może to być trudne, nawet jeśli dane są dostępne do ponownego trenowania modelu na wszystkich dostępnych danych, ponieważ może to zająć zbyt dużo czasu. W takim przypadku można zastosować model tylko do części dostępnych danych, aby upewnić się, że zaimplementowany model działa zgodnie z oczekiwaniami, a następnie można go zastosować do własnych danych.</p> <h3 id="zastosuj-to-do-własnych-danych">Zastosuj to do własnych danych</h3> <p>Ostatnim krokiem jest zastosowanie modelu do własnych danych. Możesz zastosować ten sam model, co w artykule, bez żadnych zmian, lub dostosować go do swojego projektu lub danych.</p> <h2 id="skuteczne-notatki-i-podkreślanie">Skuteczne Notatki i Podkreślanie</h2> <p>Aby utrwalić wiedzę i ułatwić późniejsze odniesienie się do artykułu, warto prowadzić efektywne notatki. Warto również korzystać z różnych kolorów podczas podkreślania lub zaznaczania kluczowych fragmentów tekstu.</p> <h2 id="przykłady-i-analogie">Przykłady i Analogie</h2> <p>Korzystanie z przykładów i analogii może pomóc w zrozumieniu trudnych koncepcji. Przykłady z życia codziennego lub analogie do znanych sytuacji mogą uczynić treść bardziej przystępną.</p> <h2 id="podsumowanie">Podsumowanie</h2> <p>Czytanie artykułów naukowych może być zarówno wyzwaniem, jak i źródłem wiedzy. Warto skoncentrować się na kluczowych sekcjach artykułów, zadawać pytania w razie potrzeby, korzystać z kontekstu i rozwijać własne cele czytania. Z czasem i praktyką, stanie się to bardziej efektywnym procesem, który pomoże w rozwoju wiedzy i badawczej kariery.</p>]]></content><author><name></name></author><category term="paper"/><category term="articles,"/><category term="reading,"/><category term="science,"/><category term="learning,"/><category term="techniques,"/><category term="strategies,"/><category term="papers,"/><category term="research"/><summary type="html"><![CDATA[Wprowadzenie w świat wiedzy - czytanie artykułów naukowych.]]></summary></entry><entry><title type="html">Przetwarzanie Obrazów - Wprowadzenie</title><link href="https://szymok.github.io/blog/2023/cv-przetw-obrazow/" rel="alternate" type="text/html" title="Przetwarzanie Obrazów - Wprowadzenie"/><published>2023-09-13T08:01:45+00:00</published><updated>2023-09-13T08:01:45+00:00</updated><id>https://szymok.github.io/blog/2023/cv-przetw-obrazow</id><content type="html" xml:base="https://szymok.github.io/blog/2023/cv-przetw-obrazow/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/visual_nexus_abstract_non-representational_geometric_shadows_lo_391fb38d-c47c-4755-85cc-fd1604bf1264-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/visual_nexus_abstract_non-representational_geometric_shadows_lo_391fb38d-c47c-4755-85cc-fd1604bf1264-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/visual_nexus_abstract_non-representational_geometric_shadows_lo_391fb38d-c47c-4755-85cc-fd1604bf1264-1400.webp"/> <img src="/assets/img/visual_nexus_abstract_non-representational_geometric_shadows_lo_391fb38d-c47c-4755-85cc-fd1604bf1264.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Obraz wygenerowany przy pomocy Midjourney </div> <h1 id="przetwarzanie-obrazów-wprowadzenie-do-technik-i-zastosowań">Przetwarzanie Obrazów: Wprowadzenie do Technik i Zastosowań</h1> <h2 id="złożoność-i-wybuchowość-w-przetwarzaniu-obrazów">Złożoność i Wybuchowość w Przetwarzaniu Obrazów</h2> <p>Przetwarzanie obrazów to dynamicznie rozwijająca się dziedzina w informatyce, która ma ogromne znaczenie w naszym codziennym życiu. Obejmuje ona analizę, manipulację i zrozumienie danych wizualnych, co znajduje zastosowanie w wielu dziedzinach, od medycyny po przemysł filmowy. W tym artykule przyjrzymy się temu fascynującemu obszarowi, skupiając się na aspektach złożoności i wybuchowości w kontekście przetwarzania obrazów.</p> <h2 id="zrozumienie-przetwarzania-obrazów">Zrozumienie Przetwarzania Obrazów</h2> <p>Przetwarzanie obrazów to nauka o analizie i manipulacji cyfrowych obrazów. W rzeczywistości każdy obraz cyfrowy jest reprezentowany jako siatka pikseli, z których każdy ma określoną wartość koloru. W tej dziedzinie nauki wykorzystuje się techniki matematyczne i algorytmy, aby ekstrahować informacje z obrazów i podejmować decyzje na ich podstawie. W efekcie przetwarzanie obrazów pozwala na automatyczną analizę i interpretację danych wizualnych.</p> <h2 id="złożoność-w-przetwarzaniu-obrazów">Złożoność w Przetwarzaniu Obrazów</h2> <p>Złożoność przetwarzania obrazów wynika z kilku czynników. Po pierwsze, obrazy cyfrowe mogą być bardzo rozbudowane pod względem rozmiaru i szczegółowości. Rozdzielczość obrazów może sięgać milionów pikseli, co sprawia, że analiza każdego z nich staje się wyzwaniem obliczeniowym. Po drugie, obrazy mogą zawierać wiele warstw informacji, takich jak kolory, tekstury i kształty. Przetwarzanie tych danych wymaga zaawansowanych algorytmów.</p> <h2 id="wybuchowość-w-przetwarzaniu-obrazów">Wybuchowość w Przetwarzaniu Obrazów</h2> <p>Wybuchowość w kontekście przetwarzania obrazów oznacza zdolność do dynamicznego reagowania na różnorodność danych wizualnych i sytuacji. W rzeczywistości, świat obrazów jest pełen zmiennych czynników, takich jak zmienne oświetlenie, perspektywa, położenie obiektów itp. Dlatego też, algorytmy przetwarzania obrazów muszą być elastyczne i zdolne do dostosowania się do różnych scenariuszy.</p> <h2 id="zaawansowane-techniki-w-przetwarzaniu-obrazów">Zaawansowane Techniki w Przetwarzaniu Obrazów</h2> <h3 id="1-segmentacja-obrazu">1. Segmentacja obrazu</h3> <p>Segmentacja to proces podziału obrazu na różne obszary, które reprezentują różne obiekty lub regiony. Zaawansowane techniki segmentacji pozwalają na automatyczne wyodrębnienie obiektów z tła, co jest przydatne w medycynie (np. detekcja guzów), przemyśle (np. kontrola jakości) i wielu innych dziedzinach.</p> <h3 id="2-wykrywanie-obiektów">2. Wykrywanie obiektów</h3> <p>Wykrywanie obiektów polega na identyfikowaniu i lokalizowaniu obiektów na obrazie. To kluczowa funkcja w przetwarzaniu obrazów, stosowana w systemach monitoringu, rozpoznawaniu twarzy, czy nawet w autonomicznych pojazdach.</p> <h3 id="3-analiza-tekstur">3. Analiza tekstur</h3> <p>Analiza tekstur pozwala na identyfikację powtarzających się wzorców na obrazie. To przydatne w dziedzinach takich jak diagnostyka medyczna (analiza tekstur na obrazach MRI) oraz w przemyśle filmowym (animacja tekstur na powierzchniach 3D).</p> <h2 id="zastosowania-przetwarzania-obrazów">Zastosowania Przetwarzania Obrazów</h2> <h3 id="medycyna">Medycyna</h3> <p>Przetwarzanie obrazów ma kluczowe znaczenie w medycynie, gdzie jest wykorzystywane do diagnostyki, planowania zabiegów chirurgicznych i monitorowania stanu pacjentów. Przykładowo, komputerowe tomografie (CT) i rezonanse magnetyczne (MRI) opierają się na zaawansowanych technikach przetwarzania obrazów.</p> <h3 id="przemysł">Przemysł</h3> <p>W przemyśle przetwarzanie obrazów jest używane do kontroli jakości produktów, monitoringu procesów produkcyjnych i zarządzania magazynami. Dzięki temu można unikać wadliwych produktów i zoptymalizować produkcję.</p> <h3 id="bezpieczeństwo">Bezpieczeństwo</h3> <p>W systemach bezpieczeństwa, takich jak kamery monitoringu, przetwarzanie obrazów umożliwia wykrywanie podejrzanych zachowań, rozpoznawanie twarzy i identyfikację pojęć kluczowych w czasie rzeczywistym.</p> <h2 id="przyszłość-przetwarzania-obrazów">Przyszłość Przetwarzania Obrazów</h2> <p>Przetwarzanie obrazów rozwija się w zastraszającym tempie. Zaawansowane modele uczenia maszynowego, takie jak sieci neuronowe, rewolucjonizują dziedzinę, umożliwiając automatyczne rozpoznawanie obiektów i interpretację treści na obrazach. Przyszłość przetwarzania obrazów będzie wiązać się z jeszcze bardziej zaawansowanymi algorytmami, które będą w stanie analizować obrazy w bardziej kontekstualny sposób, jak ludzki mózg.</p> <h2 id="podsumowanie">Podsumowanie</h2> <p>Przetwarzanie obrazów to dziedzina, która ma ogromne znaczenie w naszym życiu codziennym i w wielu dziedzinach, takich jak medycyna, przemysł czy bezpieczeństwo. Złożoność i wybuchowość tego obszaru sprawiają, że naukowcy i inżynierowie pracują nad coraz bardziej zaawansowanymi technikami i algorytmami. Przetwarzanie obrazów jest jednym z kluczowych filarów rozwoju sztucznej inteligencji i będzie odgrywać jeszcze większą rolę w przyszłości.</p>]]></content><author><name></name></author><category term="computer-vision"/><category term="computer-vision"/><category term="computer-vision-learn"/><category term="techniques"/><category term="applications"/><summary type="html"><![CDATA[Computer Vision, wprowadzenie, techniki i zastosowania.]]></summary></entry><entry><title type="html">Computer Vision - o co w tym chodzi?</title><link href="https://szymok.github.io/blog/2023/computer-vision-basics/" rel="alternate" type="text/html" title="Computer Vision - o co w tym chodzi?"/><published>2023-09-10T12:12:45+00:00</published><updated>2023-09-10T12:12:45+00:00</updated><id>https://szymok.github.io/blog/2023/computer-vision-basics</id><content type="html" xml:base="https://szymok.github.io/blog/2023/computer-vision-basics/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/supermoggy_computer_vision_in_education_94e97ddc-a0bf-4656-908e-5465fd54b2af-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/supermoggy_computer_vision_in_education_94e97ddc-a0bf-4656-908e-5465fd54b2af-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/supermoggy_computer_vision_in_education_94e97ddc-a0bf-4656-908e-5465fd54b2af-1400.webp"/> <img src="/assets/img/supermoggy_computer_vision_in_education_94e97ddc-a0bf-4656-908e-5465fd54b2af.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Computer Vision według Midjourney </div> <h1 id="podstawy-computer-vision-wprowadzenie-do-świata-wizualnej-analizy">Podstawy Computer Vision: Wprowadzenie do Świata Wizualnej Analizy</h1> <p>Computer Vision, czyli po polsku Wizja Komputerowa, to fascynujący obszar sztucznej inteligencji, który umożliwia maszynom rozumienie i interpretację obrazów oraz filmów. Ta dziedzina odgrywa kluczową rolę w rozwoju technologii, otwierając przed nami nieograniczone możliwości. W tym artykule zapoznamy się z podstawami Computer Vision, aby pomóc Ci zrozumieć, czym jest i dlaczego jest tak istotna.</p> <h2 id="czym-jest-computer-vision"><strong>Czym Jest Computer Vision?</strong></h2> <p>Computer Vision jest dziedziną sztucznej inteligencji, która ma na celu umożliwienie komputerom “widzenia” i analizy wizualnych danych. To oznacza, że maszyny mogą rozpoznawać obiekty, osoby, miejsca, ruch i wiele innych aspektów wizualnych informacji, tak jak to robi człowiek. W skrócie, Computer Vision pozwala komputerom zrozumieć świat wizualny, co ma wiele praktycznych zastosowań.</p> <h2 id="zastosowania-computer-vision"><strong>Zastosowania Computer Vision</strong></h2> <p>Zanim zagłębimy się w techniczne detale, warto zrozumieć, dlaczego Computer Vision jest tak ważny i jakie ma praktyczne zastosowania. Oto kilka obszarów, w których ta technologia odgrywa kluczową rolę:</p> <h3 id="1-medycyna"><strong>1. Medycyna</strong></h3> <p>W dziedzinie medycyny Computer Vision jest wykorzystywany do analizy obrazów medycznych, takich jak zdjęcia rentgenowskie czy tomografie komputerowe. Dzięki temu lekarze mogą szybciej i dokładniej diagnozować schorzenia, co przekłada się na poprawę opieki zdrowotnej.</p> <h3 id="2-przemysł"><strong>2. Przemysł</strong></h3> <p>W przemyśle Computer Vision jest używany do kontroli jakości produktów, śledzenia i zarządzania magazynami oraz automatyzacji procesów produkcyjnych. To pozwala na zwiększenie efektywności i obniżenie kosztów produkcji.</p> <h3 id="3-motoryzacja"><strong>3. Motoryzacja</strong></h3> <p>W branży motoryzacyjnej Computer Vision odgrywa kluczową rolę w rozwoju aut autonomicznych. Dzięki technologii wizualnej samochody potrafią rozpoznawać znaki drogowe, unikać kolizji i samodzielnie prowadzić pojazd.</p> <h3 id="4-rozrywka"><strong>4. Rozrywka</strong></h3> <p>W świecie rozrywki Computer Vision jest wykorzystywany do tworzenia gier wirtualnych, aplikacji rzeczywistości rozszerzonej i rozpoznawania ruchu. To pozwala na bardziej immersywne i zaawansowane doświadczenia rozrywkowe.</p> <h3 id="5-bezpieczeństwo"><strong>5. Bezpieczeństwo</strong></h3> <p>W zastosowaniach związanych z bezpieczeństwem Computer Vision jest używany do monitorowania i analizy wideo z kamer przemysłowych oraz do rozpoznawania twarzy w celu kontroli dostępu.</p> <h2 id="jak-działa-computer-vision"><strong>Jak Działa Computer Vision?</strong></h2> <p>Teraz, gdy mamy ogólne pojęcie o zastosowaniach Computer Vision, przejdźmy do tego, jak ta technologia działa. Istnieje wiele metod i algorytmów wykorzystywanych w Computer Vision, ale ogólny proces można podzielić na kilka głównych kroków:</p> <h3 id="1-akwizycja-danych"><strong>1. Akwizycja Danych</strong></h3> <p>Pierwszym krokiem w Computer Vision jest pozyskanie danych wizualnych. To może obejmować zdjęcia, nagrania wideo lub obrazy z kamer.</p> <h3 id="2-preprocessing"><strong>2. Preprocessing</strong></h3> <p>Następnie dane te są przetwarzane, aby usunąć szum, dostosować kontrast i jasność, a także przekształcić je na formę bardziej odpowiednią do analizy.</p> <h3 id="3-wykrywanie-obiektów"><strong>3. Wykrywanie obiektów</strong></h3> <p>Ten krok polega na identyfikacji obiektów lub cech w obrazie. To może obejmować rozpoznawanie twarzy, pojazdów, znaków drogowych i innych obiektów.</p> <h3 id="4-ekstrakcja-cech"><strong>4. Ekstrakcja Cech</strong></h3> <p>Computer Vision analizuje cechy wykrytych obiektów, takie jak kształt, kolor, tekstura i inne. To pozwala na bardziej zaawansowane analizy.</p> <h3 id="5-klasyfikacja-i-interpretacja"><strong>5. Klasyfikacja i Interpretacja</strong></h3> <p>Na podstawie ekstrahowanych cech Computer Vision dokonuje klasyfikacji obiektów i interpretuje dane. Na przykład, może rozpoznać, że na obrazie widnieje pies.</p> <h3 id="6-decyzje-i-działania"><strong>6. Decyzje i Działania</strong></h3> <p>W końcowym etapie Computer Vision podejmuje decyzje lub podejmuje działania na podstawie swoich analiz. Na przykład, może wysłać sygnał do systemu sterowania, aby zatrzymać pojazd w przypadku wykrycia przeszkody.</p> <h2 id="wyzwania-w-computer-vision"><strong>Wyzwania w Computer Vision</strong></h2> <p>Chociaż Computer Vision ma wiele zastosowań i jest niesamowicie obiecujący, to także stawia przed nami wiele wyzwań. Oto kilka z nich:</p> <h3 id="1-zrozumienie-kontekstu"><strong>1. Zrozumienie Kontekstu</strong></h3> <p>Computer Vision czasem ma trudności z zrozumieniem kontekstu. Na przykład, może rozpoznać, że na obrazie jest pies, ale może nie zrozumieć, czy jest on przyjacielem czy wrogiem.</p> <h3 id="2-skomplikowane-środowiska"><strong>2. Skomplikowane Środowiska</strong></h3> <p>W realnym świecie obrazy są często zanieczyszczone, a obiekty są często częściowo ukryte lub przesłonięte. To stanowi wyzwanie dla algorytmów Computer Vision.</p> <h3 id="3-wymagane-duże-zbiory-danych"><strong>3. Wymagane Duże Zbiory Danych</strong></h3> <p>Wielu algorytmów Computer Vision wymaga ogromnych zbiorów danych treningowych, co może być kosztowne i czasochłonne.</p> <h3 id="4-prywatność-i-bezpieczeństwo"><strong>4. Prywatność i Bezpieczeństwo</strong></h3> <p>Wykorzystanie technologii Computer Vision w zastosowaniach związanych z bezpieczeństwem i prywatnością może budzić obawy dotyczące ochrony danych osobowych.</p> <h2 id="podsumowanie"><strong>Podsumowanie</strong></h2> <p>Computer Vision to fascynujący obszar, który zmienia nasz sposób patrzenia na świat. Ta technologia pozwala maszynom zrozumieć i analizować wizualne dane, otwierając przed nami wiele nowych możliwości. Choć są pewne wyzwania związane z Computer Vision, to jej potencjał jest ogromny, a jej rola w naszym życiu tylko rośnie. Warto pozostać z nami, aby dowiedzieć się więcej o tej fascynującej dziedzinie.</p> <p>Artykuł na temat podstaw Computer Vision jest tylko wprowadzeniem do tego obszaru. Jeśli jesteś zainteresowany bardziej zaawansowanymi aspektami, takimi jak głębokie uczenie się czy analiza obrazów 3D, to tematy, które możemy zgłębiać w przyszłości. Computer Vision to dziedzina, która będzie miała coraz większy wpływ na naszą codzienność, więc warto być na bieżąco z jej najnowszymi osiągnięciami i możliwościami.</p> <p><em>Mając na uwadze te podstawy Computer Vision, możemy teraz eksplorować bardziej zaawansowane techniki i aplikacje tej fascynującej dziedziny.</em></p>]]></content><author><name></name></author><category term="computer-vision"/><category term="computer-vision"/><category term="computer-vision-basics"/><category term="computer-vision-ai"/><category term="ai"/><category term="podstawy"/><summary type="html"><![CDATA[Computer Vision, podstawy, które warto znać.]]></summary></entry><entry><title type="html">Jak Się Uczyć Computer Vision Praktyczny Przewodnik</title><link href="https://szymok.github.io/blog/2023/cv-learning/" rel="alternate" type="text/html" title="Jak Się Uczyć Computer Vision Praktyczny Przewodnik"/><published>2023-09-10T12:12:45+00:00</published><updated>2023-09-10T12:12:45+00:00</updated><id>https://szymok.github.io/blog/2023/cv-learning</id><content type="html" xml:base="https://szymok.github.io/blog/2023/cv-learning/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cheryl8555_learning_through_traditional_education_settings_whil_4d9cc9f9-62e3-4494-85b1-c62cf17e488f-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cheryl8555_learning_through_traditional_education_settings_whil_4d9cc9f9-62e3-4494-85b1-c62cf17e488f-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cheryl8555_learning_through_traditional_education_settings_whil_4d9cc9f9-62e3-4494-85b1-c62cf17e488f-1400.webp"/> <img src="/assets/img/cheryl8555_learning_through_traditional_education_settings_whil_4d9cc9f9-62e3-4494-85b1-c62cf17e488f.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Obraz wygenerowany przy pomocy Midjourney </div> <h1 id="jak-się-uczyć-computer-vision-praktyczny-przewodnik">Jak Się Uczyć Computer Vision: Praktyczny Przewodnik</h1> <p>Computer Vision, czyli po polsku Wizja Komputerowa, to fascynująca dziedzina sztucznej inteligencji, która umożliwia komputerom “widzenie” i analizę obrazów oraz filmów. To obszar o ogromnym potencjale i szerokich zastosowaniach, który stale się rozwija. Jeśli jesteś zainteresowany nauką Computer Vision, to jesteś we właściwym miejscu. W tym artykule przedstawimy praktyczny przewodnik, jak się uczyć Computer Vision, niezależnie od Twojego poziomu zaawansowania.</p> <h2 id="rozpocznij-od-podstaw"><strong>Rozpocznij od Podstaw</strong></h2> <p>Jeśli dopiero zaczynasz swoją przygodę z Computer Vision, to ważne jest, aby zrozumieć podstawowe koncepcje i terminologię. Oto kilka kluczowych terminów, które warto poznać:</p> <ul> <li> <p><strong>Obraz:</strong> Obraz to zbiór pikseli, które tworzą graficzne reprezentacje obiektów i scen. Obrazy są podstawowymi danymi używanymi w Computer Vision.</p> </li> <li> <p><strong>Piksel:</strong> Piksel to najmniejszy element obrazu, który zawiera informacje o kolorze i jasności.</p> </li> <li> <p><strong>Segmentacja:</strong> To proces dzielenia obrazu na konkretne obszary lub segmenty, co pomaga w identyfikowaniu obiektów.</p> </li> <li> <p><strong>Rozpoznawanie Obiektów:</strong> To zdolność komputera do identyfikacji i klasyfikacji obiektów na obrazie, na przykład rozpoznawanie twarzy lub samochodów.</p> </li> <li> <p><strong>Klasyfikacja:</strong> To przypisanie obiektu do określonej kategorii lub klasy na podstawie jego cech.</p> </li> <li> <p><strong>Analiza Ruchu:</strong> To badanie ruchu obiektów na obrazie, co jest istotne w zastosowaniach takich jak śledzenie ruchu i analiza zachowań.</p> </li> </ul> <p>Rozumienie tych podstawowych pojęć jest kluczowe dla dalszego rozwoju w Computer Vision.</p> <h2 id="wybierz-język-programowania-i-narzędzia"><strong>Wybierz Język Programowania i Narzędzia</strong></h2> <p>Computer Vision jest często wykonywany przy użyciu języków programowania takich jak Python lub C++. Python jest popularnym wyborem ze względu na swoją czytelność i bogatą gamę bibliotek do przetwarzania obrazów, takich jak OpenCV (Open Source Computer Vision Library) czy TensorFlow.</p> <p>Jeśli jesteś początkującym, zacznij od nauki Pythona, ponieważ jest przyjazny dla początkujących i szeroko stosowany w dziedzinie Data Science oraz Computer Vision.</p> <h2 id="zdobądź-wiedzę-teoretyczną"><strong>Zdobądź Wiedzę Teoretyczną</strong></h2> <p>Zanim zaczniesz pisać kod i pracować z obrazami, warto zdobyć pewną wiedzę teoretyczną. To pomoże Ci zrozumieć, jak działają algorytmy i dlaczego stosuje się określone metody. Oto kilka podstawowych dziedzin, które warto zgłębić:</p> <ul> <li> <p><strong>Przetwarzanie Obrazów:</strong> Poznaj podstawowe operacje przetwarzania obrazów, takie jak filtracja, detekcja krawędzi i normalizacja.</p> </li> <li> <p><strong>Statystyka:</strong> Statystyka jest ważna w analizie i interpretacji danych w Computer Vision.</p> </li> <li> <p><strong>Algorytmy Machine Learning:</strong> Naucz się podstawowych koncepcji związanych z uczeniem maszynowym, takich jak klasyfikacja, regresja i sieci neuronowe.</p> </li> <li> <p><strong>Matematyka:</strong> Matematyka, w tym algebra liniowa i analiza, jest kluczowym elementem w wielu algorytmach Computer Vision.</p> </li> </ul> <h2 id="praktyka-praktyka-praktyka"><strong>Praktyka, Praktyka, Praktyka</strong></h2> <p>Nie ma lepszego sposobu na naukę Computer Vision niż praktyka. Zacznij od prostych projektów i stopniowo zwiększaj poziom trudności. Oto kilka projektów, które możesz rozważyć:</p> <ul> <li> <p><strong>Rozpoznawanie Obiektów na Obrazach:</strong> Próbuj tworzyć modele, które potrafią rozpoznawać i klasyfikować obiekty na obrazach.</p> </li> <li> <p><strong>Śledzenie Ruchu:</strong> Zaprojektuj system, który może śledzić ruch obiektów na nagraniach wideo.</p> </li> <li> <p><strong>Analiza Twarzy:</strong> Spróbuj rozpoznawać twarze i analizować ich cechy, takie jak wyraz twarzy czy emocje.</p> </li> <li> <p><strong>Aplikacje Mobilne:</strong> Stwórz prostą aplikację mobilną, która wykorzystuje Computer Vision, na przykład do rozpoznawania QR kodów.</p> </li> </ul> <h2 id="kursy-i-źródła-online"><strong>Kursy i Źródła Online</strong></h2> <p>Istnieje wiele kursów online, które pomogą Ci zdobyć zaawansowaną wiedzę z zakresu Computer Vision. Niektóre z nich są dostępne za darmo, a inne wymagają subskrypcji lub zakupu kursu. Oto kilka źródeł, które warto rozważyć:</p> <ul> <li> <p><strong>Coursera:</strong> Platforma oferuje wiele kursów z Computer Vision prowadzonych przez renomowane uczelnie.</p> </li> <li> <p><strong>Udacity:</strong> Udacity oferuje programy nanodegree z Computer Vision, które pozwalają zdobyć praktyczne doświadczenie.</p> </li> <li> <p><strong>edX:</strong> Na edX znajdziesz kursy prowadzone przez topowe uniwersytety i instytucje.</p> </li> <li> <p><strong>YouTube:</strong> Istnieje wiele darmowych tutoriali i wykładów na YouTube, które mogą być cennym źródłem wiedzy.</p> </li> </ul> <h2 id="konferencje-i-społeczności"><strong>Konferencje i Społeczności</strong></h2> <p>Uczestnictwo w konferencjach i zaangażowanie się w społeczności związaną z Computer Vision to doskonały sposób na poznanie najnowszych trendów i nawiązanie kontaktów z profesjonalistami. Niektóre znane konferencje to:</p> <ul> <li> <p><strong>Conference on Computer Vision and Pattern Recognition (CVPR):</strong> Jedna z największych i najważniejszych konferencji w dziedzinie Computer Vision.</p> </li> <li> <p><strong>International Conference on Computer Vision (ICCV):</strong> Inna prestiżowa konferencja poświęcona Computer Vision.</p> </li> <li> <p><strong>Społeczności Online:</strong> Istnieją fora dyskusyjne i grupy na platformach takich jak Reddit i Stack Overflow, gdzie można zadawać pytania i dzielić się wiedzą.</p> </li> </ul> <h2 id="podejmij-wyzwanie-kaggle"><strong>Podejmij Wyzwanie Kaggle</strong></h2> <p>Kaggle to platforma, na której można wziąć udział w konkursach związanych z analizą danych i Machine Learning, w tym z Computer Vision. To doskonały sposób na sprawdzenie swoich umiejętności i rywalizację z innymi osobami na całym świecie.</p> <h2 id="podsumowanie"><strong>Podsumowanie</strong></h2> <p>Nauka Computer Vision to fascynująca podróż, która może otworzyć przed Tobą wiele drzwi zawodowych. Niezależnie od tego, czy jesteś początkującym, czy zaawansowanym programistą, kluczem do sukcesu jest regularna praktyka, zdobywanie wiedzy teoretycznej oraz uczestnictwo w społeczności związaną z tą dziedziną. Warto również być na bieżąco z najnowszymi osiągnięciami i trendami w Computer Vision, ponieważ ta dziedzina rozwija się niezwykle dynamicznie. Odkrywaj świat wizualnej analizy i ciesz się procesem nauki!</p>]]></content><author><name></name></author><category term="computer-vision"/><category term="computer-vision"/><category term="computer-vision-learn"/><category term="computer-vision-ai"/><category term="ai"/><category term="podstawy"/><summary type="html"><![CDATA[Computer Vision, od czego zacząć naukę.]]></summary></entry><entry><title type="html">SportsSloMo - Nowość w branży analizy sportowej!</title><link href="https://szymok.github.io/blog/2023/interpolacja-klatek-w-sporcie/" rel="alternate" type="text/html" title="SportsSloMo - Nowość w branży analizy sportowej!"/><published>2023-09-08T00:12:45+00:00</published><updated>2023-09-08T00:12:45+00:00</updated><id>https://szymok.github.io/blog/2023/interpolacja-klatek-w-sporcie</id><content type="html" xml:base="https://szymok.github.io/blog/2023/interpolacja-klatek-w-sporcie/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/video/soccer.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls=""/> </figure> </div> </div> <h1 id="interpolacja-klatek-wideo-zorientowana-na-człowieka-w-transmisjach-sportowych">Interpolacja klatek wideo zorientowana na człowieka w transmisjach sportowych</h1> <p>Interpolacja klatek wideo w kontekście transmisji sportowych jest fascynującym obszarem badań w dziedzinie computer vision. Dzięki wykorzystaniu zaawansowanych technik interpolacji, można poprawić jakość transmisji sportowych, zwłaszcza w sytuacjach, gdy dostępne źródło wideo jest ograniczone pod względem liczby klatek na sekundę (FPS). W tym artykule przyjrzymy się temu zagadnieniu, skupiając się na aspektach związanych z ludzką orientacją i dostarczając dogłębnych spostrzeżeń na temat wykorzystania interpolacji klatek w kontekście sportu.</p> <h2 id="zrozumienie-interpolacji-klatek-wideo">Zrozumienie interpolacji klatek wideo</h2> <p>Interpolacja klatek wideo to proces generowania nowych klatek wideo na podstawie istniejących klatek. Ma to na celu zwiększenie liczby klatek na sekundę, co może poprawić płynność i jakość oglądanej transmisji. W przypadku sportów, gdzie szybkie ruchy i akcje są kluczowe, interpolacja może być szczególnie korzystna. Jednak skomplikowanie polega na tym, jak interpolować klatki w taki sposób, aby zachować naturalny wygląd ruchu sportowca.</p> <h2 id="złożoność-interpolacji-klatek">Złożoność interpolacji klatek</h2> <p>Interpolacja klatek wideo jest zadaniem złożonym, ponieważ wymaga uwzględnienia wielu czynników, takich jak prędkość ruchu, kąt kamery i interakcje między zawodnikami. Istnieje wiele algorytmów interpolacji, które próbują rozwiązać ten problem. Jednym z najczęściej stosowanych jest metoda liniowej interpolacji, która zakłada, że ruch między klatkami jest stały. Jednak w transmisjach sportowych rzeczywistość jest znacznie bardziej skomplikowana.</p> <h2 id="wybuchowość-w-interpolacji-klatek">Wybuchowość w interpolacji klatek</h2> <p>Kiedy mówimy o wybuchowości w kontekście interpolacji klatek, chodzi nam o zdolność do elastycznego reagowania na zmienne warunki w transmisjach sportowych. To oznacza, że algorytmy interpolacji muszą być w stanie dostosować się do szybkich zmian, takich jak niespodziewane ruchy zawodników czy zmiany oświetlenia na boisku. Wybuchowość jest kluczowa, ponieważ nie można przewidzieć wszystkich scenariuszy, które mogą mieć miejsce podczas meczu.</p> <h2 id="zaawansowane-techniki-interpolacji">Zaawansowane techniki interpolacji</h2> <p>W ostatnich latach dokonano znaczących postępów w dziedzinie interpolacji klatek wideo, zwłaszcza z wykorzystaniem sztucznej inteligencji. Jedną z obiecujących technik jest wykorzystanie sieci neuronowych, które są w stanie analizować wzorce ruchu zawodników i generować klatki wideo o wyższej jakości. Te zaawansowane modele potrafią uwzględniać złożone czynniki, takie jak zmiany prędkości i kierunku ruchu, co sprawia, że interpolacja staje się bardziej realistyczna.</p> <h2 id="przykłady-zastosowań-interpolacji-klatek-w-sporcie">Przykłady zastosowań interpolacji klatek w sporcie</h2> <p>Interpolacja klatek wideo zorientowana na człowieka ma wiele praktycznych zastosowań w dziedzinie transmisji sportowych. Oto kilka przykładów:</p> <h3 id="poprawa-jakości-zwolnień">Poprawa jakości zwolnień</h3> <p>Zwolnienia (slow motion) są często używane w transmisjach sportowych, aby pokazać szczegóły i kluczowe momenty. Interpolacja klatek pozwala na płynne i realistyczne zwolnienia, które zwiększają emocje podczas oglądania.</p> <h3 id="udoskonalenie-analizy-taktyki">Udoskonalenie analizy taktyki</h3> <p>Analizatorzy sportowi często korzystają z wolniejszych klatek do analizy taktyki drużyn. Dzięki dokładniejszym klatkom uzyskanym dzięki interpolacji, można lepiej zrozumieć strategie i decyzje podejmowane przez zawodników.</p> <h3 id="minimalizacja-efektu-upixelizowania">Minimalizacja efektu “upixelizowania”</h3> <p>W przypadku transmisji sportowych o niskiej jakości, szczególnie w przypadku retransmisji starszych meczów, interpolacja klatek może pomóc w minimalizacji efektu “upixelizowania” (rozmycia) i poprawieniu ogólnego wrażenia oglądania.</p> <h2 id="wyzwania-i-przyszłość-interpolacji-klatek">Wyzwania i przyszłość interpolacji klatek</h2> <p>Mimo że interpolacja klatek wideo przynosi wiele korzyści, istnieją także wyzwania. Jednym z nich jest utrzymanie naturalności ruchu zawodników. Ponadto, zbyt agresywna interpolacja może prowadzić do efektu “plastikowej” animacji, który jest niepożądany.</p> <p>W przyszłości możemy spodziewać się dalszego rozwoju technik interpolacji klatek wideo zorientowanych na człowieka. Wykorzystanie zaawansowanych modeli uczenia maszynowego, takich jak sieci GAN (Generative Adversarial Networks), może prowadzić do jeszcze bardziej realistycznych rezultatów.</p> <h2 id="podsumowanie">Podsumowanie</h2> <p>Interpolacja klatek wideo zorientowana na człowieka w transmisjach sportowych to fascynujący obszar badań w dziedzinie computer vision. Złożoność i wybuchowość tego zadania sprawiają, że wymaga ono zaawansowanych technik i podejścia opartego na sztucznej inteligencji. Dzięki tym technologiom możemy cieszyć się wyższą jakością transmisji sportowych, które pozwalają nam lepiej zrozumieć i docenić talent zawodników oraz taktykę drużyn.</p> <p>W miarę jak technologia ro</p> <p>zwija się dalej, możemy oczekiwać jeszcze bardziej imponujących osiągnięć w dziedzinie interpolacji klatek wideo, co z pewnością przyczyni się do wzbogacenia doświadczenia oglądania sportu dla wszystkich fanów na całym świecie.</p>]]></content><author><name></name></author><category term="computer-vision"/><category term="sportsloMo"/><category term="sportsloMo-ai"/><category term="ai"/><category term="benchmark"/><category term="interpolacja"/><category term="sport"/><summary type="html"><![CDATA[Nowa technologia(benchmark) w branży analizy sportowej.]]></summary></entry><entry><title type="html">Rząd a AI</title><link href="https://szymok.github.io/blog/2023/ai-w-rekach-rzadu/" rel="alternate" type="text/html" title="Rząd a AI"/><published>2023-08-21T05:12:45+00:00</published><updated>2023-08-21T05:12:45+00:00</updated><id>https://szymok.github.io/blog/2023/ai-w-rekach-rzadu</id><content type="html" xml:base="https://szymok.github.io/blog/2023/ai-w-rekach-rzadu/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sahilofix_America_government_garden_childrens_book_illustration_f1d1c5d1-34df-4501-a146-74024190e7ca-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sahilofix_America_government_garden_childrens_book_illustration_f1d1c5d1-34df-4501-a146-74024190e7ca-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sahilofix_America_government_garden_childrens_book_illustration_f1d1c5d1-34df-4501-a146-74024190e7ca-1400.webp"/> <img src="/assets/img/sahilofix_America_government_garden_childrens_book_illustration_f1d1c5d1-34df-4501-a146-74024190e7ca.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Obraz wygenerowany przy pomocy Midjourney oraz edytowany w Photoshopie przy pomoocy funkcji Generative AI. </div> <h2 id="potęga-technologii-ai-wpływ-interwencji-rządowej-w-zaawansowane-systemy-ai"><strong>Potęga Technologii AI: Wpływ Interwencji Rządowej w Zaawansowane Systemy AI</strong></h2> <p>W dynamicznym świecie technologii wyróżnia się jeden głos wśród chóru insiderów branżowych i innowatorów. Charles Jennings, doświadczony weteran świata oprogramowania, spędził dziesięciolecia na czele firm zajmujących się oprogramowaniem, na własne oczy obserwując potencjał transformacyjny sztucznej inteligencji. Jego najnowsza przedsięwzięcie, technologia rozpoznawania twarzy oparta na sztucznej inteligencji, ponownie przyciągnęła uwagę opinii publicznej. Jednak jego perspektywa na przyszłość AI nie jest powszechnie słyszana w środowisku technologicznym. W inspirującej rozmowie z Stevenem Overly z POLITICO Tech, Jennings twierdzi, że najbardziej zaawansowane systemy sztucznej inteligencji stały się zbyt potężne, aby pozostawić je w prywatnych rękach. Argumentuje za zmianą równowagi władzy, sugerując, że interwencja rządowa jest niezbędnym krokiem, aby wykorzystać pełny potencjał AI.</p> <h3 id="bezprecedensowa-potęga-sztucznej-inteligencji"><strong>Bezprecedensowa Potęga Sztucznej Inteligencji</strong></h3> <p>Wzrost znaczenia AI w ostatnich latach charakteryzował się bezprecedensowym postępem. Zastosowania AI, zwłaszcza w technologii rozpoznawania twarzy, wykazały zdolność do analizy ogromnych zbiorów danych, identyfikacji wzorców i podejmowania decyzji z nadzwyczajną dokładnością. Te zdolności wykraczają poza zakres możliwości człowieka, obiecując przełomowe zmiany w wielu dziedzinach. Jednak w miarę wzrostu potencjału AI narastały również obawy dotyczące etyki, prywatności i nadużyć. Jennings wyznacza kluczowy moment: czy te potężne narzędzia powinny pozostać wyłącznie w rękach gigantów technologicznych, czy też powinny być powierzone ludowi poprzez interwencję rządową?</p> <h3 id="dychotomia-giganci-technologiczni-a-rząd"><strong>Dychotomia: Giganci Technologiczni a Rząd</strong></h3> <p>Jennings sprowadza tę decyzję do dychotomii dwóch opcji: albo giganci technologiczni nadal kontrolują trajektorię AI, albo rządy wkraczają w regulację i zarządzanie jej rozwojem. Koncepcja powierzenia takiej władzy podmiotom prywatnym budzi uzasadnione obawy dotyczące potencjalnych uprzedzeń, monopolów i niekontrolowanego wpływu, jaki skoncentrowana władza może wywrzeć. Jednak postulat interwencji rządowej nie jest pozbawiony swoich komplikacji.</p> <p>Jennings przyznaje, że obecne rządy mogą nie być w pełni przygotowane do skutecznego zarządzania zaawansowanymi systemami AI. Chociaż Kongres może odgrywać rolę regulatora, dynamiczna i szybko ewoluująca natura technologii AI stanowi istotne wyzwanie. Szybki rozwój zdolności AI często przewyższa procesy legislacyjne, czyniąc je niewystarczającymi do nadążania za szybkimi zmianami w środowisku technologicznym.</p> <h3 id="imperatyw-zmiany"><strong>Imperatyw Zmiany</strong></h3> <p>Jak więc znaleźć drogę naprzód? Jennings nie postuluje całkowitego odrzucenia roli Kongresu, ale nawołuje do innowacyjnych, dostosowanych struktur, które mogą efektywnie nadzorować i regulować rozwój technologii AI. Sugeruje, że poleganie wyłącznie na Kongresie w zakresie nadzoru jest porównywalne do proszenia żółwia, by dorównał zającowi - daremne wysiłki. Zamiast tego proponuje potrzebę nowych podejść i instytucji, specjalnie dostosowanych do zarządzania złożonością AI.</p> <h3 id="nowy-paradoks-kształtowanie-zarządzania-ai"><strong>Nowy Paradoks: Kształtowanie Zarządzania AI</strong></h3> <p>Wyobraźmy sobie nowy paradygmat, w którym zarządzanie AI jest kształtowane przez zróżnicowaną grupę ekspertów, technologów, etyków i decydentów. Ta grupa przekroczyłaby tradycyjne struktury biurokratyczne, umożliwiając szybkie reakcje na postępy AI. Służyłaby jako interfejs między postępami technologicznymi a regulacją rządową, zapewniając priorytet dla interesów społeczeństwa. Poprzez połączenie wiedzy ekspertów, ten nowy model mógłby poruszać się po skomplikowanej sieci rozwoju AI z elastycznością, której obecny krajobraz regulacyjny brakuje.</p> <h3 id="etyka-i-przejrzystość-filary-zarządzania-ai"><strong>Etyka i Przejrzystość: Filary Zarządzania AI</strong></h3> <p>Etyka i przejrzystość leżą u podstaw tego proponowanego paradygmatu zarządzania AI. Potencjał technologii AI do utrwalania uprzedzeń i naruszania prywatności osobistej podkreśla pilność potrzeby etycznego fundamentu. Mechanizmy przejrzystości umożliwiłyby społeczeństwu zrozumienie procesów podejmowania decyzji przez systemy AI, zmniejszając efekt “czarnej skrzynki”, który często utrudnia zrozumienie. Poprzez rozwiązanie tych kwestii etycznych i związanych z przejrzystością, ten model mógłby budować zaufanie publiczne, kluczowy czynnik skutecznego wdrożenia technologii AI.</p> <h3 id="od-regulacji-do-współpracy-kształtowanie-przyszłości-ai"><strong>Od Regulacji do Współpracy: Kształtowanie Przyszłości AI</strong></h3> <p>Koncepcja interwencji rządowej w dziedzinie AI nie jest bez swoich krytyków. Skeptycy argumentują, że zaangażowanie rządu może hamować innowacje i utrudniać dynamiczny wzrost, który sektor prywatny jest w stanie osiągnąć. Jednak perspektywa Jenningsa przewartościowuje dyskurs. Zamiast wyobrażać sobie interwencję rządową jako duszącą siłę regulacyjną, przedstawia ją jako wspólny wysiłek w kierunku odpowiedzialnego kształtowania przyszłości AI.</p> <h3 id="podsumowanie-wezwanie-do-przemyślenia-przyszłości-ai"><strong>Podsumowanie: Wezwanie do Przemyślenia Przyszłości AI</strong></h3> <p>Wnioski Charlesa Jenningsa zachęcają do głębokiego przemyślenia przyszłości sztucznej inteligencji. W miarę jak AI kontynuuje swoją błyskawiczną karierę, jej potencjalny wpływ na społeczeństwo nie może być bagatelizowany. Wybór między kontrolą prywatną a interwencją rządową niesie głębokie implikacje dla naszej przyszłości technologicznej. Chociaż wyzwania są ogromne, nie są one nie do pokonania. W miarę jak zastanawiamy się, kto powinien dzierżyć ogromną moc AI, ważne jest, abyśmy podejście do tego dyskursu z umysłem otwartym, gotowością do innowacji i determinacją kształtowali przyszłość, w której AI służy zbiorowym interesom społeczeństwa.</p> <p>W końcu to nie tylko wybór między gigantami technologicznymi a rządem. To wezwanie do zjednoczenia sił obu światów - prywatnych innowacji i publicznego zarządzania - aby kierować AI ku przyszłości, która przynosi korzyści wszystkim. Skomplikowany taniec między złożonością a dynamicznością w dziedzinie zarządzania AI jest odzwierciedleniem złożonego oddziaływania perspektyw, pomysłów i potencjalnych rozwiązań. W miarę jak rozważamy drogę naprzód, pamiętajmy, że w krajobrazie AI nawet jedno głos - choćby niekonwencjonalny - może wywołać rozmowę prowadzącą do przełomowych zmian.</p> <p><em>Oświadczenie: Wyrażone w tym artykule opinie są wyłącznie zdaniem autora i niekoniecznie odzwierciedlają poglądy POLITICO ani żadnych powiązanych podmiotów.</em> Źródło: [POLITICO](<a href="https://politico-tech.simplecast.com/episodes/one-techs-bold-idea-ai-is-the-new-atomic-energy-nationalize-it">POLITICO</a>)</p>]]></content><author><name></name></author><category term="article"/><category term="rzad"/><category term="sztuczna-inteligencja"/><category term="ai"/><category term="llm"/><summary type="html"><![CDATA[Co powinny zrobić rządy w kwestii sztucznej inteligencji.]]></summary></entry><entry><title type="html">Jak uruchomić LLM lokalnie</title><link href="https://szymok.github.io/blog/2023/llm-local/" rel="alternate" type="text/html" title="Jak uruchomić LLM lokalnie"/><published>2023-08-01T07:01:45+00:00</published><updated>2023-08-01T07:01:45+00:00</updated><id>https://szymok.github.io/blog/2023/llm-local</id><content type="html" xml:base="https://szymok.github.io/blog/2023/llm-local/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/infidel0986_a_generative_AI_LLM_hot_air_balloon_with_business_p_82aac953-8aec-429d-b858-1c84f034be75-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/infidel0986_a_generative_AI_LLM_hot_air_balloon_with_business_p_82aac953-8aec-429d-b858-1c84f034be75-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/infidel0986_a_generative_AI_LLM_hot_air_balloon_with_business_p_82aac953-8aec-429d-b858-1c84f034be75-1400.webp"/> <img src="/assets/img/infidel0986_a_generative_AI_LLM_hot_air_balloon_with_business_p_82aac953-8aec-429d-b858-1c84f034be75.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Obraz wygenerowany przy pomocy Midjourney oraz edytowany w Photoshopie przy pomoocy funkcji Generate AI. </div> <h2 id="uruchamianie-modeli-llm-lokalnie-za-pomocą-biblioteki-dalai">Uruchamianie modeli LLM lokalnie za pomocą biblioteki Dalai</h2> <p>Czy kiedykolwiek zastanawiałeś się nad uruchomieniem zaawansowanych modeli językowych, takich jak ChatGPT, na swoim własnym komputerze? Nie jesteś w tej przygodzie sam! W tym przewodniku krok po kroku dowiemy się, jak to zrobić za pomocą modeli LLaMA i Alpaca, korzystając z biblioteki Dalai. Bądź gotowy na szczegółową, krok po kroku i interesującą podróż do świata AI!</p> <h3 id="czym-jest-biblioteka-dalai">Czym jest biblioteka Dalai?</h3> <p>Dalai to narzędzie opracowane przez Meta AI w celu umożliwienia użytkownikom korzystania z modeli językowych LLM na swoich własnych komputerach. Dzięki tej bibliotece, możemy wykorzystać modele LLM, takie jak LLaMA i Alpaca, w środowisku offline, co eliminuje konieczność korzystania z centralnych i często komercyjnych rozwiązań oferowanych przez duże firmy.</p> <h3 id="dostępność-jako-biblioteka-nodejs">Dostępność jako biblioteka Node.js</h3> <p>Dalai został stworzony jako biblioteka dla środowiska Node.js, co umożliwia łatwe i elastyczne wykorzystanie modeli LLM w aplikacjach opartych na tym środowisku. Jest to szczególnie korzystne dla programistów pracujących w języku JavaScript.</p> <h2 id="dylemat-lokalnej-sztucznej-inteligencji-nasza-własna-prywatna-ostoja">Dylemat lokalnej sztucznej inteligencji: Nasza własna prywatna ostoja</h2> <p>Mierzymy się z wieloma możliwościami, jakie model generatywnej sztucznej inteligencji nam przynosi. Jednak wraz z wielką mocą przychodzi wielka odpowiedzialność (dzięki, Wujek Ben). Jednym z największych obaw, które mamy, jest prywatność danych. Centralizowane modele oferowane przez OpenAI i Microsoft są fantastyczne, ale czy naprawdę chcemy oddać nasze dane na srebrnej tacy?</p> <p>Wyobraź sobie, że Batman musiałby podzielić się lokalizacją Batjaskini ze wszystkimi. Nie byłoby to zbyt fajne, prawda? Tutaj wchodzi w grę uruchomienie modelu AI na swoim lokalnym komputerze. To jak posiadanie swojej własnej Batjaskini (bez fajnych gadżetów i pojazdów w stylu nietoperza, oczywiście).</p> <p>Plusy uruchamiania LLM na maszynach lokalnych:</p> <ul><li>Prywatność danych: Jest to jedna z największych zalet uruchamiania modeli LLM na maszynach lokalnych. Korzystając z własnej infrastruktury, użytkownik ma większą kontrolę nad swoimi danymi i unika przekazywania ich do zewnętrznych serwerów lub chmur. Dla osób lub organizacji, które szczególnie dbają o prywatność danych, jest to kluczowe.</li> <li>Szybkość działania: Uruchamianie modeli LLM na lokalnych maszynach może być szybsze niż korzystanie z modeli działających w chmurze. Dzięki temu można uzyskać wyniki generowania tekstu błyskawicznie, bez opóźnień związanych z przesyłaniem danych do zdalnych serwerów.</li> <li>Brak opłat za korzystanie: Często korzystanie z modeli LLM w chmurze może być powiązane z opłatami, które rosną w miarę zwiększania ilości generowanego tekstu. Uruchamianie modeli lokalnie może pozwolić uniknąć tych kosztów i oszczędzić na długoterminowej współpracy.</li> <li>Modyfikowalność i dostosowywanie: Korzystając z maszyn lokalnych, użytkownik ma pełną kontrolę nad konfiguracją i dostosowaniem modeli LLM. Można zmieniać parametry, testować różne warianty modeli i dostosowywać je do swoich potrzeb.</li> </ul> <p>Minusy uruchamiania LLM na maszynach lokalnych:</p> <ul><li>Wymagania sprzętowe: Niektóre modele LLM, zwłaszcza te zaawansowane, mogą wymagać znacznych zasobów sprzętowych, takich jak duża ilość pamięci RAM czy mocny procesor. Uruchomienie ich na komputerze osobistym może być utrudnione lub niemożliwe ze względu na ograniczenia sprzętowe.</li> <li>Kompleksowość instalacji: Instalacja i konfiguracja modeli LLM na lokalnych maszynach może być skomplikowana, szczególnie dla osób bez doświadczenia w programowaniu czy obszarze sztucznej inteligencji. Wymaga to znalezienia odpowiednich wersji bibliotek, narzędzi i zależności, co może być czasochłonne i frustrujące.</li> <li>Brak skalowalności: Uruchomienie modelu LLM na maszynie lokalnej ogranicza skalowalność generowania tekstu. Jeśli potrzebujemy dużej ilości generowanego tekstu lub jednoczesnego dostępu wielu użytkowników, lokalne środowisko może nie być wystarczające.</li> <li>Ograniczona aktualizacja modeli: W porównaniu do korzystania z modeli LLM w chmurze, aktualizacje modeli mogą być trudniejsze do przeprowadzenia na maszynach lokalnych. Wymaga to ręcznej aktualizacji i utrzymania modelu, co może być problematyczne, gdy pojawią się nowe i ulepszone wersje modeli.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Screenshot%202023-08-01%20232108-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Screenshot%202023-08-01%20232108-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Screenshot%202023-08-01%20232108-1400.webp"/> <img src="/assets/img/Screenshot%202023-08-01%20232108.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Diagram z artykułu opublikowanego w magazynie Research on Foundation Models (CRFM) w Stanford. Źródło: <a href="https://crfm.stanford.edu/">CRFM</a> </div> <h2 id="llama-kompaktowy-potwór-stworzony-przez-meta-ai">LLaMA: Kompaktowy potwór stworzony przez Meta AI</h2> <p>LLaMA to podstawowy model językowy, który osiągnął coś niesamowitego. Mimo że jest 13 razy mniejszy od kolosalnego GPT-3, przewyższa ten ostatni na większości benchmarków! Ten kompaktowy potwór może być uruchamiany na lokalnych maszynach - jedna odważna jednostka nawet zdołała go uruchomić na Raspberry Pi!</p> <p>Teraz, dzięki pewnym nieprzewidzianym okolicznościom, LLaMA jest dostępny do użytku niekomercyjnego. Został stworzony przez utalentowany zespół w Meta AI, a LLaMA oraz jego “rodzeństwo” - Alpaca - sprawiają, że lokalne wykorzystanie sztucznej inteligencji staje się bardziej dostępne niż kiedykolwiek wcześniej. Więc, bez zbędnych zwłok, zaczynajmy tę wspaniałą podróż!</p> <p>Pierwszym z brzegu pomysłem na skorzystaniu z wymiarów Raspberry PI byłoby stworzenie stworzenie salonu, gdzie każde urządzenie polegałoby na osobnym modelu i użytkownicy mogliby się z nimi komunikować, jednocześnie tworząc wirtualną historie. Byłoby to o tyle ciekawe, że spędzenie pewnego czasu w tym lokalu, posunięcie historii dalej i pozostawienie jej w tym samym miejscu dla kolejnych klientów lokalu. W ten sposób każdy mógłby wnieść swój wkład w historię, a jednocześnie cieszyć się z tego, co stworzyli inni.</p> <h2 id="instalacja-i-uruchamianie-llama">Instalacja i uruchamianie LLaMA</h2> <p>Sklonuj repozytorium i zainstaluj niezbędne wymagania z https://gichub.com/cockroiJpeanuVdolai.</p> <p>Aby rozpocząć, uruchom polecenie:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">npx</span> <span class="n">dalaî</span> <span class="n">install</span> <span class="mi">7</span><span class="n">B</span>
</code></pre></div></div> <p>Zanim przejdziesz dalej, upewnij się, że LLaMA-7B potrzebuje około 31 GB pamięci. Sprawdź, czy na twoim komputerze jest wystarczająco dużo miejsca na tego małego, ale potężnego gościa. Sam miałem z tym sporo problemów!</p> <p>Aby uruchomić LLaMA, wystarczy wpisać:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">npx</span> <span class="n">dalai</span> <span class="n">serves</span>
</code></pre></div></div> <p>I to wszystko! Masz teraz duży model językowy działający lokalnie. Gratulacje! Dlaczego? Ponieważ musiałem przejść przez wiele trudności, aby to uruchomić, takie jak dopasowywanie określonych wersji Pythona i Node. Szczegóły możesz znaleźć w pliku Readme na stronie https://github.com/cocktailpeaonut/dalai.</p> <p>Jednak kiedy to uruchomiłem, otrzymałem mnóstwo bezsensownych ciągów liter w odpowiedzi na proste pytanie “Mam ochotę coś zjeść, ponieważ…”. Po dokładniejszym zbadaniu wygląda na to, że jest to znany problem. Ktoś w kanale dyskusji sugerował: “Sprawdź model Alpaca”, więc to zrobiłem.</p> <h2 id="alpaca-cudo-które-podąża-za-instrukcjami">Alpaca: Cudo, które podąża za instrukcjami</h2> <p>Alpaca to wersja fine-tuningowana LLaMA, zaprojektowana tak, aby podążała za instrukcjami, podobnie jak ChatGPT. Niesamowite jest to, że cały proces dopasowania kosztował mniej niż 600 dolarów! Porównując to z ogromną ceną 5 milionów dolarów za GPT-3.5, to prawdziwa okazja!</p> <p>Jak to osiągnięto? Model tekstu OpenAI - davinci-003 - nieświadomie pomógł, przekształcając 175 zadań samouczka w aż 52 000 przykładów podążających za instrukcjami do nadzorowanego dopasowania. Mówię o inteligentnym rozwiązaniu! Autorami tego niesamowitego modelu są Rohan Taori i inni. To takie kreatywne - praktycznie użyli da-vinci-03 jako nauczyciela dla LLaMA, aby stworzyć Alpacę! Całą pracę można znaleźć w artykule na stronie htps://crfm.stanford.edu/2023/03/13/alpaco.html</p> <h2 id="instalacja-i-uruchamianie-alpaca">Instalacja i uruchamianie Alpaca</h2> <p>Aby zainstalować Alpacę, wystarczy uruchomić:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">npx</span> <span class="n">dalai</span> <span class="n">alpaca</span> <span class="n">install</span> <span class="mi">78</span>
</code></pre></div></div> <p>Alpaca to lekki model, który wymaga tylko 4 GB pamięci, więc nie zajmie wiele miejsca na twoim komputerze. Aby uruchomić Alpacę, po prostu powtórz polecenie:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">npx</span> <span class="n">dalai</span> <span class="n">alpaca</span> <span class="n">serves</span>
</code></pre></div></div> <p>I gotowe! Masz teraz własny model ChatGPT, gotowy do działania!</p> <h2 id="wszechstronne-api-dalai">Wszechstronne API Dalai</h2> <p>To nie koniec zabawy - biblioteka Dalai oferuje również interfejs API, który umożliwia integrację zarówno LLaMA, jak i Alpaki w twoje własne aplikacje. Otwiera to świat możliwości dla innowacyjnych projektów i eksperymentów na twoim lokalnym komputerze.</p> <p>Pomyśl o stworzeniu swojego własnego chatbota opartego na sztucznej inteligencji, budowaniu inteligentnego asystenta do pisania czy nawet opracowaniu nauczyciela AI dla twojego ulubionego przedmiotu! Teraz, kiedy nie jesteś ograniczony do 32 tysięcy słów, możesz karmić modele wszystkimi klasykami napisanymi przez swojego ulubionego autora (który już nie żyje, aby dać nam więcej magicznych dzieł).</p> <p>Baw się dobrze z lokalnymi modelami LLM i ciesz się wspaniałymi możliwościami, jakie oferują. Sztuczna inteligencja staje się coraz bardziej dostępna, co pozwala nam na bardziej kreatywną i interesującą pracę z modelami językowymi na naszych własnych komputerach.</p>]]></content><author><name></name></author><category term="article"/><category term="AI"/><category term="sztuczna-inteligencja"/><category term="generatywne-ai"/><category term="llm"/><category term="llama"/><category term="alpaca"/><summary type="html"><![CDATA[Krótki artykuł o tym jak uruchomić LLM lokalnie.]]></summary></entry><entry><title type="html">AWS a linie lotnicze, jak to działa?</title><link href="https://szymok.github.io/blog/2023/aws-airport/" rel="alternate" type="text/html" title="AWS a linie lotnicze, jak to działa?"/><published>2023-06-25T08:42:12+00:00</published><updated>2023-06-25T08:42:12+00:00</updated><id>https://szymok.github.io/blog/2023/aws-airport</id><content type="html" xml:base="https://szymok.github.io/blog/2023/aws-airport/"><![CDATA[<h2 id="wstęp">Wstęp</h2> <p>Choć to historia mogłaby wydawać się jak scena z filmu, jest to tylko wymyślony scenariusz, stworzony na potrzeby tego artykułu. Celem tego opisu jest zilustrowanie, jak łatwo można przegapić lot, gdy nie jesteśmy świadomi konsekwencji niezauważenia upływu czasu na lotnisku.*</p> <p>Grupa przyjaciół przybyła na Lotnisko Chopina w Warszawie z dużym wyprzedzeniem przed planowanym odlotem. Byli podekscytowani zbliżającą się podróżą do Nowego Jorku - mieli spędzić tam dwa tygodnie, zwiedzając miasto i ciesząc się amerykańskim stylem życia. Po odprawie bagażu, kontroli bezpieczeństwa i przepustkach imigracyjnych, zdecydowali się na krótki odpoczynek w jednej z restauracji lotniska.</p> <p>Czas mijał niezauważenie, kiedy rozmawiali, jedli i śmiali się, nieświadomi tego, że ich samolot miał odlecieć za niecałą godzinę. Gdy w końcu spojrzeli na zegarek, zrozumieli, że nie mają już czasu na luzie dotrzeć do bramki. Zgromadzili swoje rzeczy i w pośpiechu ruszyli w kierunku bramki.</p> <p>Linie lotnicze rozpoczęły procedurę wejścia na pokład na godzinę przed planowanym odlotem, a ta zakończyła się w ciągu 30 minut. Jednak grupa przyjaciół była nadal nieobecna. Mimo wielokrotnych ogłoszeń, aby zgromadzili się przy bramce, nie było żadnej reakcji. Pracownik linii lotniczych, nie mogąc ich znaleźć, poinformował o tym swoich przełożonych. Bramka została zamknięta, a samolot wystartował 10 minut przed planowanym odlotem.</p> <p>Grupa przyjaciół dotarła do bramki 5 minut przed planowanym odlotem. Z przerażeniem zobaczyli, że bramka jest już zamknięta, a samolot zaczyna się oddalać. Zrozumieli, że przegapili swój lot. Byli załamani, że ich długo planowane wakacje zostały nagle zrujnowane.</p> <p>Podszedł do nich pracownik lotniska i wyjaśnił, że powinni byli być przy bramce co najmniej 30 minut przed odlotem. Z ciężkim sercem zarezerwowali nocleg w hotelu lotniskowym, zdecydowani na złapanie następnego lotu do Nowego Jorku.</p> <p>Tak jak w wielu przypadkach, przegapienie lotu przez tę grupę przyjaciół to kolejny przykład na to, jak łatwo można przecenić czas potrzebny na dotarcie do bramki, zwłaszcza jeżeli przemawiają do nas różnego rodzaju rozproszenia.</p> <hr/> <h2 id="wyzwania-związane-z-bookowaniem-lotów">Wyzwania związane z bookowaniem lotów</h2> <p>Nie jest rzadkością, że pasażerowie spóźniają się na swój lot, nawet po otrzymaniu karty pokładowej, jak mogliśmy zobaczyć w powyższej anegdocie. Istnieje kilka powodów, dlaczego tak się dzieje.</p> <ul> <li> Niedoszacowanie wymaganego czasu: Pasażerowie mogą nie zdawać sobie sprawy, ile czasu potrzebują, aby dotrzeć do bramki, zwłaszcza jeśli nie znają lotniska lub mają do pokonania duże odległości. Mogą również niedoszacować czasu potrzebnego na kontrole bezpieczeństwa i inne procedury.</li> <li> Opóźnienia lotów: Nawet jeśli została wydana karta pokładowa, loty mogą być opóźnione z różnych powodów, takich jak pogoda, problemy techniczne lub zator ruchu lotniczego. Pasażerowie mogą nie zdawać sobie sprawy, że ich lot został opóźniony i przegapić czas wejścia na pokład.</li> <li> Wolne wejście na pokład: Proces wejścia na pokład może potrwać długo, zwłaszcza jeśli pasażerowie nie stosują się do instrukcji linii lotniczych. To może prowadzić do opóźnień, utraty połączeń i innych problemów.</li> <li> Problemy z bezpieczeństwem: Pasażerowie mogą mieć problemy z bezpieczeństwem, takie jak niemożność zabrania określonych przedmiotów na pokładzie lub konieczność dodatkowej kontroli. To może powodować opóźnienia.</li> <li> Problemy komunikacyjne: Linie lotnicze mogą nie dostarczać jasnych instrukcji ani nieefektywnie komunikować się z pasażerami podczas procesu wejścia na pokład. Nagłe zmiany bramek mogą prowadzić do zamieszania i opóźnień.</li> </ul> <p>Interesujące jest, że w ostatnich latach lotniska na całym świecie wprowadzają nowoczesne technologie, takie jak sztuczna inteligencja, chmura obliczeniowa i uczenie maszynowe, aby zapobiec sytuacjom, w których pasażerowie przegapiają swoje loty. Dzięki wykorzystaniu zaawansowanych algorytmów i analizie danych, te technologie mogą pomóc w zoptymalizowaniu procesów lotniskowych i minimalizacji opóźnień.</p> <p>Przykładem jest wykorzystanie sztucznej inteligencji do prognozowania czasu potrzebnego na przejście przez kontrolę bezpieczeństwa. Za pomocą analizy danych historycznych, algorytmy mogą przewidzieć, jak długo zajmie pasażerom przejście przez kontrolę i ustalić optymalne czasy przybycia na lotnisko.</p> <p>Chmura obliczeniowa jest również wykorzystywana do przechowywania i przetwarzania ogromnych ilości danych związanych z lotniskami. Dzięki temu, informacje o lotach, pasażerach, bagażach i innych czynnikach mogą być łatwo dostępne i szybko przetwarzane, co pozwala na lepsze zarządzanie operacjami lotniska.</p> <p>Uczenie maszynowe również odgrywa istotną rolę w zapobieganiu przegapieniu lotów. Algorytmy uczą się na podstawie danych historycznych i aktualnych, identyfikują wzorce i czynniki ryzyka, które mogą prowadzić do opóźnień lub przegapienia lotu. Dzięki temu, systemy mogą ostrzegać personel lotniska i pasażerów o potencjalnych problemach i proponować działania zaradcze.</p> <p>To fascynujące, jak nowoczesne technologie mogą pomóc w poprawie doświadczenia podróżowania lotniczego i minimalizacji ryzyka przegapienia lotu. Warto śledzić rozwój tych rozwiązań i być na bieżąco z innowacjami w branży lotnictwa.</p> <hr/> <h2 id="możliwości-jakie-daje-ai-i-ml">Możliwości jakie daje AI i ML</h2> <p>Sztuczna inteligencja i uczenie maszynowe mogą pomóc w rozwiązaniu większości z powyższych problemów. Wykorzystajmy tę samą anegdotę, aby zobaczyć jak.</p> <p>Podróżująca grupa przyjaciół z niecierpliwością czekała na wizytę u swojej rodziny w Ameryce przez wiele miesięcy. Przybyła na lotnisko w Dubaju na cztery godziny przed swoim lotem, odprawiła bagaż i przeszła przez kontrole imigracyjne i bezpieczeństwa. Ponieważ miała kilka godzin do wylotu, postanowiła zrobić trochę zakupów i zjeść coś. Jednak straciła poczucie czasu i nie wiedziała, że powinna dotrzeć do bramki na 30 minut przed planowanym odlotem samolotu.</p> <p>Na szczęście lotnisko miało system bookingu oparty na AI, który gwarantował bezproblemowe bookowanie wszystkich pasażerów. System ten wykorzystywał Internet rzeczy (IoT) i uczenie maszynowe do śledzenia ruchów pasażerów na lotnisku i szacowania ich czasu przybycia do bramki.</p> <p>Kiedy system przewidział, że przyjaciele mogą się spóźnić, natychmiast zaalarmował pracowników bramki i personel linii lotniczych, aby ich zlokalizować. System ten wykorzystywał technologię rozpoznawania twarzy i inne technologie śledzenia, aby precyzyjnie zlokalizować ich miejsce na lotnisku, a w ciągu kilku minut pracownik lotniska był w stanie ich znaleźć i odprowadzić do bramki.</p> <p>Spóźnieni mogli bezproblemowo wejść na pokład swojego lotu, a także cieszyć się zrobionymi zakupami - wszystko to dzięki bezproblemowemu i efektywnemu procesowi bookingu, który umożliwiły AI, IoT i uczenie maszynowe.</p> <p>Fakty są takie, że technologia AI i uczenie maszynowe stają się coraz bardziej niezbędne w świecie lotnictwa. Możemy oczekiwać, że tego typu systemy staną się coraz bardziej powszechne w przyszłości, zapewniając lepszą organizację i wygodę dla pasażerów. Ciekawe jest to, jak technologia może przekształcić prozaiczne zadania, takie jak czekanie na lot, w bardziej przyjemne i bezstresowe doświadczenia. W przyszłości możemy spodziewać się jeszcze więcej innowacyjnych rozwiązań z wykorzystaniem AI, IoT i uczenia maszynowego w branży lotniczej.</p> <hr/> <h2 id="aws-ai-ml-analiza-danych-i-iot-w-branży-lotniczej">AWS: AI, ML, analiza danych i IoT w branży lotniczej</h2> <p>Opisane powyżej bezproblemowe bookowanie na lot można łatwo zrealizować, wykorzystując usługi AWS Cloud. Dostępnych jest wiele urządzeń IoT, które mogą śledzić ruchy pasażera czy personelu lotniczego za pomocą geofencingu i BLE (Bluetooth o niskim zużyciu energii).</p> <p>Na przykład, beacony mogą pokryć obszar od 5m do 2,5km. Wysyłają one sygnały do urządzeń, takich jak telefony komórkowe, które są mapowane z ich lokalizacją. Te informacje są przechowywane w AWS RDS, co pomaga w detekcji lokalizacji pasażera. Można także wykorzystać kamery do śledzenia ruchów.</p> <p>AWS oferuje szereg usług AI, ML, analizy danych i IoT (Internet rzeczy), które można wykorzystać do budowania inteligentnych i opartych na danych aplikacji.</p> <p>Do stworzenia bezproblemowego rozwiązania bookowania na lot można wykorzystać następujące usługi:</p> <ul> <li> Amazon SageMaker: To kompleksowo zarządzana usługa, która dostarcza deweloperom i naukowcom narzędzi do budowania, trenowania i wdrażania modeli uczenia maszynowego na dużą skalę.</li> <li> Amazon Rekognition: Usługa analizy obrazów i wideo oparta na głębokim uczeniu, która może wykrywać obiekty, twarze i tekst na obrazach i wideo.</li> <li> Amazon Comprehend: Usługa przetwarzania języka naturalnego, która może analizować tekst i wydobywać z niego informacje takie jak sentyment, jednostki i kluczowe frazy.</li> <li> Amazon Polly: Usługa text-to-speech, która może przekształcać tekst w realistyczne mowy w wielu językach i głosach.</li> <li> Amazon Translate: Usługa tłumaczenia maszynowego oparta na sieciach neuronowych, która może tłumaczyć tekst między językami z dużą precyzją.</li> <li> Amazon Transcribe: Usługa automatycznego rozpoznawania mowy, która może transkrybować pliki audio i wideo na tekst.</li> <li> Amazon Forecast: Kompleksowo zarządzana usługa prognozowania, która wykorzystuje uczenie maszynowe do dostarczania wysoce precyzyjnych prognoz.</li> <li> Amazon Personalize: Usługa, która zapewnia rekomendacje w czasie rzeczywistym dotyczące treści, produktów i usług, wykorzystując algorytmy uczenia maszynowego.</li> </ul> <hr/> <h2 id="amazon-sagemaker---budowanie-trenowanie-i-wdrażanie-modeli-uczenia-maszynowego">Amazon SageMaker - budowanie, trenowanie i wdrażanie modeli uczenia maszynowego</h2> <p>Amazon SageMaker to potężna platforma uczenia maszynowego z standardowym interfejsem, która dostarcza kompletny zestaw narzędzi i usług do szybkiego budowania, trenowania i wdrażania modeli uczenia maszynowego na dużą skalę. SageMaker wykorzystuje kontenery do opakowania ulubionych algorytmów i frameworków, w tym wbudowanych algorytmów takich jak XGBoost, DeepAR i FM, a także frameworków takich jak PyTorch, SKLearn i TensorFlow.</p> <p>Niektóre z kluczowych usług dostarczanych przez Amazon SageMaker to:</p> <ul> <li>Etykietowanie danych: Ground Truth w SageMakerze to w pełni zarządzana usługa etykietowania danych, która ułatwia etykietowanie zestawów danych za pomocą anotatorów ludzkich lub wbudowanych modeli uczenia maszynowego.</li> <li>Budowanie modeli: SageMaker oferuje szereg wbudowanych algorytmów i frameworków do budowania, trenowania i wdrażania modeli uczenia maszynowego. Obsługuje także tworzenie niestandardowych algorytmów przy użyciu popularnych frameworków takich jak TensorFlow, MXNet i PyTorch.</li> <li>Trenowanie modeli: SageMaker zapewnia skalowalne i rozproszone środowisko treningowe (z wykorzystaniem GPU i wielu instancji), które pomaga w trenowaniu efektywnych modeli uczenia maszynowego na dużych zbiorach danych.</li> <li>Hostowanie modeli: SageMaker zapewnia w pełni zarządzane środowisko hostowania modeli, umożliwiające deweloperom wdrażanie modeli uczenia maszynowego jako interfejsy API z automatycznym skalowaniem, monitorowaniem i możliwością debugowania.</li> <li>Tuning modeli: Amazon SageMaker oferuje usługę automatycznego strojenia modeli, która umożliwia naukowcom danych optymalizację hiperparametrów i poprawę dokładności modelu bez konieczności ingerencji manualnej.</li> <li>Wnioskowanie w czasie rzeczywistym: SageMaker zapewnia w pełni zarządzaną, wysoko dostępną usługę wnioskowania w czasie rzeczywistym, która może skalować się, aby obsłużyć miliony żądań na sekundę.</li> <li>Wnioskowanie wsadowe: Amazon SageMaker dostarcza w pełni zarządzaną usługę wnioskowania wsadowego, która może przetwarzać duże ilości danych i dostarczać predykcje w sposób kosztowo efektywny. Pełny workflow uczenia maszynowego: Amazon SageMaker zapewnia pełen workflow uczenia maszynowego, obejmujący przygotowanie danych, inżynierię cech, trening modelu, wdrażanie i monitorowanie.</li> <li>Integracja z innymi usługami AWS: Amazon SageMaker integruje się z innymi usługami AWS, takimi jak S3, Lambda, Step Functions i CloudFormation, aby zapewnić spójne doświadczenie z uczeniem maszynowym. Dzięki usługom Amazon SageMaker lotniska mogą skutecznie budować, trenować i wdrażać modele uczenia maszynowego, a także obsługiwać wnioskowanie w czasie rzeczywistym i wsadowe. To zapewnia płynne i efektywne procesy związane z analizą danych i predykcją, co ma zastosowanie w liniach lotniczych.</li> </ul> <hr/> <h2 id="rola-usług-aws-rekognition-iot-core-i-greengrass">Rola usług AWS Rekognition, IoT Core i Greengrass</h2> <p>W oparciu o infrastrukturę IoT, beacony i kamery mogą być zainstalowane w całym terminalu lotniska w celu wykrywania ruchów pasażerów. AWS Greengrass może być wykorzystany do wdrażania funkcji AWS Lambda, które przechwytują obrazy z lokalnych kamer/czujników i wysyłają je do AWS Rekognition w celu analizy. Kamery mogą przechwytywać obrazy lub nagrania wideo w regularnych odstępach czasu (co 5/10 sekund) i wysyłać je do bramy AWS IoT.</p> <p>Zdolność do rozpoznawania twarzy w usłudze AWS Rekognition może być wykorzystana do analizy obrazów lub nagrań wideo, wykrywania obecności poszczególnych pasażerów oraz śledzenia ich ruchów. Na podstawie wyników analizy można generować alerty i wysyłać powiadomienia, jeśli w określonym obszarze występuje duże zagęszczenie pasażerów lub zatory, lub jeśli pasażer porusza się w kierunku niewłaściwej bramki.</p> <p>Wyniki analizy mogą być przesyłane z powrotem do AWS Greengrass w celu dalszej obróbki lub podjęcia działań, takich jak uruchamianie lokalnych alarmów lub wysyłanie powiadomień. Dzięki temu systemowi możliwe jest bieżące monitorowanie ruchu pasażerów w terminalu lotniska, identyfikowanie problematycznych obszarów lub sytuacji oraz podejmowanie odpowiednich działań w celu zapewnienia płynnego przebiegu procesu zaokrętowania.</p> <hr/> <h2 id="tworzenie-opartego-na-aiml-rozwiązania-do-obsługi-lotu">Tworzenie opartego na AI/ML rozwiązania do obsługi lotu</h2> <p>Nasze rozwiązanie wykorzystuje algorytm XGBoost do binarnej klasyfikacji, popularny wybór do przewidywania wystąpienia zdarzenia na podstawie zestawu cech wejściowych. Staramy się przewidzieć, czy pasażer, który odprawił bagaż i robi zakupy, dotrze do bramki wejściowej 30 minut przed planowym czasem odlotu lotu. Wbudowany algorytm XGBoost w SageMaker ułatwia trenowanie i wdrażanie potężnych modeli uczenia maszynowego. Dzięki niewielkiemu przygotowaniu danych i dostrojeniu hiperparametrów, budowanie modeli, które szybko dokonują dokładnych prognoz w różnych zadaniach, jest prostym procesem. SageMaker dostarcza Jupyter Notebook w chmurze, który jest łatwy w tworzeniu i używaniu. Oto kroki postępowania:</p> <ul> <li>Przygotowanie danych: Nasze dane powinny być w formacie, z którym XGBoost może pracować. Zazwyczaj oznacza to plik CSV z kolumnami dla cech i kolumną docelową dla etykiety.</li> <li>Przesyłanie danych: Musimy przesłać dane do kubełka S3, aby SageMaker mógł na niego uzyskać dostęp.</li> <li>Tworzenie zadania trenującego: Możemy utworzyć zadanie trenujące, określając lokalizację danych treningowych w S3/Datalake oraz hiperparametry, których chcemy użyć dla algorytmu XGBoost. Można to zrobić za pośrednictwem konsoli SageMaker, pakietu SDK SageMaker lub AWS CLL.</li> <li>Monitorowanie zadania trenującego: Po rozpoczęciu zadania trenującego możemy monitorować jego postęp za pośrednictwem konsoli SageMaker lub pakietu SDK.</li> <li>Wdrażanie modelu: Po zakończeniu zadania trenującego możemy wdrożyć wytrenowany model jako punkt końcowy, który może być używany do wnioskowania.</li> <li>Testowanie modelu: Możemy przetestować wdrożony model, wysyłając nowe dane i obserwując predykcje, które generuje.</li> </ul> <h3 id="dane-wejściowe">Dane wejściowe</h3> <p>Dane wejściowe dla naszego modelu składają się z zestawu cech dotyczących ruchu pasażera w obrębie lotniska, jego zachowania podczas zakupów i czasu przybycia na lotnisko. Te cechy są zbierane za pomocą urządzeń IoT, takich jak kamery, beacons i czujniki rozmieszczone w całym lotnisku.</p> <p>Oto cechy wejściowe, które zostały użyte w naszym modelu:</p> <ul> <li>Czas przybycia: Dane dotyczące czasu, o którym pasażer przybywa na lotnisko, są zbierane od pasażerów, którzy już dokonali odprawy online. Czujniki IoT przy wejściu na lotnisko zbierają te dane i przekazują je do magazynu danych. Dla pasażerów, którzy nie dokonali odprawy online, dane te są gromadzone na stanowisku odprawy lub w automacie, z którego otrzymuje się kartę pokładową.</li> <li>Stan pasażera: Informuje, czy pasażer przeszedł kontrolę imigracyjną, kontrolę bezpieczeństwa, odprawę itp.</li> <li>Czas trwania zakupów: To jest czas, jaki pasażerowie spędzają na zakupach po otrzymaniu karty pokładowej i po przejściu kontroli imigracyjnej/bezpieczeństwa.</li> <li>Odległość od bramki: To jest odległość między strefą zakupów a bramką wejściową i jest obliczana za pomocą czujników IoT rozmieszczonych w całej strefie wolnocłowej.</li> <li>Czas przybycia na bramkę: To jest czas, o którym pasażer dociera na bramkę wejściową.</li> <li>Czas przewidywania będzie stale aktualizowany w innym rejestrze, aż pasażer dotrze do bramki wejściowej. Ciągłe alertowanie wiadomości zostanie wysłane na telefon komórkowy/smartfon pasażera oraz do sprzedawcy znajdującego się w pobliżu pasażera. W odpowiednim czasie zostanie poproszona o pomoc sprzedawcy w celu poinformowania pasażera o konieczności przemieszczenia się w kierunku bramki, aby wejść na pokład samolotu. Na telewizorze również pojawi się informacja dla pasażera o konieczności przemieszczenia się w kierunku bramki. Pasażer zostanie również oznaczony na mediach społecznościowych i poproszony o przemieszczenie się w kierunku bramki. Wszystko to będzie działo się automatycznie dzięki różnym usługom AWS AI/ML, IoT i innym.</li> <li>Planowany czas odlotu: To jest zaplanowany czas odlotu lotu pasażera.</li> <li>Opóźnienie lotu: Wskazuje opóźnienie w zaplanowanym czasie odlotu lotu pasażera.</li> <li>Wzorzec chodu: Jest to wzorzec chodu zarejestrowany za pomocą urządzenia noszonego przez pasażera lub smartfona. Jeśli nie jest dostępny, zostanie użyta wartość domyślna.</li> <li>Bagaż podręczny: Te dane będą zbierane podczas odprawy, ale mogą być niejednoznaczne ze względu na dodawanie zakupów.</li> <li>Zatłoczenie terminala: To jest miara zajętości terminala w chwili przybycia pasażera na lotnisko i na drodze do bramki. Na urządzeniu smartfona pasażera wyświetlany będzie również mapę cieplną.</li> </ul> <h3 id="przygotowanie-danych">Przygotowanie danych</h3> <p>Przed przystąpieniem do trenowania modelu przeprowadziliśmy kilka kroków przygotowawczych, jak następuje:</p> <p><b>Czyszczenie:</b> Usuwanie nieprawidłowych lub brakujących danych.</p> <p><b>Przetwarzanie wstępne:</b> Skalowanie cech liczbowych, aby mieć tę samą skalę, i normalizacja danych w celu poprawy wydajności modelu.</p> <p><b>Inżynieria cech:</b> Tworzenie nowych cech na podstawie istniejących danych w celu poprawy dokładności modelu.</p> <h3 id="trenowanie-i-wdrożenie-modelu">Trenowanie i wdrożenie modelu</h3> <p>Po przygotowaniu danych użyliśmy wbudowanego algorytmu XGBoost w Amazon SageMaker do trenowania naszego modelu klasyfikacji binarnej. Następnie wdrożyliśmy wytrenowany model za pomocą usługi wdrożenia modelu SageMaker, która automatycznie skaluje model, aby obsłużyć duże ilości ruchu.</p> <h3 id="integracja-z-urządzeniami-iot">Integracja z urządzeniami IoT</h3> <p>Następnie zintegrowaliśmy wdrożony model uczenia maszynowego z urządzeniami IoT, takimi jak kamery i czujniki, aby monitorować ruchy pasażerów i przewidywać ich czasy przybycia na bramkę.</p> <p><b>System alarmowy:</b> Do zbudowania systemu alarmowego użyliśmy usługi Amazon Simple Notification Service (SNS), aby powiadamiać agentów bramkowych i personel linii lotniczych, gdy pasażerom przewidywane jest spóźnienie.</p> <p><b>System śledzenia:</b> Do zbudowania systemu śledzenia użyliśmy rozpoznawania twarzy i innych technologii śledzenia, aby zlokalizować pasażerów, którzy mają przewidywane opóźnienie i eskortować ich do bramki.</p> <p>W sumie ta implementacja analizy predykcyjnej za pomocą SageMaker może pomóc liniom lotniczym optymalizować proces wejścia na pokład, przewidując, którzy pasażerowie mogą być zagrożeni spóźnieniem i podejmując proaktywne kroki, aby zapewnić, że dotrą na czas do bramki.</p> <h2 id="podsumowanie">Podsumowanie</h2> <p>Usługi AWS oferują różnorodne narzędzia i rozwiązania, które mogą zrewolucjonizować sposób działania lotnisk, prowadząc do znaczących popraw w obszarach efektywności, doświadczenia pasażera, bezpieczeństwa i zrównoważonego rozwoju. AWS IoT może usprawniać zarządzanie przepływem pasażerów, podczas gdy usługi uczenia maszynowego, takie jak Amazon SageMaker, mogą pomóc w przewidywaniu potencjalnych usterek w sprzęcie lotniskowym. Amazon Rekognition umożliwia bezproblemową odprawę i zwiększa bezpieczeństwo, a śledzenie bagażu w czasie rzeczywistym dzięki AWS IoT poprawia doświadczenia pasażerów. Z usługami analitycznymi AWS, takimi jak Amazon Redshift i Amazon Quicksight, lotniska mogą analizować ogromne ilości danych i podejmować świadome decyzje. Bezpieczne połączenia zapewnia AWS Direct Connect, a planowanie zasobów lotniska staje się bardziej efektywne dzięki mocy obliczeniowej chmury AWS. Zrównoważony rozwój jest również na wyciągnięcie ręki, dzięki zobowiązaniu Amazon do osiągnięcia 100% odnawialnego zużycia energii dla swojej globalnej infrastruktury.</p>]]></content><author><name></name></author><category term="article"/><category term="analiza-danych"/><category term="aws"/><category term="amazon"/><category term="s3"/><category term="lambda"/><category term="airport"/><category term="lotnisko"/><category term="technologia"/><category term="ai"/><category term="machine-learning"/><summary type="html"><![CDATA[Krótkie przedstawienie usług AWS, które pomagają w przypadku problemów na lotnisku.]]></summary></entry><entry><title type="html">Historia wizualizacji danych</title><link href="https://szymok.github.io/blog/2023/history-visualization/" rel="alternate" type="text/html" title="Historia wizualizacji danych"/><published>2023-06-11T11:59:00+00:00</published><updated>2023-06-11T11:59:00+00:00</updated><id>https://szymok.github.io/blog/2023/history-visualization</id><content type="html" xml:base="https://szymok.github.io/blog/2023/history-visualization/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/History-of-Data-Visualization-11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/History-of-Data-Visualization-11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/History-of-Data-Visualization-11-1400.webp"/> <img src="/assets/img/History-of-Data-Visualization-11.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Diagram nawiązujący do wizualizacji danych i historii. Źródło: <a href="https://www.researchgate.net/publication/221027352_Data_Mining_and_Data_Visualization" target="_blank">ResearchGate</a> </div> <h2 id="historia-wizualizacji-danych">Historia wizualizacji danych</h2> <p>Wizualizacja danych ma długą i fascynującą historię, sięgającą głęboko w przeszłość. Od prymitywnych malowideł naskalnych po dzisiejsze zaawansowane narzędzia komputerowe, wizualizacja danych odegrała znaczącą rolę w rozwijaniu naszego zrozumienia informacji i przedstawianiu jej w sposób zarówno atrakcyjny, jak i efektywny. W pierwszym rozdziale tej książki przyjrzymy się początkom wizualizacji danych i dowiemy się, jak nasza zdolność do przedstawiania informacji wizualnie ewoluowała na przestrzeni wieków.</p> <p>Nasza historia wizualizacji danych rozpoczyna się w odległej przeszłości, gdy ludzie odkrywali potrzebę przedstawiania danych w formie graficznej. Już tysiące lat temu nasi przodkowie stosowali prymitywne techniki, aby przekazać informacje wizualnie. Malowidła naskalne, hieroglify i piktogramy były pierwszymi krokami w procesie tworzenia graficznych reprezentacji danych. Te wczesne formy wizualizacji pomagały w komunikacji, dzieleniu się historiami i gromadzeniu wiedzy.</p> <p>Wraz z upływem czasu ludzie doskonalili swoje umiejętności w tworzeniu coraz bardziej zaawansowanych form wizualizacji danych. W średniowieczu powstały mapy, które umożliwiały przedstawienie geograficznych informacji w sposób czytelny i intuicyjny. W renesansie naukowcy i matematycy opracowywali wykresy i diagramy, które pomagały w analizowaniu danych liczbowych i zrozumieniu złożonych zależności.</p> <p>Jednak prawdziwa rewolucja w dziedzinie wizualizacji danych nastąpiła wraz z rozwojem technologii komputerowej. W drugiej połowie XX wieku powstały pierwsze programy komputerowe, które umożliwiły tworzenie interaktywnych grafik, wykresów i diagramów. Przy użyciu komputera, dane mogły być przedstawiane w sposób bardziej precyzyjny, elastyczny i efektywny niż kiedykolwiek wcześniej.</p> <p>W pierwszym części naszej podróży po historii wizualizacji danych zgłębimy te fascynujące etapy rozwoju. Będziemy badać ewolucję od prymitywnych rysunków naskalnych do zaawansowanych narzędzi wizualizacyjnych dostępnych obecnie. Przyjrzymy się kluczowym postaciom i przełomowym momentom, które wpłynęły na rozwój tej dziedziny.</p> <hr/> <h2 id="początki-wizualizacji-danych">Początki wizualizacji danych</h2> <p>“Pierwsze próby wizualizacji danych sięgają czasów prehistorycznych” - to zdanie rozbudza moją ciekawość. Był to okres, kiedy ludzie używali malowideł naskalnych i rysunków do przedstawienia informacji. Fascynujące jest to, jak nasi przodkowie z epoki kamienia potrafili przekazywać skomplikowane koncepty za pomocą prostych form wyrazu.</p> <p>Dla przykładu, jednym z najstarszych znanych dowodów na wizualizację danych jest malowidło naskalne odkryte w jaskini Lascaux we Francji. Te malunki, które datuje się na około 17 000 lat temu, przedstawiają różne zwierzęta, takie jak byki i konie, a także symboliczne znaki, które mogły reprezentować liczby czy zmiany pór roku. <a href="https://www.lascaux.fr/en">oficjalna strona jaskini Lascaux</a>, na której znajdują się informacje na temat prehistorycznych malowideł.</p> <p>Zauważalne jest, że ta prymitywna forma wizualizacji danych posiadała w sobie zarówno aspekt artystyczny, jak i informatyczny. Dzięki temu dzisiaj możemy dowiedzieć się więcej o życiu tych prehistorycznych ludzi - od ich codziennych zajęć, poprzez to, co jedli, aż do jakich zwierząt obawiali się najbardziej.</p> <p>Ciekawostką jest również fakt, że niektóre z tych malowideł mogą być wcześniejszymi formami map. Np. malowidło naskalne w jaskini w Bedeilhac w południowej Francji, które ma około 14 000 lat, zawiera układ linii i kropek, który według niektórych badaczy może przedstawiać okoliczne tereny.</p> <p>Jeśli chodzi o grafy z tego okresu, nie były one skomplikowane jak dzisiejsze wykresy słupkowe czy kołowe, ale z pewnością można zauważyć próbę przedstawienia pewnych wzorców i trendów. Na przykład, rysunki w jaskiniach często przedstawiały zwierzęta w różnych fazach ruchu, co mogło sugerować migracje tych gatunków w określonym czasie roku.</p> <p>Choć metody wizualizacji danych z tamtych czasów mogą wydawać nam się dziś prymitywne, stanowiły one podstawę dla rozwoju tej dziedziny, jaki widzimy obecnie. Wzory, symbole i obrazy wykorzystywane przez naszych przodków nie tylko pomagały im przetrwać, ale również przekazywały ważne informacje przyszłym pokoleniom.</p> <hr/> <h3 id="william-playfair-ojciec-współczesnej-wizualizacji-danych">William Playfair: Ojciec współczesnej wizualizacji danych</h3> <p>Playfair, szkocki ekonomista i inżynier, to postać, której nie da się pominąć, mówiąc o historii wizualizacji danych. To on w XVIII wieku wprowadził wykresy liniowe, słupkowe i kołowe jako narzędzia do prezentacji danych statystycznych.</p> <p>Jego dzieło “Commercial and Political Atlas” z 1786 roku jest uznawane za pierwsze znane zastosowanie wykresu liniowego do reprezentowania danych. Playfair zauważył, że wykresy mogą “przemawiać” do odbiorców bardziej bezpośrednio niż surowe liczby, pomagając im lepiej zrozumieć i zinterpretować dane.</p> <p>Dzięki innowacjom Playfaira wizualizacja danych stała się bardziej dostępna i zrozumiała. Wykresy liniowe, słupkowe i kołowe stały się podstawą analizy danych, a ich wpływ jest widoczny nawet w dzisiejszych narzędziach do wizualizacji danych.</p> <p>Poniżej znajduje się kilka przykładów wykresów, które Playfair stworzył w swojej książce “Commercial and Political Atlas”. Zauważ, jak wykresy te są podobne do tych, które tworzymy dzisiaj.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/1073px-1786_Playfair_-_Exports_and_Imports_of_Scotland_to_and_from_different_parts_for_one_Year_from_Christmas_1780_to_Christmas_1781-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/1073px-1786_Playfair_-_Exports_and_Imports_of_Scotland_to_and_from_different_parts_for_one_Year_from_Christmas_1780_to_Christmas_1781-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/1073px-1786_Playfair_-_Exports_and_Imports_of_Scotland_to_and_from_different_parts_for_one_Year_from_Christmas_1780_to_Christmas_1781-1400.webp"/> <img src="/assets/img/1073px-1786_Playfair_-_Exports_and_Imports_of_Scotland_to_and_from_different_parts_for_one_Year_from_Christmas_1780_to_Christmas_1781.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Na tym wykresie słupkowym przedstawiono import i eksport Szkocji z i do 17 krajów w 1781 roku. Źródło: <a href="https://en.wikipedia.org/wiki/William_Playfair#/media/File:1786_Playfair_-_Exports_and_Imports_of_Scotland_to_and_from_different_parts_for_one_Year_from_Christmas_1780_to_Christmas_1781.jpg">Wikipedia</a> </div> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Playfair-piechart-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Playfair-piechart-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Playfair-piechart-1400.webp"/> <img src="/assets/img/Playfair-piechart.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Wykres kołowy z Playfair's Statistical Breviary (1801), pokazujący proporcje imperium tureckiego znajdującego się w Azji, Europie i Afryce przed 1789 rokiem. Źródło: <a href="https://en.wikipedia.org/wiki/William_Playfair#/media/File:Playfair-piechart.jpg">Wikipedia</a> </div> <hr/> <h2 id="wizualizacja-danych-w-służbie-zdrowia">Wizualizacja danych w służbie zdrowia</h2> <p>Wizualizacja danych jest obecnie szeroko stosowana w wielu dziedzinach, ale jedną z najbardziej obiecujących jest służba zdrowia. Wizualizacja danych może pomóc w analizie i interpretacji danych medycznych, co może prowadzić do lepszych decyzji klinicznych i poprawy opieki zdrowotnej.</p> <hr/> <h3 id="florence-nightingale">Florence Nightingale</h3> <p>Najbardziej znane osiągnięcie Nightingale w dziedzinie wizualizacji danych to jej “diagram kołowy” (polar area diagram), który często nazywany jest “diagramem różycy”. Użyła go do ilustracji, jakie były przyczyny zgonów wśród żołnierzy podczas Wojny Krymskiej.</p> <p>Jej diagram różycy przedstawiał, że większość zgonów nie wynikała bezpośrednio z obrażeń wojennych, ale z chorób zakaźnych. Ta wizualizacja miała ogromny wpływ na reformy sanitarno-higieniczne w obozach wojskowych.</p> <p>Praca Nightingale była nie tylko innowacyjna pod kątem technicznym, ale miała również długotrwałe konsekwencje dla zdrowia publicznego. Dzięki jej wizualizacjom zwrócono uwagę na istotne kwestie higieny i opieki zdrowotnej, co przyczyniło się do poprawy warunków w obozach wojskowych, a później także w innych instytucjach zdrowotnych.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/R-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/R-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/R-1400.webp"/> <img src="/assets/img/R.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Diagram obszarowy biegunowy został wynaleziony przez Florence Nightingale, aby zobrazować skalę niepotrzebnych zgonów w brytyjskich szpitalach wojskowych podczas Wojny Krymskiej (1954-56). Źródło: <a href="https://en.wikipedia.org/wiki/Florence_Nightingale#/media/File:Diagram_of_the_causes_of_mortality_in_the_Army_in_the_East_FOLIO_I._VOL.I._Wellcome_L0000551.jpg">Wikipedia</a> </div> <p>Obszar każdego kolorowego klinu, mierzony od środka, jest proporcjonalny do reprezentowanej statystyki. Niebieskie klasy reprezentują zgony z “zapobiegawczych lub łagodzących” chorób zakaźnych (chorób zakaźnych takich jak cholera czy tyfus), różowe klasy zgony z ran, a szare klasy zgony z wszystkich innych przyczyn. Śmiertelność osiągnęła szczyt w styczniu 1855 roku, kiedy zmarło 2761 osób na choroby zakaźne, 83 z ran i 324 z innych przyczyn.</p> <p>Bazując na średniej sile armii wynoszącej 32393, Nightingale obliczyła roczną śmiertelność na poziomie 1174 na 1000. Diagram pochodzi od Bernarda Cohena, “Florence Nightingale,” Scientific American, marzec 1984. Oryginalnie pochodzi z książki Nightingale “Notes on Matters Affecting the Health, Efficiency and Hospital Administration of the British Army”, opublikowanej w 1858 roku.</p> <hr/> <h3 id="john-snow">John Snow</h3> <p>John Snow, angielski lekarz, jest znany z tego, że jako pierwszy zastosował wizualizację danych do badania epidemiologii. W 1854 roku, podczas epidemii cholery w Londynie, Snow stworzył mapę, która przedstawiała lokalizację przypadków zachorowań na cholerę w dzielnicy Soho.</p> <p>Snow zidentyfikował źródło epidemii jako publiczną pompę wodną na Broad Street. Zrobił to, lokalizując przypadki choroby na mapie, co pozwoliło mu zobaczyć skupisko w okolicy tej pompy. Ta wizualizacja była kluczowa dla zrozumienia, jak cholera rozprzestrzenia się przez zanieczyszczoną wodę.</p> <p>Praca Snowa pomogła zmienić podejście do zdrowia publicznego i zrozumieć, jak choroby zakaźne, takie jak cholera, mogą rozprzestrzeniać się w populacji. Jego metoda używania mapy do wizualizacji danych zdrowotnych jest nadal stosowana dzisiaj, na przykład w monitorowaniu rozprzestrzeniania się wirusa COVID-19.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/88b66df5d4c7aa5216284822e6591481-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/88b66df5d4c7aa5216284822e6591481-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/88b66df5d4c7aa5216284822e6591481-1400.webp"/> <img src="/assets/img/88b66df5d4c7aa5216284822e6591481.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Wykres pokazujący temperaturę i śmiertelność Londynu dla każdego tygodnia 11 lat, 1840-50 z Farr's Report on the 1849 epidemic. Numer WI L0039176, Wellcome Library Źródło: <a href="https://wellcomecollection.org/works/yp5q3q3n">Wellcome Collection</a> </div> <hr/> <h2 id="charles-minard-wizualizacja-danych-wojennych">Charles Minard: Wizualizacja danych wojennych</h2> <p>Charles Minard, francuski inżynier i ekonomista, jest sławny z powodu swojej niezwykłej umiejętności prezentowania skomplikowanych danych w prosty i zrozumiały sposób. Minard jest najbardziej znany z wyjątkowego diagramu przedstawiającego katastrofalną kampanię Napoleona w Rosji w 1812 roku. Ta innowacyjna wizualizacja, często uważana za “najlepszy wykres statystyczny wszech czasów”, jednocześnie ilustruje sześć różnych zmiennych: liczbę wojsk, odległość, temperaturę, datę, kierunek ruchu i lokalizację.</p> <p>Minard użył szerokości linii, aby reprezentować liczbę pozostałych sił Napoleona w różnych etapach marszu. Wizualizacja jest nie tylko estetycznie przyjemna, ale również mocno oddziałuje na odbiorcę poprzez pokazanie ogromu strat poniesionych podczas kampanii. W dodatku, dołączony do wykresu wykres liniowy ilustruje temperatury podczas odwrotu armii francuskiej, dodając kolejny wymiar do tej opowieści.</p> <p>Wizualizacja Minarda jest doskonałym przykładem tego, jak skomplikowane zestawy danych można przekształcić w intuicyjne obrazy, które pozwalają odbiorcy szybko zrozumieć kontekst i znaczenie prezentowanych informacji. Ta praca jest do dziś inspiracją dla specjalistów od wizualizacji danych na całym świecie.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/mapa-charles-minard-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/mapa-charles-minard-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/mapa-charles-minard-1400.webp"/> <img src="/assets/img/mapa-charles-minard.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Wykres przedstawiający liczbę wojsk Napoleona w czasie kampanii rosyjskiej w 1812 roku. Źródło: <a href="https://commons.wikimedia.org/wiki/File:Minard.png">Wikimedia Commons</a> </div> <p>Ten mapa pokazuje ruch wojsk podczas kampanii rosyjskiej. Liczba żołnierzy, którzy rozpoczęli kampanię, wynosiła około 442 000 - pokazane po lewej stronie mapy na brązowo. Do Moskwy dotarło 100 000 żołnierzy - prawa strona mapy na brązowo. Na dolnym, prawym, czarnym pasku mapa pokazuje liczbę żołnierzy, którzy opuścili Moskwę - 100 000 - a po prawej stronie na czarno wskazuje, że do Francji wróciło tylko 10 000 żołnierzy. Dolna część wykresu pokazuje skalę temperatury na całej trasie.</p> <p>Dzięki temu wykresowi mamy szczegółowy obraz tego, co zaszło w bitwie. Jeżeli przeanalizujesz wykres, łatwiej będzie zrozumieć i “zwizualizować” liczby niż na podstawie tekstu. Wyjaśnienie tekstowe utrudnia zrozumienie liczb w odpowiedniej kolejności wielkości. Spoglądając na wykres, możemy lepiej zrozumieć katastrofę, jaką była ta bitwa.</p> <hr/> <h2 id="początki-współczesnej-wizualizacji-danych">Początki współczesnej wizualizacji danych</h2> <p>Wizualizacja danych zaczęła się rozwijać wraz z rozwojem technologii komputerowych. W latach 60. XX wieku pojawiły się pierwsze komputery, które umożliwiły przetwarzanie i wizualizację dużych zbiorów danych. W tym samym czasie pojawiły się pierwsze narzędzia do wizualizacji danych, takie jak systemy graficzne, które umożliwiły użytkownikom tworzenie wykresów i diagramów bez konieczności pisania kodu.</p> <hr/> <h3 id="herman-hollerith-maszyna-do-przetwarzania-danych">Herman Hollerith: Maszyna do przetwarzania danych</h3> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/R%20(1)-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/R%20(1)-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/R%20(1)-1400.webp"/> <img src="/assets/img/R%20(1).jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Maszyna do sortowania i liczenia kart perforowanych zaprojektowana przez Hermana Holleritha. Źródło: <a href="https://americanhistory.si.edu/collections/search/object/nmah_694410">National Museum of American History</a> </div> <p>Herman Hollerith, amerykański wynalazca i statystyk, jest postacią, która zasługuje na szczególne uznanie w dziedzinie przetwarzania i wizualizacji danych. To on zaprojektował i skonstruował pierwszą funkcjonalną maszynę do przetwarzania danych - maszynę do sortowania i liczenia kart perforowanych. Ta innowacyjna technologia zrewolucjonizowała sposób, w jaki dane były zbierane i analizowane, stanowiąc punkt zwrotny dla przyszłych generacji komputerów.</p> <p>Dzięki swojemu wynalazkowi, Hollerith znacznie przyspieszył proces spisu powszechnego w Stanach Zjednoczonych w 1890 roku, co wcześniej zajmowało wiele lat. Jego maszyna potrafiła przetworzyć dane o populacji w ciągu zaledwie kilku miesięcy, co było wtedy niewyobrażalne.</p> <p>W 1896 roku Hollerith założył Tabulating Machine Company, firmę, która później przekształciła się w giganta technologicznego, znanego dzisiaj jako IBM. Wykorzystanie kart perforowanych do przechowywania i przetwarzania danych, zapoczątkowane przez Holleritha, stało się fundamentem dla rozwoju technologii informacyjnej. Bez jego przyczynkowego wkładu, historia wizualizacji danych mogłaby wyglądać zupełnie inaczej. Praca Holleritha położyła podwaliny pod nowoczesne metody analizy i wizualizacji danych, które teraz są nieodłączną częścią naszego świata.</p> <hr/> <h3 id="john-tukey-ojciec-eksploracyjnej-analizy-danych">John Tukey: Ojciec eksploracyjnej analizy danych</h3> <p>John Tukey, wybitny amerykański matematyk i statystyk, jest powszechnie uznawany za “ojca eksploracyjnej analizy danych” (EDA - Exploratory Data Analysis). EDA to podejście do analizy danych, które polega na eksploracji i wizualizacji danych przed formalnym testowaniem statystycznym, pozwalając na zrozumienie ich struktury, wykrycie anomalii, sprawdzenie założeń czy identyfikację potencjalnych modeli.</p> <p>Jednym z kluczowych wkładów Tukeya w dziedzinę wizualizacji danych jest wynalezienie box plotu (diagramu pudełkowego). Diagram ten to prosty, ale bardzo efektywny sposób prezentowania rozkładu danych. Dzięki box plotom, możemy łatwo zauważyć medianę, kwartyle i potencjalne wartości odstające, co daje nam podstawowe zrozumienie rozkładu danych.</p> <p>Tukey zawsze podkreślał wagę wizualizacji w procesie analizy danych. W swojej pracy “Eksploracyjna Analiza Danych” z 1977 roku, wyjaśnił jak różne metody wizualizacji, takie jak histogramy, wykresy punktowe czy wykresy Q-Q, mogą pomóc w zrozumieniu danych. Ta praca jest do dziś fundamentalnym źródłem wiedzy na temat EDA.</p> <p>Dziedzictwo Tukeya żyje w każdej analizie danych, która zaczyna się od dokładnego zrozumienia danych poprzez ich wizualizację. Jego wkład w dziedzinę statystyki i wizualizacji danych jest nieoceniony, a jego prace nadal inspirują kolejne generacje analityków danych.</p> <hr/> <h3 id="edward-tufte-wizualizacja-danych-w-xx-wieku">Edward Tufte: Wizualizacja danych w XX wieku</h3> <p>Edward Tufte, amerykański teoretyk informacji, jest niezaprzeczalnie jednym z najbardziej wpływowych pionierów w dziedzinie wizualizacji danych w XX wieku. Zasłynął z tworzenia szczegółowych zasad dotyczących efektywnej prezentacji danych statystycznych, które znalazły odzwierciedlenie w jego licznych publikacjach.</p> <p>Jego książka “The Visual Display of Quantitative Information”, jest kluczowym dziełem w tej dziedzinie, stanowiącym kanon dobrej praktyki wizualizacji danych. Tufte wprowadził tutaj takie pojęcia jak “lie factor” - czynnik kłamstwa, który mierzy stopień zniekształcenia danych prezentowanych na wykresie, czy “data-ink ratio” - stosunek “atramentu danych” do całkowitej ilości “atramentu” użytego do stworzenia wykresu.</p> <p>Kolejne z jego znanych dzieł, “Envisioning Information”, koncentruje się na różnorodnych sposobach prezentacji informacji, wykorzystując przykłady z tak różnych dziedzin jak kartografia, sztuka, projektowanie interfejsów, czy nauki przyrodnicze.</p> <p>Edward Tufte jest również znany z wprowadzenia koncepcji “sparklines” - małych, intensywnych, prostych, wykresów słupkowych, które pozwalają na skondensowane przedstawienie informacji. Wszystkie te idee i koncepcje przyczyniły się do kształtowania nowoczesnej wizualizacji danych, a wkład Tufta jest nieoceniony dla dzisiejszych projektantów i analityków danych.</p> <hr/> <h3 id="jacques-bertin-semiotyka-wizualizacji-danych">Jacques Bertin: Semiotyka wizualizacji danych</h3> <p>Jacques Bertin, wybitny francuski kartograf i teoretyk informacji, jest postacią niezwykle istotną dla dziedziny wizualizacji danych. Jego wkład polegał na stworzeniu semiologii graficznej, czyli nauki o znakach graficznych, ich strukturze i sposobie działania na odbiorcę.</p> <p>W swojej fundamentalnej książce “Semiology of Graphics”, opublikowanej po raz pierwszy w 1967 roku, Bertin przedstawił siedem fundamentalnych zmiennych wizualnych: położenie, kształt, kolor, orientację, wielkość, wartość i teksturę. Każda z tych zmiennych ma specyficzne właściwości i potrafi przekazywać określone informacje w sposób zrozumiały dla odbiorcy.</p> <p>Bertin zwracał uwagę na to, że wizualizacja danych musi być przemyślana i zrozumiała dla odbiorcy. Podkreślał, że skuteczność wizualizacji danych zależy od prawidłowego wyboru i zastosowania zmiennych wizualnych.</p> <p>Nauka Bertina dotycząca semiologii graficznej ma olbrzymie znaczenie dla dzisiejszych praktyk wizualizacji danych. Jego idee nadal inspirują i kształtują sposób, w jaki prezentujemy i interpretujemy informacje. “Semiology of Graphics” Jacques’a Bertina to absolutna klasyka w dziedzinie wizualizacji danych, która pomogła zdefiniować podstawy tej dyscypliny.</p> <hr/> <h2 id="początek-ery-komputerowej-wizualizacji-danych-koniec-lat-60-xx-wieku">Początek ery komputerowej wizualizacji danych (koniec lat 60. XX wieku)</h2> <p>Koniec lat 60. XX wieku to ważny moment w historii wizualizacji danych, który zapoczątkował erę komputerowej wizualizacji danych. To właśnie w tym czasie, dzięki gwałtownemu rozwojowi technologii informatycznej, zaczęto stosować komputery do tworzenia i interpretowania wizualizacji danych.</p> <p>Przełomem były innowacyjne programy takie jak Systat, SPSS i SAS. Te narzędzia, pierwotnie stworzone do analizy statystycznej, umożliwiły automatyczną wizualizację danych. Oferta tych narzędzi szybko się rozrastała, co umożliwiło tworzenie skomplikowanych wykresów i diagramów z dużych zbiorów danych w relatywnie krótkim czasie.</p> <p>Wraz z upowszechnieniem komputerów osobistych i rozwojem technologii graficznych, możliwości wizualizacji danych stały się praktycznie nieograniczone. Rozpoczął się proces tworzenia coraz to nowszych narzędzi do analizy i prezentacji danych, które umożliwiły wizualizację informacji na skalę niewyobrażalną wcześniej.</p> <p>Rozwój technologii komputerowych sprawił, że analiza i wizualizacja danych stała się szybsza, dokładniejsza i bardziej dostępna. To właśnie te lata dały początek nowoczesnej wizualizacji danych, której jesteśmy świadkami dzisiaj. Ewolucja narzędzi do wizualizacji danych, która rozpoczęła się w latach 60., jest nadal w toku, a możliwości jakie daje nam dzisiejsza technologia są niezwykle ekscytujące.</p> <hr/> <h3 id="ben-shneiderman-interaktywna-wizualizacji-danych">Ben Shneiderman: Interaktywna wizualizacji danych</h3> <p>Ben Shneiderman, wybitny amerykański informatyk i profesor na University of Maryland, jest uznawany za pioniera w dziedzinie interaktywnej wizualizacji danych. Jego prace wyznaczyły nowy kierunek w podejściu do prezentacji i interakcji z danymi.</p> <p>Shneiderman jest twórcą koncepcji “direct manipulation”, czyli bezpośredniej manipulacji, co zrewolucjonizowało sposób, w jaki użytkownicy komputerów współdziałają z interfejsami użytkownika. Podkreślał znaczenie interaktywności i angażowania użytkowników w proces analizy danych.</p> <p>Jego publikacja “The Eyes Have It: A Task by Data Type Taxonomy for Information Visualizations” jest fundamentalnym dziełem w tej dziedzinie. W tej pracy, Shneiderman wprowadził koncepcję “Mantra Wizualizacji”, składającą się z czterech zasad: “Przeglądaj pierwszy, zoom i filtruj, następnie szczegół na życzenie”. Ta koncepcja jest do dzisiaj stosowana w projektowaniu interaktywnych wizualizacji danych.</p> <p>Shneiderman miał ogromny wpływ na rozwój interaktywnych wizualizacji danych, a jego koncepcje nadal są stosowane w nowoczesnym projektowaniu UX/UI. Dzięki jego wkładowi, dzisiaj możemy korzystać z narzędzi, które umożliwiają łatwe i intuicyjne poruszanie się po skomplikowanych zestawach danych. Jego prace są nieocenionym źródłem wiedzy dla każdego, kto interesuje się wizualizacją danych.</p> <hr/> <h2 id="podsumowanie">Podsumowanie</h2> <p>Podsumowując, historia wizualizacji danych to niezwykle interesujące i dynamiczne pole, które od starożytności do współczesności przeszło przez wiele faz ewolucji. Od prostych reprezentacji w formie map i wykresów, przez innowacyjne prace Minarda, aż do wynalazku maszyn do przetwarzania danych przez Holleritha, wizualizacja danych zawsze była nieodzownym elementem nauki i biznesu.</p> <p>XX wiek to era ekspansji w dziedzinie wizualizacji danych, kiedy to tacy giganci jak Tukey, Tufte i Bertin zdefiniowali podstawy tej dziedziny. Z biegiem lat, z nadejściem komputerów, możliwości wizualizacji danych znacznie się poszerzyły, czemu przyczyniły się także prace Shneidermana.</p> <p>Obecnie, w dobie cyfryzacji i rosnącej ilości dostępnych danych, wizualizacja danych odgrywa kluczową rolę w wielu dziedzinach życia. Służy do przekazywania skomplikowanych informacji w przystępnej formie, pomaga w podejmowaniu decyzji i jest nieodzowna w świecie nauki, technologii i biznesu.</p> <p>Oczekuje się, że przyszłość przyniesie jeszcze więcej innowacji w dziedzinie wizualizacji danych, a jej znaczenie będzie dalej rosnąć. Jak pokazuje historia, potencjał tej dziedziny jest nieograniczony, a nasza zdolność do wykorzystania danych w celu zrozumienia świata wciąż się rozwija.</p> <hr/>]]></content><author><name></name></author><category term="article"/><category term="analiza-danych"/><category term="narzedzia"/><category term="historia"/><category term="wizualizacje"/><category term="visualization"/><category term="edukacja"/><summary type="html"><![CDATA[Artykuł, który skupia sie na historii wizualizacji danych]]></summary></entry><entry><title type="html">Wykorzystywanie AI w pisaniu artykułów</title><link href="https://szymok.github.io/blog/2023/ai-writing/" rel="alternate" type="text/html" title="Wykorzystywanie AI w pisaniu artykułów"/><published>2023-03-13T00:10:00+00:00</published><updated>2023-03-13T00:10:00+00:00</updated><id>https://szymok.github.io/blog/2023/ai-writing</id><content type="html" xml:base="https://szymok.github.io/blog/2023/ai-writing/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kaitlyn-baker-vZJdYl5JVXY-unsplash-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kaitlyn-baker-vZJdYl5JVXY-unsplash-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kaitlyn-baker-vZJdYl5JVXY-unsplash-1400.webp"/> <img src="/assets/img/kaitlyn-baker-vZJdYl5JVXY-unsplash.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Pisanie artykułów, które są napędzane przez AI, jest coraz bardziej popularne. </div> <h2 id="jak-wykorzystywać-ai-w-pisaniu-tekstów-i-artykułach">Jak wykorzystywać AI w pisaniu tekstów i artykułach?</h2> <p>AI, czyli sztuczna inteligencja, to dziedzina nauki i technologii, która zajmuje się tworzeniem maszyn i systemów zdolnych do wykonywania zadań wymagających ludzkiego intelektu. AI ma coraz większy wpływ na różne aspekty naszego życia, w tym na sposób pisania i czytania tekstów. W tym artykule przedstawię kilka sposobów, w jaki możemy wykorzystywać AI w pisaniu tekstów i artykułach oraz jakie są tego zalety i wady.</p> <p>Generatory tekstu są dostępne od lat, ale coś się zmieniło: w końcu stały się dobre. Tam, gdzie poprzednie iteracje wymagały ciężkiej edycji, najnowsza wersja Chat GPT od OpenAI używa lepszej gramatyki niż ja. Jednakże, mało w nim jest twórczej iskry. Wynika to z faktu, jak działa Chat GPT. Jego uczenie maszynowe opiera się na 570 GB tekstu z Wikipedii, internetu i książek. Przebrnięcie przez 300 miliardów słów nauczyło system jak zbudowane są zdania, ale nie procesu kreatywnego, który doprowadził do ich powstania.</p> <p>Podczas gdy modele AI mogą być trenowane na ogromnych ilościach danych i potrafią rozpoznawać wzorce oraz generować tekst, który jest spójny i konsekwentny stylowo, to nie potrafią w pełni zrozumieć głębszego znaczenia lub implikacji słów, których używają. AI nie jest zdolna do kreatywności w taki sam sposób, jak ludzie. Może generować tekst na podstawie wzorców, które widziała w danych, ale nie potrafi wymyślać nowych pomysłów lub perspektyw w sposób, w jaki może to zrobić człowiek pisarz. To może prowadzić do braku oryginalności i głębi w pisaniu.</p> <p>Mimo to, nauczyciele i wykładowcy są zaniepokojeni i coraz częściej można usłyszeć o zakazie używania Chat GPT przez swoją szkołę(głównie w Ameryce), a australijskie szkoły wracają do egzaminów papierowych i ołówkowych. Ale jak daleko mogą posunąć się w tym kierunku? Uczniowie od dawna są oceniani przez pryzmat swojego pisania na dobrze znanych tematach. Dyskusje o symbolice w Szekspirze już są dostępne w sieci, więc studenci mogą je otworzyć tak samo łatwo, jak Chat GPT. Łatwo jest kupić wstępnie napisane eseje, znaleźć przykładowe teksty do skopiowania lub w inny sposób uzyskać odpowiedzi z internetu - wpisz “tematy z książki xxx” w Google i gotowe.</p> <p>Jednakże, czytanie gotowców lub innych materiałów nie jest oszukiwaniem. Czytanie, myślenie, a potem pisanie tego własnymi słowami to prawdziwa praca. Dla niektórych uczniów pisanie własnymi słowami jest najtrudniejszą częścią. Ale jest mnóstwo algorytmów poza Google, które mogą pomóc w tym zadaniu. Sprawdzanie pisowni jest na wyższym poziomie niż kiedyś</p> <hr/> <h2 id="rodzaje-i-funkcje-ai-w-pisaniu">Rodzaje i funkcje AI w pisaniu</h2> <p>AI może nam pomóc w pisaniu na wiele sposobów, w zależności od celu i rodzaju tekstu, który chcemy stworzyć. Oto niektóre z najczęstszych funkcji AI w pisaniu:</p> <ul> <li> Generowanie tytułów: AI może zaproponować nam kilka tytułów do naszego tekstu, które będą pasować do tematu, treści i stylu pisania. Na przykład, jeśli chcemy napisać artykuł o AI w medycynie, AI może zaproponować nam takie tytuły jak: "AI ratuje życie: jak sztuczna inteligencja zmienia oblicze medycyny", "Jak AI pomaga lekarzom w diagnozowaniu i leczeniu chorób" lub "Przyszłość medycyny: jak AI wpływa na jakość i dostępność opieki zdrowotnej".</li> <li> Generowanie treści: AI może napisać za nas cały tekst lub jego część, bazując na podanych przez nas informacjach, instrukcjach lub pytaniach. Na przykład, jeśli chcemy napisać wprowadzenie do naszego artykułu o AI w medycynie, AI może wygenerować dla nas taką treść: "AI, czyli sztuczna inteligencja, to dziedzina nauki i technologii, która zajmuje się tworzeniem maszyn i systemów zdolnych do wykonywania zadań wymagających ludzkiego intelektu. AI ma coraz większy wpływ na różne aspekty naszego życia, w tym na sposób diagnozowania i leczenia chorób. W tym artykule przedstawię kilka przykładów zastosowań AI w medycynie oraz jakie są tego korzyści i zagrożenia dla pacjentów i lekarzy."</li> <li> Generowanie podsumowań: AI może podsumować dla nas główne punkty naszego tekstu lub tekstu źródłowego, który chcemy zacytować lub sparafrazować. Na przykład, jeśli chcemy podsumować artykuł o AI w edukacji, AI może wygenerować dla nas takie podsumowanie: "Artykuł przedstawia kilka sposobów wykorzystania AI w edukacji, takich jak personalizacja nauki, ocena postępów uczniów, wspomaganie nauczycieli i tworzenie interaktywnych materiałów dydaktycznych. Artykuł podkreśla również potencjalne korzyści i wyzwania związane z wprowadzaniem AI do szkolnictwa."</li> </ul> <hr/> <h2 id="przykłady-konkretnych-narzędzi-i-aplikacji-ai-do-pisania-które-są-dostępne-na-rynku-lub-w-fazie-rozwoju">Przykłady konkretnych narzędzi i aplikacji AI do pisania, które są dostępne na rynku lub w fazie rozwoju</h2> <p>Na rynku istnieje wiele narzędzi i aplikacji AI do pisania, które mają różne funkcje i cele. Oto niektóre z nich:</p> <ul> <li> <a href="https://inkforall.com/">INK for All</a>: to narzędzie łączy w sobie funkcje AI do pisania i SEO. Może pomóc w tworzeniu optymalnych tytułów, treści, słów kluczowych i meta opisów dla stron internetowych.</li> <li> <a href="https://www.copy.ai/">Copy.ai</a>: to narzędzie służy do generowania krótkich form treści, takich jak slogany, nagłówki, opisy produktów, posty na social media i wiele innych.</li> <li> <a href="https://chat.openai.com/">ChatGPT</a>: to narzędzie pozwala na prowadzenie konwersacji z AI na dowolny temat. Może być używane do testowania pomysłów, tworzenia dialogów, zabawy lub nauki.</li> <li> <a href="https://rytr.me/">Rytr</a>: to narzędzie jest przeznaczone do codziennego pisania. Może pomóc w tworzeniu treści na różne cele i style, takie jak blogi, e-maile, opowiadania, listy motywacyjne i wiele innych.</li> <li> <a href="https://www.grammarly.com/">Grammarly</a>: to narzędzie jest znane z korekty gramatyki i ortografii w tekście. Może też pomóc w poprawieniu stylu, tonu i klarowności tekstu oraz w wykrywaniu plagiatu.</li> <li> <a href="https://www.frase.io/">Frase</a>: to narzędzie jest przeznaczone do tworzenia długich form treści, takich jak artykuły, raporty, e-booki i wiele innych. Może pomóc w badaniu tematu, generowaniu struktury tekstu, tworzeniu treści i optymalizacji SEO.</li> <li> <a href="https://www.outranking.io/s">Outranking</a>: to narzędzie jest skierowane do przedsiębiorców, agencji i przedsiębiorstw. Może pomóc w tworzeniu wysokiej jakości treści marketingowych i sprzedażowych oraz w analizie konkurencji i wyników.</li> </ul> <hr/> <h2 id="zalety-i-wady-wykorzystywania-ai-do-pisania">Zalety i wady wykorzystywania AI do pisania</h2> <p>Zalety:</p> <ul> <li> Zwiększenie produktywności i skalowalności: narzędzia AI do pisania mogą pomóc w szybszym i łatwiejszym tworzeniu treści na różne cele i platformy.</li> <li> Zwiększenie kreatywności i jakości: narzędzia AI do pisania mogą pomóc w generowaniu pomysłów, struktur, tytułów, sloganów i innych elementów tekstu, które mogą zwiększyć jego atrakcyjność i zainteresowanie czytelnika.</li> <li> Zwiększenie zasięgu i dostępności: narzędzia AI do pisania mogą pomóc w tłumaczeniu, adaptacji i optymalizacji treści dla różnych języków, kultur i grup docelowych.</li> </ul> <p>Wady:</p> <ul> <li> Ryzyko dezinformacji i manipulacji: narzędzia AI do pisania mogą być wykorzystywane do masowego tworzenia fałszywych lub tendencyjnych informacji, które mogą wpływać na opinie publiczną, politykę i bezpieczeństwo.</li> <li> Utrata autentyczności i osobowości: narzędzia AI do pisania mogą sprawić, że treść będzie brzmiała sztucznie lub nieoryginalnie, co może obniżyć zaufanie i lojalność czytelnika.</li> <li> Naruszenie praw autorskich i etycznych: narzędzia AI do pisania mogą nieświadomie lub celowo kopiować lub plagiatować treści z innych źródeł, co może naruszać prawa własności intelektualnej lub moralne autorów.</li> </ul> <hr/> <h2 id="jak-sprawdzić-czy-dany-tekst-nie-został-wygenerowany-przez-ai">Jak sprawdzić, czy dany tekst nie został wygenerowany przez AI?</h2> <p>Sztuczna inteligencja (AI) jest zdolna do generowania tekstów na różne tematy i w różnych stylach. Niektóre z tych tekstów są tak przekonujące, że trudno je odróżnić od tekstów napisanych przez ludzi. Jednak nie wszystkie teksty wygenerowane przez AI są wiarygodne lub prawdziwe. Mogą one zawierać błędy, niespójności, fałszywe informacje lub manipulacje. Dlatego ważne jest, aby umieć wykrywać teksty napisane przez AI i oceniać ich jakość i wiarygodność. Jednym ze sposobów wykrywania tekstów napisanych przez AI jest analiza różnych cech tekstu, takich jak płynność, spójność, oryginalność czy poprawność językowa. Można do tego używać specjalnego oprogramowania, które porównuje tekst z bazą danych lub modelem językowym i ocenia jego prawdopodobieństwo lub zgodność. Na przykład, narzędzie GLTR podświetla słowa w tekście na różne kolory w zależności od tego, jak często występują one w danym kontekście. Jeśli tekst zawiera wiele rzadkich lub niepasujących słów, oznacza to, że jest on mniej naturalny i prawdopodobnie wygenerowany przez AI. Innym przykładem jest AI Classifier, który wskazuje, czy tekst został wygenerowany przez AI na podstawie tego, jak dobrze model GPT-3 przewiduje kolejne słowa w tekście. Jeśli tekst jest bardzo przewidywalny dla modelu, oznacza to, że jest on bardziej podobny do tekstu wygenerowanego przez AI Wykrywanie tekstów napisanych przez AI jest ważnym i trudnym zadaniem, które wymaga zarówno narzędzi komputerowych, jak i ludzkiego osądu. Nie ma jednego niezawodnego sposobu na odróżnienie tekstu wygenerowanego przez AI od tekstu napisanego przez człowieka, ponieważ AI może naśladować różne style i tematy. Niektóre teksty mogą być również zmodyfikowane lub zmieszane z tekstami ludzkimi, aby uniknąć wykrycia. Dlatego należy być krytycznym i ostrożnym podczas czytania i oceniania tekstów, zwłaszcza tych pochodzących z nieznanych lub niezaufanych źródeł. Wykrywanie tekstów napisanych przez AI ma również znaczenie społeczne i etyczne, ponieważ dotyczy kwestii prawdy, wiarygodności i odpowiedzialności w komunikacji i informacji.</p> <hr/> <p>Podsumowując, AI w pisaniu jest potężnym i obiecującym narzędziem, które ma wiele zalet i wad. Pytanie czy i jak wykorzystać AI w pisaniu w sposób odpowiedzialny i etyczny? Na pewno potrzebne są jasne i spójne wytyczne, standardy i regulacje dotyczące stosowania AI w pisaniu, które będą chronić prawa i interesy zarówno twórców, jak i odbiorców treści. Dalsze kierunki badań lub zastosowań AI w pisaniu mogą obejmować:</p> <ul> <li> Badanie wpływu AI na jakość i styl pisania oraz na postrzeganie i ocenę treści przez czytelników.</li> <li> Badanie możliwości i ograniczeń AI w tworzeniu różnych rodzajów treści, takich jak literatura, dziennikarstwo, marketing, edukacja i inne.</li> <li> Badanie sposobów poprawy współpracy i interakcji między ludźmi a AI w procesie pisania oraz roli ludzkiej kreatywności i kontroli nad treścią.</li> <li> Badanie sposobów wykorzystania AI do promowania różnorodności, inkluzywności i sprawiedliwości w treściach oraz do zwalczania uprzedzeń, stereotypów i dyskryminacji.</li> </ul>]]></content><author><name></name></author><category term="article"/><category term="sztuczna-inteligencja"/><category term="generowanie-tekstu"/><category term="technologie-jezykowe"/><category term="przyszłosc-mediow"/><category term="etyka-regulacje"/><summary type="html"><![CDATA[Artykuł przedstawia zalety i wady wykorzystywania sztucznej inteligencji (AI) w pisaniu artykułów]]></summary></entry></feed>