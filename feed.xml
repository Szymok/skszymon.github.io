<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="pl"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://szymok.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://szymok.github.io/" rel="alternate" type="text/html" hreflang="pl"/><updated>2023-08-23T17:22:32+00:00</updated><id>https://szymok.github.io/feed.xml</id><title type="html">blank</title><subtitle>Blog o analizie danych i sztucznej inteligencji. To dwa kluczowe narzędzia wspierające decyzje biznesowe i pozwalające na uzyskanie przewagi konkurencyjnej. </subtitle><entry><title type="html">Rząd a AI</title><link href="https://szymok.github.io/blog/2023/ai-w-rekach-rzadu/" rel="alternate" type="text/html" title="Rząd a AI"/><published>2023-08-21T05:12:45+00:00</published><updated>2023-08-21T05:12:45+00:00</updated><id>https://szymok.github.io/blog/2023/ai-w-rekach-rzadu</id><content type="html" xml:base="https://szymok.github.io/blog/2023/ai-w-rekach-rzadu/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sahilofix_America_government_garden_childrens_book_illustration_f1d1c5d1-34df-4501-a146-74024190e7ca-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sahilofix_America_government_garden_childrens_book_illustration_f1d1c5d1-34df-4501-a146-74024190e7ca-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sahilofix_America_government_garden_childrens_book_illustration_f1d1c5d1-34df-4501-a146-74024190e7ca-1400.webp"/> <img src="/assets/img/sahilofix_America_government_garden_childrens_book_illustration_f1d1c5d1-34df-4501-a146-74024190e7ca.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Obraz wygenerowany przy pomocy Midjourney oraz edytowany w Photoshopie przy pomoocy funkcji Generative AI. </div> <h2 id="potęga-technologii-ai-wpływ-interwencji-rządowej-w-zaawansowane-systemy-ai"><strong>Potęga Technologii AI: Wpływ Interwencji Rządowej w Zaawansowane Systemy AI</strong></h2> <p>W dynamicznym świecie technologii wyróżnia się jeden głos wśród chóru insiderów branżowych i innowatorów. Charles Jennings, doświadczony weteran świata oprogramowania, spędził dziesięciolecia na czele firm zajmujących się oprogramowaniem, na własne oczy obserwując potencjał transformacyjny sztucznej inteligencji. Jego najnowsza przedsięwzięcie, technologia rozpoznawania twarzy oparta na sztucznej inteligencji, ponownie przyciągnęła uwagę opinii publicznej. Jednak jego perspektywa na przyszłość AI nie jest powszechnie słyszana w środowisku technologicznym. W inspirującej rozmowie z Stevenem Overly z POLITICO Tech, Jennings twierdzi, że najbardziej zaawansowane systemy sztucznej inteligencji stały się zbyt potężne, aby pozostawić je w prywatnych rękach. Argumentuje za zmianą równowagi władzy, sugerując, że interwencja rządowa jest niezbędnym krokiem, aby wykorzystać pełny potencjał AI.</p> <h3 id="bezprecedensowa-potęga-sztucznej-inteligencji"><strong>Bezprecedensowa Potęga Sztucznej Inteligencji</strong></h3> <p>Wzrost znaczenia AI w ostatnich latach charakteryzował się bezprecedensowym postępem. Zastosowania AI, zwłaszcza w technologii rozpoznawania twarzy, wykazały zdolność do analizy ogromnych zbiorów danych, identyfikacji wzorców i podejmowania decyzji z nadzwyczajną dokładnością. Te zdolności wykraczają poza zakres możliwości człowieka, obiecując przełomowe zmiany w wielu dziedzinach. Jednak w miarę wzrostu potencjału AI narastały również obawy dotyczące etyki, prywatności i nadużyć. Jennings wyznacza kluczowy moment: czy te potężne narzędzia powinny pozostać wyłącznie w rękach gigantów technologicznych, czy też powinny być powierzone ludowi poprzez interwencję rządową?</p> <h3 id="dychotomia-giganci-technologiczni-a-rząd"><strong>Dychotomia: Giganci Technologiczni a Rząd</strong></h3> <p>Jennings sprowadza tę decyzję do dychotomii dwóch opcji: albo giganci technologiczni nadal kontrolują trajektorię AI, albo rządy wkraczają w regulację i zarządzanie jej rozwojem. Koncepcja powierzenia takiej władzy podmiotom prywatnym budzi uzasadnione obawy dotyczące potencjalnych uprzedzeń, monopolów i niekontrolowanego wpływu, jaki skoncentrowana władza może wywrzeć. Jednak postulat interwencji rządowej nie jest pozbawiony swoich komplikacji.</p> <p>Jennings przyznaje, że obecne rządy mogą nie być w pełni przygotowane do skutecznego zarządzania zaawansowanymi systemami AI. Chociaż Kongres może odgrywać rolę regulatora, dynamiczna i szybko ewoluująca natura technologii AI stanowi istotne wyzwanie. Szybki rozwój zdolności AI często przewyższa procesy legislacyjne, czyniąc je niewystarczającymi do nadążania za szybkimi zmianami w środowisku technologicznym.</p> <h3 id="imperatyw-zmiany"><strong>Imperatyw Zmiany</strong></h3> <p>Jak więc znaleźć drogę naprzód? Jennings nie postuluje całkowitego odrzucenia roli Kongresu, ale nawołuje do innowacyjnych, dostosowanych struktur, które mogą efektywnie nadzorować i regulować rozwój technologii AI. Sugeruje, że poleganie wyłącznie na Kongresie w zakresie nadzoru jest porównywalne do proszenia żółwia, by dorównał zającowi - daremne wysiłki. Zamiast tego proponuje potrzebę nowych podejść i instytucji, specjalnie dostosowanych do zarządzania złożonością AI.</p> <h3 id="nowy-paradoks-kształtowanie-zarządzania-ai"><strong>Nowy Paradoks: Kształtowanie Zarządzania AI</strong></h3> <p>Wyobraźmy sobie nowy paradygmat, w którym zarządzanie AI jest kształtowane przez zróżnicowaną grupę ekspertów, technologów, etyków i decydentów. Ta grupa przekroczyłaby tradycyjne struktury biurokratyczne, umożliwiając szybkie reakcje na postępy AI. Służyłaby jako interfejs między postępami technologicznymi a regulacją rządową, zapewniając priorytet dla interesów społeczeństwa. Poprzez połączenie wiedzy ekspertów, ten nowy model mógłby poruszać się po skomplikowanej sieci rozwoju AI z elastycznością, której obecny krajobraz regulacyjny brakuje.</p> <h3 id="etyka-i-przejrzystość-filary-zarządzania-ai"><strong>Etyka i Przejrzystość: Filary Zarządzania AI</strong></h3> <p>Etyka i przejrzystość leżą u podstaw tego proponowanego paradygmatu zarządzania AI. Potencjał technologii AI do utrwalania uprzedzeń i naruszania prywatności osobistej podkreśla pilność potrzeby etycznego fundamentu. Mechanizmy przejrzystości umożliwiłyby społeczeństwu zrozumienie procesów podejmowania decyzji przez systemy AI, zmniejszając efekt “czarnej skrzynki”, który często utrudnia zrozumienie. Poprzez rozwiązanie tych kwestii etycznych i związanych z przejrzystością, ten model mógłby budować zaufanie publiczne, kluczowy czynnik skutecznego wdrożenia technologii AI.</p> <h3 id="od-regulacji-do-współpracy-kształtowanie-przyszłości-ai"><strong>Od Regulacji do Współpracy: Kształtowanie Przyszłości AI</strong></h3> <p>Koncepcja interwencji rządowej w dziedzinie AI nie jest bez swoich krytyków. Skeptycy argumentują, że zaangażowanie rządu może hamować innowacje i utrudniać dynamiczny wzrost, który sektor prywatny jest w stanie osiągnąć. Jednak perspektywa Jenningsa przewartościowuje dyskurs. Zamiast wyobrażać sobie interwencję rządową jako duszącą siłę regulacyjną, przedstawia ją jako wspólny wysiłek w kierunku odpowiedzialnego kształtowania przyszłości AI.</p> <h3 id="podsumowanie-wezwanie-do-przemyślenia-przyszłości-ai"><strong>Podsumowanie: Wezwanie do Przemyślenia Przyszłości AI</strong></h3> <p>Wnioski Charlesa Jenningsa zachęcają do głębokiego przemyślenia przyszłości sztucznej inteligencji. W miarę jak AI kontynuuje swoją błyskawiczną karierę, jej potencjalny wpływ na społeczeństwo nie może być bagatelizowany. Wybór między kontrolą prywatną a interwencją rządową niesie głębokie implikacje dla naszej przyszłości technologicznej. Chociaż wyzwania są ogromne, nie są one nie do pokonania. W miarę jak zastanawiamy się, kto powinien dzierżyć ogromną moc AI, ważne jest, abyśmy podejście do tego dyskursu z umysłem otwartym, gotowością do innowacji i determinacją kształtowali przyszłość, w której AI służy zbiorowym interesom społeczeństwa.</p> <p>W końcu to nie tylko wybór między gigantami technologicznymi a rządem. To wezwanie do zjednoczenia sił obu światów - prywatnych innowacji i publicznego zarządzania - aby kierować AI ku przyszłości, która przynosi korzyści wszystkim. Skomplikowany taniec między złożonością a dynamicznością w dziedzinie zarządzania AI jest odzwierciedleniem złożonego oddziaływania perspektyw, pomysłów i potencjalnych rozwiązań. W miarę jak rozważamy drogę naprzód, pamiętajmy, że w krajobrazie AI nawet jedno głos - choćby niekonwencjonalny - może wywołać rozmowę prowadzącą do przełomowych zmian.</p> <p><em>Oświadczenie: Wyrażone w tym artykule opinie są wyłącznie zdaniem autora i niekoniecznie odzwierciedlają poglądy POLITICO ani żadnych powiązanych podmiotów.</em> Źródło: [POLITICO](<a href="https://politico-tech.simplecast.com/episodes/one-techs-bold-idea-ai-is-the-new-atomic-energy-nationalize-it">POLITICO</a>)</p>]]></content><author><name></name></author><category term="article"/><category term="rzad"/><category term="sztuczna-inteligencja"/><category term="ai"/><category term="llm"/><summary type="html"><![CDATA[Co powinny zrobić rządy w kwestii sztucznej inteligencji.]]></summary></entry><entry><title type="html">Jak uruchomić LLM lokalnie</title><link href="https://szymok.github.io/blog/2023/llm-local/" rel="alternate" type="text/html" title="Jak uruchomić LLM lokalnie"/><published>2023-08-01T07:01:45+00:00</published><updated>2023-08-01T07:01:45+00:00</updated><id>https://szymok.github.io/blog/2023/llm-local</id><content type="html" xml:base="https://szymok.github.io/blog/2023/llm-local/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/infidel0986_a_generative_AI_LLM_hot_air_balloon_with_business_p_82aac953-8aec-429d-b858-1c84f034be75-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/infidel0986_a_generative_AI_LLM_hot_air_balloon_with_business_p_82aac953-8aec-429d-b858-1c84f034be75-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/infidel0986_a_generative_AI_LLM_hot_air_balloon_with_business_p_82aac953-8aec-429d-b858-1c84f034be75-1400.webp"/> <img src="/assets/img/infidel0986_a_generative_AI_LLM_hot_air_balloon_with_business_p_82aac953-8aec-429d-b858-1c84f034be75.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Obraz wygenerowany przy pomocy Midjourney oraz edytowany w Photoshopie przy pomoocy funkcji Generate AI. </div> <h2 id="uruchamianie-modeli-llm-lokalnie-za-pomocą-biblioteki-dalai">Uruchamianie modeli LLM lokalnie za pomocą biblioteki Dalai</h2> <p>Czy kiedykolwiek zastanawiałeś się nad uruchomieniem zaawansowanych modeli językowych, takich jak ChatGPT, na swoim własnym komputerze? Nie jesteś w tej przygodzie sam! W tym przewodniku krok po kroku dowiemy się, jak to zrobić za pomocą modeli LLaMA i Alpaca, korzystając z biblioteki Dalai. Bądź gotowy na szczegółową, krok po kroku i interesującą podróż do świata AI!</p> <h3 id="czym-jest-biblioteka-dalai">Czym jest biblioteka Dalai?</h3> <p>Dalai to narzędzie opracowane przez Meta AI w celu umożliwienia użytkownikom korzystania z modeli językowych LLM na swoich własnych komputerach. Dzięki tej bibliotece, możemy wykorzystać modele LLM, takie jak LLaMA i Alpaca, w środowisku offline, co eliminuje konieczność korzystania z centralnych i często komercyjnych rozwiązań oferowanych przez duże firmy.</p> <h3 id="dostępność-jako-biblioteka-nodejs">Dostępność jako biblioteka Node.js</h3> <p>Dalai został stworzony jako biblioteka dla środowiska Node.js, co umożliwia łatwe i elastyczne wykorzystanie modeli LLM w aplikacjach opartych na tym środowisku. Jest to szczególnie korzystne dla programistów pracujących w języku JavaScript.</p> <h2 id="dylemat-lokalnej-sztucznej-inteligencji-nasza-własna-prywatna-ostoja">Dylemat lokalnej sztucznej inteligencji: Nasza własna prywatna ostoja</h2> <p>Mierzymy się z wieloma możliwościami, jakie model generatywnej sztucznej inteligencji nam przynosi. Jednak wraz z wielką mocą przychodzi wielka odpowiedzialność (dzięki, Wujek Ben). Jednym z największych obaw, które mamy, jest prywatność danych. Centralizowane modele oferowane przez OpenAI i Microsoft są fantastyczne, ale czy naprawdę chcemy oddać nasze dane na srebrnej tacy?</p> <p>Wyobraź sobie, że Batman musiałby podzielić się lokalizacją Batjaskini ze wszystkimi. Nie byłoby to zbyt fajne, prawda? Tutaj wchodzi w grę uruchomienie modelu AI na swoim lokalnym komputerze. To jak posiadanie swojej własnej Batjaskini (bez fajnych gadżetów i pojazdów w stylu nietoperza, oczywiście).</p> <p>Plusy uruchamiania LLM na maszynach lokalnych:</p> <ul><li>Prywatność danych: Jest to jedna z największych zalet uruchamiania modeli LLM na maszynach lokalnych. Korzystając z własnej infrastruktury, użytkownik ma większą kontrolę nad swoimi danymi i unika przekazywania ich do zewnętrznych serwerów lub chmur. Dla osób lub organizacji, które szczególnie dbają o prywatność danych, jest to kluczowe.</li> <li>Szybkość działania: Uruchamianie modeli LLM na lokalnych maszynach może być szybsze niż korzystanie z modeli działających w chmurze. Dzięki temu można uzyskać wyniki generowania tekstu błyskawicznie, bez opóźnień związanych z przesyłaniem danych do zdalnych serwerów.</li> <li>Brak opłat za korzystanie: Często korzystanie z modeli LLM w chmurze może być powiązane z opłatami, które rosną w miarę zwiększania ilości generowanego tekstu. Uruchamianie modeli lokalnie może pozwolić uniknąć tych kosztów i oszczędzić na długoterminowej współpracy.</li> <li>Modyfikowalność i dostosowywanie: Korzystając z maszyn lokalnych, użytkownik ma pełną kontrolę nad konfiguracją i dostosowaniem modeli LLM. Można zmieniać parametry, testować różne warianty modeli i dostosowywać je do swoich potrzeb.</li> </ul> <p>Minusy uruchamiania LLM na maszynach lokalnych:</p> <ul><li>Wymagania sprzętowe: Niektóre modele LLM, zwłaszcza te zaawansowane, mogą wymagać znacznych zasobów sprzętowych, takich jak duża ilość pamięci RAM czy mocny procesor. Uruchomienie ich na komputerze osobistym może być utrudnione lub niemożliwe ze względu na ograniczenia sprzętowe.</li> <li>Kompleksowość instalacji: Instalacja i konfiguracja modeli LLM na lokalnych maszynach może być skomplikowana, szczególnie dla osób bez doświadczenia w programowaniu czy obszarze sztucznej inteligencji. Wymaga to znalezienia odpowiednich wersji bibliotek, narzędzi i zależności, co może być czasochłonne i frustrujące.</li> <li>Brak skalowalności: Uruchomienie modelu LLM na maszynie lokalnej ogranicza skalowalność generowania tekstu. Jeśli potrzebujemy dużej ilości generowanego tekstu lub jednoczesnego dostępu wielu użytkowników, lokalne środowisko może nie być wystarczające.</li> <li>Ograniczona aktualizacja modeli: W porównaniu do korzystania z modeli LLM w chmurze, aktualizacje modeli mogą być trudniejsze do przeprowadzenia na maszynach lokalnych. Wymaga to ręcznej aktualizacji i utrzymania modelu, co może być problematyczne, gdy pojawią się nowe i ulepszone wersje modeli.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Screenshot%202023-08-01%20232108-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Screenshot%202023-08-01%20232108-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Screenshot%202023-08-01%20232108-1400.webp"/> <img src="/assets/img/Screenshot%202023-08-01%20232108.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Diagram z artykułu opublikowanego w magazynie Research on Foundation Models (CRFM) w Stanford. Źródło: <a href="https://crfm.stanford.edu/">CRFM</a> </div> <h2 id="llama-kompaktowy-potwór-stworzony-przez-meta-ai">LLaMA: Kompaktowy potwór stworzony przez Meta AI</h2> <p>LLaMA to podstawowy model językowy, który osiągnął coś niesamowitego. Mimo że jest 13 razy mniejszy od kolosalnego GPT-3, przewyższa ten ostatni na większości benchmarków! Ten kompaktowy potwór może być uruchamiany na lokalnych maszynach - jedna odważna jednostka nawet zdołała go uruchomić na Raspberry Pi!</p> <p>Teraz, dzięki pewnym nieprzewidzianym okolicznościom, LLaMA jest dostępny do użytku niekomercyjnego. Został stworzony przez utalentowany zespół w Meta AI, a LLaMA oraz jego “rodzeństwo” - Alpaca - sprawiają, że lokalne wykorzystanie sztucznej inteligencji staje się bardziej dostępne niż kiedykolwiek wcześniej. Więc, bez zbędnych zwłok, zaczynajmy tę wspaniałą podróż!</p> <p>Pierwszym z brzegu pomysłem na skorzystaniu z wymiarów Raspberry PI byłoby stworzenie stworzenie salonu, gdzie każde urządzenie polegałoby na osobnym modelu i użytkownicy mogliby się z nimi komunikować, jednocześnie tworząc wirtualną historie. Byłoby to o tyle ciekawe, że spędzenie pewnego czasu w tym lokalu, posunięcie historii dalej i pozostawienie jej w tym samym miejscu dla kolejnych klientów lokalu. W ten sposób każdy mógłby wnieść swój wkład w historię, a jednocześnie cieszyć się z tego, co stworzyli inni.</p> <h2 id="instalacja-i-uruchamianie-llama">Instalacja i uruchamianie LLaMA</h2> <p>Sklonuj repozytorium i zainstaluj niezbędne wymagania z https://gichub.com/cockroiJpeanuVdolai.</p> <p>Aby rozpocząć, uruchom polecenie:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">npx</span> <span class="n">dalaî</span> <span class="n">install</span> <span class="mi">7</span><span class="n">B</span>
</code></pre></div></div> <p>Zanim przejdziesz dalej, upewnij się, że LLaMA-7B potrzebuje około 31 GB pamięci. Sprawdź, czy na twoim komputerze jest wystarczająco dużo miejsca na tego małego, ale potężnego gościa. Sam miałem z tym sporo problemów!</p> <p>Aby uruchomić LLaMA, wystarczy wpisać:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">npx</span> <span class="n">dalai</span> <span class="n">serves</span>
</code></pre></div></div> <p>I to wszystko! Masz teraz duży model językowy działający lokalnie. Gratulacje! Dlaczego? Ponieważ musiałem przejść przez wiele trudności, aby to uruchomić, takie jak dopasowywanie określonych wersji Pythona i Node. Szczegóły możesz znaleźć w pliku Readme na stronie https://github.com/cocktailpeaonut/dalai.</p> <p>Jednak kiedy to uruchomiłem, otrzymałem mnóstwo bezsensownych ciągów liter w odpowiedzi na proste pytanie “Mam ochotę coś zjeść, ponieważ…”. Po dokładniejszym zbadaniu wygląda na to, że jest to znany problem. Ktoś w kanale dyskusji sugerował: “Sprawdź model Alpaca”, więc to zrobiłem.</p> <h2 id="alpaca-cudo-które-podąża-za-instrukcjami">Alpaca: Cudo, które podąża za instrukcjami</h2> <p>Alpaca to wersja fine-tuningowana LLaMA, zaprojektowana tak, aby podążała za instrukcjami, podobnie jak ChatGPT. Niesamowite jest to, że cały proces dopasowania kosztował mniej niż 600 dolarów! Porównując to z ogromną ceną 5 milionów dolarów za GPT-3.5, to prawdziwa okazja!</p> <p>Jak to osiągnięto? Model tekstu OpenAI - davinci-003 - nieświadomie pomógł, przekształcając 175 zadań samouczka w aż 52 000 przykładów podążających za instrukcjami do nadzorowanego dopasowania. Mówię o inteligentnym rozwiązaniu! Autorami tego niesamowitego modelu są Rohan Taori i inni. To takie kreatywne - praktycznie użyli da-vinci-03 jako nauczyciela dla LLaMA, aby stworzyć Alpacę! Całą pracę można znaleźć w artykule na stronie htps://crfm.stanford.edu/2023/03/13/alpaco.html</p> <h2 id="instalacja-i-uruchamianie-alpaca">Instalacja i uruchamianie Alpaca</h2> <p>Aby zainstalować Alpacę, wystarczy uruchomić:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">npx</span> <span class="n">dalai</span> <span class="n">alpaca</span> <span class="n">install</span> <span class="mi">78</span>
</code></pre></div></div> <p>Alpaca to lekki model, który wymaga tylko 4 GB pamięci, więc nie zajmie wiele miejsca na twoim komputerze. Aby uruchomić Alpacę, po prostu powtórz polecenie:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">npx</span> <span class="n">dalai</span> <span class="n">alpaca</span> <span class="n">serves</span>
</code></pre></div></div> <p>I gotowe! Masz teraz własny model ChatGPT, gotowy do działania!</p> <h2 id="wszechstronne-api-dalai">Wszechstronne API Dalai</h2> <p>To nie koniec zabawy - biblioteka Dalai oferuje również interfejs API, który umożliwia integrację zarówno LLaMA, jak i Alpaki w twoje własne aplikacje. Otwiera to świat możliwości dla innowacyjnych projektów i eksperymentów na twoim lokalnym komputerze.</p> <p>Pomyśl o stworzeniu swojego własnego chatbota opartego na sztucznej inteligencji, budowaniu inteligentnego asystenta do pisania czy nawet opracowaniu nauczyciela AI dla twojego ulubionego przedmiotu! Teraz, kiedy nie jesteś ograniczony do 32 tysięcy słów, możesz karmić modele wszystkimi klasykami napisanymi przez swojego ulubionego autora (który już nie żyje, aby dać nam więcej magicznych dzieł).</p> <p>Baw się dobrze z lokalnymi modelami LLM i ciesz się wspaniałymi możliwościami, jakie oferują. Sztuczna inteligencja staje się coraz bardziej dostępna, co pozwala nam na bardziej kreatywną i interesującą pracę z modelami językowymi na naszych własnych komputerach.</p>]]></content><author><name></name></author><category term="article"/><category term="AI"/><category term="sztuczna-inteligencja"/><category term="generatywne-ai"/><category term="llm"/><category term="llama"/><category term="alpaca"/><summary type="html"><![CDATA[Krótki artykuł o tym jak uruchomić LLM lokalnie.]]></summary></entry><entry><title type="html">AWS a linie lotnicze, jak to działa?</title><link href="https://szymok.github.io/blog/2023/aws-airport/" rel="alternate" type="text/html" title="AWS a linie lotnicze, jak to działa?"/><published>2023-06-25T08:42:12+00:00</published><updated>2023-06-25T08:42:12+00:00</updated><id>https://szymok.github.io/blog/2023/aws-airport</id><content type="html" xml:base="https://szymok.github.io/blog/2023/aws-airport/"><![CDATA[<h2 id="wstęp">Wstęp</h2> <p>Choć to historia mogłaby wydawać się jak scena z filmu, jest to tylko wymyślony scenariusz, stworzony na potrzeby tego artykułu. Celem tego opisu jest zilustrowanie, jak łatwo można przegapić lot, gdy nie jesteśmy świadomi konsekwencji niezauważenia upływu czasu na lotnisku.*</p> <p>Grupa przyjaciół przybyła na Lotnisko Chopina w Warszawie z dużym wyprzedzeniem przed planowanym odlotem. Byli podekscytowani zbliżającą się podróżą do Nowego Jorku - mieli spędzić tam dwa tygodnie, zwiedzając miasto i ciesząc się amerykańskim stylem życia. Po odprawie bagażu, kontroli bezpieczeństwa i przepustkach imigracyjnych, zdecydowali się na krótki odpoczynek w jednej z restauracji lotniska.</p> <p>Czas mijał niezauważenie, kiedy rozmawiali, jedli i śmiali się, nieświadomi tego, że ich samolot miał odlecieć za niecałą godzinę. Gdy w końcu spojrzeli na zegarek, zrozumieli, że nie mają już czasu na luzie dotrzeć do bramki. Zgromadzili swoje rzeczy i w pośpiechu ruszyli w kierunku bramki.</p> <p>Linie lotnicze rozpoczęły procedurę wejścia na pokład na godzinę przed planowanym odlotem, a ta zakończyła się w ciągu 30 minut. Jednak grupa przyjaciół była nadal nieobecna. Mimo wielokrotnych ogłoszeń, aby zgromadzili się przy bramce, nie było żadnej reakcji. Pracownik linii lotniczych, nie mogąc ich znaleźć, poinformował o tym swoich przełożonych. Bramka została zamknięta, a samolot wystartował 10 minut przed planowanym odlotem.</p> <p>Grupa przyjaciół dotarła do bramki 5 minut przed planowanym odlotem. Z przerażeniem zobaczyli, że bramka jest już zamknięta, a samolot zaczyna się oddalać. Zrozumieli, że przegapili swój lot. Byli załamani, że ich długo planowane wakacje zostały nagle zrujnowane.</p> <p>Podszedł do nich pracownik lotniska i wyjaśnił, że powinni byli być przy bramce co najmniej 30 minut przed odlotem. Z ciężkim sercem zarezerwowali nocleg w hotelu lotniskowym, zdecydowani na złapanie następnego lotu do Nowego Jorku.</p> <p>Tak jak w wielu przypadkach, przegapienie lotu przez tę grupę przyjaciół to kolejny przykład na to, jak łatwo można przecenić czas potrzebny na dotarcie do bramki, zwłaszcza jeżeli przemawiają do nas różnego rodzaju rozproszenia.</p> <hr/> <h2 id="wyzwania-związane-z-bookowaniem-lotów">Wyzwania związane z bookowaniem lotów</h2> <p>Nie jest rzadkością, że pasażerowie spóźniają się na swój lot, nawet po otrzymaniu karty pokładowej, jak mogliśmy zobaczyć w powyższej anegdocie. Istnieje kilka powodów, dlaczego tak się dzieje.</p> <ul> <li> Niedoszacowanie wymaganego czasu: Pasażerowie mogą nie zdawać sobie sprawy, ile czasu potrzebują, aby dotrzeć do bramki, zwłaszcza jeśli nie znają lotniska lub mają do pokonania duże odległości. Mogą również niedoszacować czasu potrzebnego na kontrole bezpieczeństwa i inne procedury.</li> <li> Opóźnienia lotów: Nawet jeśli została wydana karta pokładowa, loty mogą być opóźnione z różnych powodów, takich jak pogoda, problemy techniczne lub zator ruchu lotniczego. Pasażerowie mogą nie zdawać sobie sprawy, że ich lot został opóźniony i przegapić czas wejścia na pokład.</li> <li> Wolne wejście na pokład: Proces wejścia na pokład może potrwać długo, zwłaszcza jeśli pasażerowie nie stosują się do instrukcji linii lotniczych. To może prowadzić do opóźnień, utraty połączeń i innych problemów.</li> <li> Problemy z bezpieczeństwem: Pasażerowie mogą mieć problemy z bezpieczeństwem, takie jak niemożność zabrania określonych przedmiotów na pokładzie lub konieczność dodatkowej kontroli. To może powodować opóźnienia.</li> <li> Problemy komunikacyjne: Linie lotnicze mogą nie dostarczać jasnych instrukcji ani nieefektywnie komunikować się z pasażerami podczas procesu wejścia na pokład. Nagłe zmiany bramek mogą prowadzić do zamieszania i opóźnień.</li> </ul> <p>Interesujące jest, że w ostatnich latach lotniska na całym świecie wprowadzają nowoczesne technologie, takie jak sztuczna inteligencja, chmura obliczeniowa i uczenie maszynowe, aby zapobiec sytuacjom, w których pasażerowie przegapiają swoje loty. Dzięki wykorzystaniu zaawansowanych algorytmów i analizie danych, te technologie mogą pomóc w zoptymalizowaniu procesów lotniskowych i minimalizacji opóźnień.</p> <p>Przykładem jest wykorzystanie sztucznej inteligencji do prognozowania czasu potrzebnego na przejście przez kontrolę bezpieczeństwa. Za pomocą analizy danych historycznych, algorytmy mogą przewidzieć, jak długo zajmie pasażerom przejście przez kontrolę i ustalić optymalne czasy przybycia na lotnisko.</p> <p>Chmura obliczeniowa jest również wykorzystywana do przechowywania i przetwarzania ogromnych ilości danych związanych z lotniskami. Dzięki temu, informacje o lotach, pasażerach, bagażach i innych czynnikach mogą być łatwo dostępne i szybko przetwarzane, co pozwala na lepsze zarządzanie operacjami lotniska.</p> <p>Uczenie maszynowe również odgrywa istotną rolę w zapobieganiu przegapieniu lotów. Algorytmy uczą się na podstawie danych historycznych i aktualnych, identyfikują wzorce i czynniki ryzyka, które mogą prowadzić do opóźnień lub przegapienia lotu. Dzięki temu, systemy mogą ostrzegać personel lotniska i pasażerów o potencjalnych problemach i proponować działania zaradcze.</p> <p>To fascynujące, jak nowoczesne technologie mogą pomóc w poprawie doświadczenia podróżowania lotniczego i minimalizacji ryzyka przegapienia lotu. Warto śledzić rozwój tych rozwiązań i być na bieżąco z innowacjami w branży lotnictwa.</p> <hr/> <h2 id="możliwości-jakie-daje-ai-i-ml">Możliwości jakie daje AI i ML</h2> <p>Sztuczna inteligencja i uczenie maszynowe mogą pomóc w rozwiązaniu większości z powyższych problemów. Wykorzystajmy tę samą anegdotę, aby zobaczyć jak.</p> <p>Podróżująca grupa przyjaciół z niecierpliwością czekała na wizytę u swojej rodziny w Ameryce przez wiele miesięcy. Przybyła na lotnisko w Dubaju na cztery godziny przed swoim lotem, odprawiła bagaż i przeszła przez kontrole imigracyjne i bezpieczeństwa. Ponieważ miała kilka godzin do wylotu, postanowiła zrobić trochę zakupów i zjeść coś. Jednak straciła poczucie czasu i nie wiedziała, że powinna dotrzeć do bramki na 30 minut przed planowanym odlotem samolotu.</p> <p>Na szczęście lotnisko miało system bookingu oparty na AI, który gwarantował bezproblemowe bookowanie wszystkich pasażerów. System ten wykorzystywał Internet rzeczy (IoT) i uczenie maszynowe do śledzenia ruchów pasażerów na lotnisku i szacowania ich czasu przybycia do bramki.</p> <p>Kiedy system przewidział, że przyjaciele mogą się spóźnić, natychmiast zaalarmował pracowników bramki i personel linii lotniczych, aby ich zlokalizować. System ten wykorzystywał technologię rozpoznawania twarzy i inne technologie śledzenia, aby precyzyjnie zlokalizować ich miejsce na lotnisku, a w ciągu kilku minut pracownik lotniska był w stanie ich znaleźć i odprowadzić do bramki.</p> <p>Spóźnieni mogli bezproblemowo wejść na pokład swojego lotu, a także cieszyć się zrobionymi zakupami - wszystko to dzięki bezproblemowemu i efektywnemu procesowi bookingu, który umożliwiły AI, IoT i uczenie maszynowe.</p> <p>Fakty są takie, że technologia AI i uczenie maszynowe stają się coraz bardziej niezbędne w świecie lotnictwa. Możemy oczekiwać, że tego typu systemy staną się coraz bardziej powszechne w przyszłości, zapewniając lepszą organizację i wygodę dla pasażerów. Ciekawe jest to, jak technologia może przekształcić prozaiczne zadania, takie jak czekanie na lot, w bardziej przyjemne i bezstresowe doświadczenia. W przyszłości możemy spodziewać się jeszcze więcej innowacyjnych rozwiązań z wykorzystaniem AI, IoT i uczenia maszynowego w branży lotniczej.</p> <hr/> <h2 id="aws-ai-ml-analiza-danych-i-iot-w-branży-lotniczej">AWS: AI, ML, analiza danych i IoT w branży lotniczej</h2> <p>Opisane powyżej bezproblemowe bookowanie na lot można łatwo zrealizować, wykorzystując usługi AWS Cloud. Dostępnych jest wiele urządzeń IoT, które mogą śledzić ruchy pasażera czy personelu lotniczego za pomocą geofencingu i BLE (Bluetooth o niskim zużyciu energii).</p> <p>Na przykład, beacony mogą pokryć obszar od 5m do 2,5km. Wysyłają one sygnały do urządzeń, takich jak telefony komórkowe, które są mapowane z ich lokalizacją. Te informacje są przechowywane w AWS RDS, co pomaga w detekcji lokalizacji pasażera. Można także wykorzystać kamery do śledzenia ruchów.</p> <p>AWS oferuje szereg usług AI, ML, analizy danych i IoT (Internet rzeczy), które można wykorzystać do budowania inteligentnych i opartych na danych aplikacji.</p> <p>Do stworzenia bezproblemowego rozwiązania bookowania na lot można wykorzystać następujące usługi:</p> <ul> <li> Amazon SageMaker: To kompleksowo zarządzana usługa, która dostarcza deweloperom i naukowcom narzędzi do budowania, trenowania i wdrażania modeli uczenia maszynowego na dużą skalę.</li> <li> Amazon Rekognition: Usługa analizy obrazów i wideo oparta na głębokim uczeniu, która może wykrywać obiekty, twarze i tekst na obrazach i wideo.</li> <li> Amazon Comprehend: Usługa przetwarzania języka naturalnego, która może analizować tekst i wydobywać z niego informacje takie jak sentyment, jednostki i kluczowe frazy.</li> <li> Amazon Polly: Usługa text-to-speech, która może przekształcać tekst w realistyczne mowy w wielu językach i głosach.</li> <li> Amazon Translate: Usługa tłumaczenia maszynowego oparta na sieciach neuronowych, która może tłumaczyć tekst między językami z dużą precyzją.</li> <li> Amazon Transcribe: Usługa automatycznego rozpoznawania mowy, która może transkrybować pliki audio i wideo na tekst.</li> <li> Amazon Forecast: Kompleksowo zarządzana usługa prognozowania, która wykorzystuje uczenie maszynowe do dostarczania wysoce precyzyjnych prognoz.</li> <li> Amazon Personalize: Usługa, która zapewnia rekomendacje w czasie rzeczywistym dotyczące treści, produktów i usług, wykorzystując algorytmy uczenia maszynowego.</li> </ul> <hr/> <h2 id="amazon-sagemaker---budowanie-trenowanie-i-wdrażanie-modeli-uczenia-maszynowego">Amazon SageMaker - budowanie, trenowanie i wdrażanie modeli uczenia maszynowego</h2> <p>Amazon SageMaker to potężna platforma uczenia maszynowego z standardowym interfejsem, która dostarcza kompletny zestaw narzędzi i usług do szybkiego budowania, trenowania i wdrażania modeli uczenia maszynowego na dużą skalę. SageMaker wykorzystuje kontenery do opakowania ulubionych algorytmów i frameworków, w tym wbudowanych algorytmów takich jak XGBoost, DeepAR i FM, a także frameworków takich jak PyTorch, SKLearn i TensorFlow.</p> <p>Niektóre z kluczowych usług dostarczanych przez Amazon SageMaker to:</p> <ul> <li>Etykietowanie danych: Ground Truth w SageMakerze to w pełni zarządzana usługa etykietowania danych, która ułatwia etykietowanie zestawów danych za pomocą anotatorów ludzkich lub wbudowanych modeli uczenia maszynowego.</li> <li>Budowanie modeli: SageMaker oferuje szereg wbudowanych algorytmów i frameworków do budowania, trenowania i wdrażania modeli uczenia maszynowego. Obsługuje także tworzenie niestandardowych algorytmów przy użyciu popularnych frameworków takich jak TensorFlow, MXNet i PyTorch.</li> <li>Trenowanie modeli: SageMaker zapewnia skalowalne i rozproszone środowisko treningowe (z wykorzystaniem GPU i wielu instancji), które pomaga w trenowaniu efektywnych modeli uczenia maszynowego na dużych zbiorach danych.</li> <li>Hostowanie modeli: SageMaker zapewnia w pełni zarządzane środowisko hostowania modeli, umożliwiające deweloperom wdrażanie modeli uczenia maszynowego jako interfejsy API z automatycznym skalowaniem, monitorowaniem i możliwością debugowania.</li> <li>Tuning modeli: Amazon SageMaker oferuje usługę automatycznego strojenia modeli, która umożliwia naukowcom danych optymalizację hiperparametrów i poprawę dokładności modelu bez konieczności ingerencji manualnej.</li> <li>Wnioskowanie w czasie rzeczywistym: SageMaker zapewnia w pełni zarządzaną, wysoko dostępną usługę wnioskowania w czasie rzeczywistym, która może skalować się, aby obsłużyć miliony żądań na sekundę.</li> <li>Wnioskowanie wsadowe: Amazon SageMaker dostarcza w pełni zarządzaną usługę wnioskowania wsadowego, która może przetwarzać duże ilości danych i dostarczać predykcje w sposób kosztowo efektywny. Pełny workflow uczenia maszynowego: Amazon SageMaker zapewnia pełen workflow uczenia maszynowego, obejmujący przygotowanie danych, inżynierię cech, trening modelu, wdrażanie i monitorowanie.</li> <li>Integracja z innymi usługami AWS: Amazon SageMaker integruje się z innymi usługami AWS, takimi jak S3, Lambda, Step Functions i CloudFormation, aby zapewnić spójne doświadczenie z uczeniem maszynowym. Dzięki usługom Amazon SageMaker lotniska mogą skutecznie budować, trenować i wdrażać modele uczenia maszynowego, a także obsługiwać wnioskowanie w czasie rzeczywistym i wsadowe. To zapewnia płynne i efektywne procesy związane z analizą danych i predykcją, co ma zastosowanie w liniach lotniczych.</li> </ul> <hr/> <h2 id="rola-usług-aws-rekognition-iot-core-i-greengrass">Rola usług AWS Rekognition, IoT Core i Greengrass</h2> <p>W oparciu o infrastrukturę IoT, beacony i kamery mogą być zainstalowane w całym terminalu lotniska w celu wykrywania ruchów pasażerów. AWS Greengrass może być wykorzystany do wdrażania funkcji AWS Lambda, które przechwytują obrazy z lokalnych kamer/czujników i wysyłają je do AWS Rekognition w celu analizy. Kamery mogą przechwytywać obrazy lub nagrania wideo w regularnych odstępach czasu (co 5/10 sekund) i wysyłać je do bramy AWS IoT.</p> <p>Zdolność do rozpoznawania twarzy w usłudze AWS Rekognition może być wykorzystana do analizy obrazów lub nagrań wideo, wykrywania obecności poszczególnych pasażerów oraz śledzenia ich ruchów. Na podstawie wyników analizy można generować alerty i wysyłać powiadomienia, jeśli w określonym obszarze występuje duże zagęszczenie pasażerów lub zatory, lub jeśli pasażer porusza się w kierunku niewłaściwej bramki.</p> <p>Wyniki analizy mogą być przesyłane z powrotem do AWS Greengrass w celu dalszej obróbki lub podjęcia działań, takich jak uruchamianie lokalnych alarmów lub wysyłanie powiadomień. Dzięki temu systemowi możliwe jest bieżące monitorowanie ruchu pasażerów w terminalu lotniska, identyfikowanie problematycznych obszarów lub sytuacji oraz podejmowanie odpowiednich działań w celu zapewnienia płynnego przebiegu procesu zaokrętowania.</p> <hr/> <h2 id="tworzenie-opartego-na-aiml-rozwiązania-do-obsługi-lotu">Tworzenie opartego na AI/ML rozwiązania do obsługi lotu</h2> <p>Nasze rozwiązanie wykorzystuje algorytm XGBoost do binarnej klasyfikacji, popularny wybór do przewidywania wystąpienia zdarzenia na podstawie zestawu cech wejściowych. Staramy się przewidzieć, czy pasażer, który odprawił bagaż i robi zakupy, dotrze do bramki wejściowej 30 minut przed planowym czasem odlotu lotu. Wbudowany algorytm XGBoost w SageMaker ułatwia trenowanie i wdrażanie potężnych modeli uczenia maszynowego. Dzięki niewielkiemu przygotowaniu danych i dostrojeniu hiperparametrów, budowanie modeli, które szybko dokonują dokładnych prognoz w różnych zadaniach, jest prostym procesem. SageMaker dostarcza Jupyter Notebook w chmurze, który jest łatwy w tworzeniu i używaniu. Oto kroki postępowania:</p> <ul> <li>Przygotowanie danych: Nasze dane powinny być w formacie, z którym XGBoost może pracować. Zazwyczaj oznacza to plik CSV z kolumnami dla cech i kolumną docelową dla etykiety.</li> <li>Przesyłanie danych: Musimy przesłać dane do kubełka S3, aby SageMaker mógł na niego uzyskać dostęp.</li> <li>Tworzenie zadania trenującego: Możemy utworzyć zadanie trenujące, określając lokalizację danych treningowych w S3/Datalake oraz hiperparametry, których chcemy użyć dla algorytmu XGBoost. Można to zrobić za pośrednictwem konsoli SageMaker, pakietu SDK SageMaker lub AWS CLL.</li> <li>Monitorowanie zadania trenującego: Po rozpoczęciu zadania trenującego możemy monitorować jego postęp za pośrednictwem konsoli SageMaker lub pakietu SDK.</li> <li>Wdrażanie modelu: Po zakończeniu zadania trenującego możemy wdrożyć wytrenowany model jako punkt końcowy, który może być używany do wnioskowania.</li> <li>Testowanie modelu: Możemy przetestować wdrożony model, wysyłając nowe dane i obserwując predykcje, które generuje.</li> </ul> <h3 id="dane-wejściowe">Dane wejściowe</h3> <p>Dane wejściowe dla naszego modelu składają się z zestawu cech dotyczących ruchu pasażera w obrębie lotniska, jego zachowania podczas zakupów i czasu przybycia na lotnisko. Te cechy są zbierane za pomocą urządzeń IoT, takich jak kamery, beacons i czujniki rozmieszczone w całym lotnisku.</p> <p>Oto cechy wejściowe, które zostały użyte w naszym modelu:</p> <ul> <li>Czas przybycia: Dane dotyczące czasu, o którym pasażer przybywa na lotnisko, są zbierane od pasażerów, którzy już dokonali odprawy online. Czujniki IoT przy wejściu na lotnisko zbierają te dane i przekazują je do magazynu danych. Dla pasażerów, którzy nie dokonali odprawy online, dane te są gromadzone na stanowisku odprawy lub w automacie, z którego otrzymuje się kartę pokładową.</li> <li>Stan pasażera: Informuje, czy pasażer przeszedł kontrolę imigracyjną, kontrolę bezpieczeństwa, odprawę itp.</li> <li>Czas trwania zakupów: To jest czas, jaki pasażerowie spędzają na zakupach po otrzymaniu karty pokładowej i po przejściu kontroli imigracyjnej/bezpieczeństwa.</li> <li>Odległość od bramki: To jest odległość między strefą zakupów a bramką wejściową i jest obliczana za pomocą czujników IoT rozmieszczonych w całej strefie wolnocłowej.</li> <li>Czas przybycia na bramkę: To jest czas, o którym pasażer dociera na bramkę wejściową.</li> <li>Czas przewidywania będzie stale aktualizowany w innym rejestrze, aż pasażer dotrze do bramki wejściowej. Ciągłe alertowanie wiadomości zostanie wysłane na telefon komórkowy/smartfon pasażera oraz do sprzedawcy znajdującego się w pobliżu pasażera. W odpowiednim czasie zostanie poproszona o pomoc sprzedawcy w celu poinformowania pasażera o konieczności przemieszczenia się w kierunku bramki, aby wejść na pokład samolotu. Na telewizorze również pojawi się informacja dla pasażera o konieczności przemieszczenia się w kierunku bramki. Pasażer zostanie również oznaczony na mediach społecznościowych i poproszony o przemieszczenie się w kierunku bramki. Wszystko to będzie działo się automatycznie dzięki różnym usługom AWS AI/ML, IoT i innym.</li> <li>Planowany czas odlotu: To jest zaplanowany czas odlotu lotu pasażera.</li> <li>Opóźnienie lotu: Wskazuje opóźnienie w zaplanowanym czasie odlotu lotu pasażera.</li> <li>Wzorzec chodu: Jest to wzorzec chodu zarejestrowany za pomocą urządzenia noszonego przez pasażera lub smartfona. Jeśli nie jest dostępny, zostanie użyta wartość domyślna.</li> <li>Bagaż podręczny: Te dane będą zbierane podczas odprawy, ale mogą być niejednoznaczne ze względu na dodawanie zakupów.</li> <li>Zatłoczenie terminala: To jest miara zajętości terminala w chwili przybycia pasażera na lotnisko i na drodze do bramki. Na urządzeniu smartfona pasażera wyświetlany będzie również mapę cieplną.</li> </ul> <h3 id="przygotowanie-danych">Przygotowanie danych</h3> <p>Przed przystąpieniem do trenowania modelu przeprowadziliśmy kilka kroków przygotowawczych, jak następuje:</p> <p><b>Czyszczenie:</b> Usuwanie nieprawidłowych lub brakujących danych.</p> <p><b>Przetwarzanie wstępne:</b> Skalowanie cech liczbowych, aby mieć tę samą skalę, i normalizacja danych w celu poprawy wydajności modelu.</p> <p><b>Inżynieria cech:</b> Tworzenie nowych cech na podstawie istniejących danych w celu poprawy dokładności modelu.</p> <h3 id="trenowanie-i-wdrożenie-modelu">Trenowanie i wdrożenie modelu</h3> <p>Po przygotowaniu danych użyliśmy wbudowanego algorytmu XGBoost w Amazon SageMaker do trenowania naszego modelu klasyfikacji binarnej. Następnie wdrożyliśmy wytrenowany model za pomocą usługi wdrożenia modelu SageMaker, która automatycznie skaluje model, aby obsłużyć duże ilości ruchu.</p> <h3 id="integracja-z-urządzeniami-iot">Integracja z urządzeniami IoT</h3> <p>Następnie zintegrowaliśmy wdrożony model uczenia maszynowego z urządzeniami IoT, takimi jak kamery i czujniki, aby monitorować ruchy pasażerów i przewidywać ich czasy przybycia na bramkę.</p> <p><b>System alarmowy:</b> Do zbudowania systemu alarmowego użyliśmy usługi Amazon Simple Notification Service (SNS), aby powiadamiać agentów bramkowych i personel linii lotniczych, gdy pasażerom przewidywane jest spóźnienie.</p> <p><b>System śledzenia:</b> Do zbudowania systemu śledzenia użyliśmy rozpoznawania twarzy i innych technologii śledzenia, aby zlokalizować pasażerów, którzy mają przewidywane opóźnienie i eskortować ich do bramki.</p> <p>W sumie ta implementacja analizy predykcyjnej za pomocą SageMaker może pomóc liniom lotniczym optymalizować proces wejścia na pokład, przewidując, którzy pasażerowie mogą być zagrożeni spóźnieniem i podejmując proaktywne kroki, aby zapewnić, że dotrą na czas do bramki.</p> <h2 id="podsumowanie">Podsumowanie</h2> <p>Usługi AWS oferują różnorodne narzędzia i rozwiązania, które mogą zrewolucjonizować sposób działania lotnisk, prowadząc do znaczących popraw w obszarach efektywności, doświadczenia pasażera, bezpieczeństwa i zrównoważonego rozwoju. AWS IoT może usprawniać zarządzanie przepływem pasażerów, podczas gdy usługi uczenia maszynowego, takie jak Amazon SageMaker, mogą pomóc w przewidywaniu potencjalnych usterek w sprzęcie lotniskowym. Amazon Rekognition umożliwia bezproblemową odprawę i zwiększa bezpieczeństwo, a śledzenie bagażu w czasie rzeczywistym dzięki AWS IoT poprawia doświadczenia pasażerów. Z usługami analitycznymi AWS, takimi jak Amazon Redshift i Amazon Quicksight, lotniska mogą analizować ogromne ilości danych i podejmować świadome decyzje. Bezpieczne połączenia zapewnia AWS Direct Connect, a planowanie zasobów lotniska staje się bardziej efektywne dzięki mocy obliczeniowej chmury AWS. Zrównoważony rozwój jest również na wyciągnięcie ręki, dzięki zobowiązaniu Amazon do osiągnięcia 100% odnawialnego zużycia energii dla swojej globalnej infrastruktury.</p>]]></content><author><name></name></author><category term="article"/><category term="analiza-danych"/><category term="aws"/><category term="amazon"/><category term="s3"/><category term="lambda"/><category term="airport"/><category term="lotnisko"/><category term="technologia"/><category term="ai"/><category term="machine-learning"/><summary type="html"><![CDATA[Krótkie przedstawienie usług AWS, które pomagają w przypadku problemów na lotnisku.]]></summary></entry><entry><title type="html">Historia wizualizacji danych</title><link href="https://szymok.github.io/blog/2023/history-visualization/" rel="alternate" type="text/html" title="Historia wizualizacji danych"/><published>2023-06-11T11:59:00+00:00</published><updated>2023-06-11T11:59:00+00:00</updated><id>https://szymok.github.io/blog/2023/history-visualization</id><content type="html" xml:base="https://szymok.github.io/blog/2023/history-visualization/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/History-of-Data-Visualization-11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/History-of-Data-Visualization-11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/History-of-Data-Visualization-11-1400.webp"/> <img src="/assets/img/History-of-Data-Visualization-11.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Diagram nawiązujący do wizualizacji danych i historii. Źródło: <a href="https://www.researchgate.net/publication/221027352_Data_Mining_and_Data_Visualization" target="_blank">ResearchGate</a> </div> <h2 id="historia-wizualizacji-danych">Historia wizualizacji danych</h2> <p>Wizualizacja danych ma długą i fascynującą historię, sięgającą głęboko w przeszłość. Od prymitywnych malowideł naskalnych po dzisiejsze zaawansowane narzędzia komputerowe, wizualizacja danych odegrała znaczącą rolę w rozwijaniu naszego zrozumienia informacji i przedstawianiu jej w sposób zarówno atrakcyjny, jak i efektywny. W pierwszym rozdziale tej książki przyjrzymy się początkom wizualizacji danych i dowiemy się, jak nasza zdolność do przedstawiania informacji wizualnie ewoluowała na przestrzeni wieków.</p> <p>Nasza historia wizualizacji danych rozpoczyna się w odległej przeszłości, gdy ludzie odkrywali potrzebę przedstawiania danych w formie graficznej. Już tysiące lat temu nasi przodkowie stosowali prymitywne techniki, aby przekazać informacje wizualnie. Malowidła naskalne, hieroglify i piktogramy były pierwszymi krokami w procesie tworzenia graficznych reprezentacji danych. Te wczesne formy wizualizacji pomagały w komunikacji, dzieleniu się historiami i gromadzeniu wiedzy.</p> <p>Wraz z upływem czasu ludzie doskonalili swoje umiejętności w tworzeniu coraz bardziej zaawansowanych form wizualizacji danych. W średniowieczu powstały mapy, które umożliwiały przedstawienie geograficznych informacji w sposób czytelny i intuicyjny. W renesansie naukowcy i matematycy opracowywali wykresy i diagramy, które pomagały w analizowaniu danych liczbowych i zrozumieniu złożonych zależności.</p> <p>Jednak prawdziwa rewolucja w dziedzinie wizualizacji danych nastąpiła wraz z rozwojem technologii komputerowej. W drugiej połowie XX wieku powstały pierwsze programy komputerowe, które umożliwiły tworzenie interaktywnych grafik, wykresów i diagramów. Przy użyciu komputera, dane mogły być przedstawiane w sposób bardziej precyzyjny, elastyczny i efektywny niż kiedykolwiek wcześniej.</p> <p>W pierwszym części naszej podróży po historii wizualizacji danych zgłębimy te fascynujące etapy rozwoju. Będziemy badać ewolucję od prymitywnych rysunków naskalnych do zaawansowanych narzędzi wizualizacyjnych dostępnych obecnie. Przyjrzymy się kluczowym postaciom i przełomowym momentom, które wpłynęły na rozwój tej dziedziny.</p> <hr/> <h2 id="początki-wizualizacji-danych">Początki wizualizacji danych</h2> <p>“Pierwsze próby wizualizacji danych sięgają czasów prehistorycznych” - to zdanie rozbudza moją ciekawość. Był to okres, kiedy ludzie używali malowideł naskalnych i rysunków do przedstawienia informacji. Fascynujące jest to, jak nasi przodkowie z epoki kamienia potrafili przekazywać skomplikowane koncepty za pomocą prostych form wyrazu.</p> <p>Dla przykładu, jednym z najstarszych znanych dowodów na wizualizację danych jest malowidło naskalne odkryte w jaskini Lascaux we Francji. Te malunki, które datuje się na około 17 000 lat temu, przedstawiają różne zwierzęta, takie jak byki i konie, a także symboliczne znaki, które mogły reprezentować liczby czy zmiany pór roku. <a href="https://www.lascaux.fr/en">oficjalna strona jaskini Lascaux</a>, na której znajdują się informacje na temat prehistorycznych malowideł.</p> <p>Zauważalne jest, że ta prymitywna forma wizualizacji danych posiadała w sobie zarówno aspekt artystyczny, jak i informatyczny. Dzięki temu dzisiaj możemy dowiedzieć się więcej o życiu tych prehistorycznych ludzi - od ich codziennych zajęć, poprzez to, co jedli, aż do jakich zwierząt obawiali się najbardziej.</p> <p>Ciekawostką jest również fakt, że niektóre z tych malowideł mogą być wcześniejszymi formami map. Np. malowidło naskalne w jaskini w Bedeilhac w południowej Francji, które ma około 14 000 lat, zawiera układ linii i kropek, który według niektórych badaczy może przedstawiać okoliczne tereny.</p> <p>Jeśli chodzi o grafy z tego okresu, nie były one skomplikowane jak dzisiejsze wykresy słupkowe czy kołowe, ale z pewnością można zauważyć próbę przedstawienia pewnych wzorców i trendów. Na przykład, rysunki w jaskiniach często przedstawiały zwierzęta w różnych fazach ruchu, co mogło sugerować migracje tych gatunków w określonym czasie roku.</p> <p>Choć metody wizualizacji danych z tamtych czasów mogą wydawać nam się dziś prymitywne, stanowiły one podstawę dla rozwoju tej dziedziny, jaki widzimy obecnie. Wzory, symbole i obrazy wykorzystywane przez naszych przodków nie tylko pomagały im przetrwać, ale również przekazywały ważne informacje przyszłym pokoleniom.</p> <hr/> <h3 id="william-playfair-ojciec-współczesnej-wizualizacji-danych">William Playfair: Ojciec współczesnej wizualizacji danych</h3> <p>Playfair, szkocki ekonomista i inżynier, to postać, której nie da się pominąć, mówiąc o historii wizualizacji danych. To on w XVIII wieku wprowadził wykresy liniowe, słupkowe i kołowe jako narzędzia do prezentacji danych statystycznych.</p> <p>Jego dzieło “Commercial and Political Atlas” z 1786 roku jest uznawane za pierwsze znane zastosowanie wykresu liniowego do reprezentowania danych. Playfair zauważył, że wykresy mogą “przemawiać” do odbiorców bardziej bezpośrednio niż surowe liczby, pomagając im lepiej zrozumieć i zinterpretować dane.</p> <p>Dzięki innowacjom Playfaira wizualizacja danych stała się bardziej dostępna i zrozumiała. Wykresy liniowe, słupkowe i kołowe stały się podstawą analizy danych, a ich wpływ jest widoczny nawet w dzisiejszych narzędziach do wizualizacji danych.</p> <p>Poniżej znajduje się kilka przykładów wykresów, które Playfair stworzył w swojej książce “Commercial and Political Atlas”. Zauważ, jak wykresy te są podobne do tych, które tworzymy dzisiaj.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/1073px-1786_Playfair_-_Exports_and_Imports_of_Scotland_to_and_from_different_parts_for_one_Year_from_Christmas_1780_to_Christmas_1781-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/1073px-1786_Playfair_-_Exports_and_Imports_of_Scotland_to_and_from_different_parts_for_one_Year_from_Christmas_1780_to_Christmas_1781-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/1073px-1786_Playfair_-_Exports_and_Imports_of_Scotland_to_and_from_different_parts_for_one_Year_from_Christmas_1780_to_Christmas_1781-1400.webp"/> <img src="/assets/img/1073px-1786_Playfair_-_Exports_and_Imports_of_Scotland_to_and_from_different_parts_for_one_Year_from_Christmas_1780_to_Christmas_1781.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Na tym wykresie słupkowym przedstawiono import i eksport Szkocji z i do 17 krajów w 1781 roku. Źródło: <a href="https://en.wikipedia.org/wiki/William_Playfair#/media/File:1786_Playfair_-_Exports_and_Imports_of_Scotland_to_and_from_different_parts_for_one_Year_from_Christmas_1780_to_Christmas_1781.jpg">Wikipedia</a> </div> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Playfair-piechart-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Playfair-piechart-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Playfair-piechart-1400.webp"/> <img src="/assets/img/Playfair-piechart.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Wykres kołowy z Playfair's Statistical Breviary (1801), pokazujący proporcje imperium tureckiego znajdującego się w Azji, Europie i Afryce przed 1789 rokiem. Źródło: <a href="https://en.wikipedia.org/wiki/William_Playfair#/media/File:Playfair-piechart.jpg">Wikipedia</a> </div> <hr/> <h2 id="wizualizacja-danych-w-służbie-zdrowia">Wizualizacja danych w służbie zdrowia</h2> <p>Wizualizacja danych jest obecnie szeroko stosowana w wielu dziedzinach, ale jedną z najbardziej obiecujących jest służba zdrowia. Wizualizacja danych może pomóc w analizie i interpretacji danych medycznych, co może prowadzić do lepszych decyzji klinicznych i poprawy opieki zdrowotnej.</p> <hr/> <h3 id="florence-nightingale">Florence Nightingale</h3> <p>Najbardziej znane osiągnięcie Nightingale w dziedzinie wizualizacji danych to jej “diagram kołowy” (polar area diagram), który często nazywany jest “diagramem różycy”. Użyła go do ilustracji, jakie były przyczyny zgonów wśród żołnierzy podczas Wojny Krymskiej.</p> <p>Jej diagram różycy przedstawiał, że większość zgonów nie wynikała bezpośrednio z obrażeń wojennych, ale z chorób zakaźnych. Ta wizualizacja miała ogromny wpływ na reformy sanitarno-higieniczne w obozach wojskowych.</p> <p>Praca Nightingale była nie tylko innowacyjna pod kątem technicznym, ale miała również długotrwałe konsekwencje dla zdrowia publicznego. Dzięki jej wizualizacjom zwrócono uwagę na istotne kwestie higieny i opieki zdrowotnej, co przyczyniło się do poprawy warunków w obozach wojskowych, a później także w innych instytucjach zdrowotnych.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/R-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/R-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/R-1400.webp"/> <img src="/assets/img/R.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Diagram obszarowy biegunowy został wynaleziony przez Florence Nightingale, aby zobrazować skalę niepotrzebnych zgonów w brytyjskich szpitalach wojskowych podczas Wojny Krymskiej (1954-56). Źródło: <a href="https://en.wikipedia.org/wiki/Florence_Nightingale#/media/File:Diagram_of_the_causes_of_mortality_in_the_Army_in_the_East_FOLIO_I._VOL.I._Wellcome_L0000551.jpg">Wikipedia</a> </div> <p>Obszar każdego kolorowego klinu, mierzony od środka, jest proporcjonalny do reprezentowanej statystyki. Niebieskie klasy reprezentują zgony z “zapobiegawczych lub łagodzących” chorób zakaźnych (chorób zakaźnych takich jak cholera czy tyfus), różowe klasy zgony z ran, a szare klasy zgony z wszystkich innych przyczyn. Śmiertelność osiągnęła szczyt w styczniu 1855 roku, kiedy zmarło 2761 osób na choroby zakaźne, 83 z ran i 324 z innych przyczyn.</p> <p>Bazując na średniej sile armii wynoszącej 32393, Nightingale obliczyła roczną śmiertelność na poziomie 1174 na 1000. Diagram pochodzi od Bernarda Cohena, “Florence Nightingale,” Scientific American, marzec 1984. Oryginalnie pochodzi z książki Nightingale “Notes on Matters Affecting the Health, Efficiency and Hospital Administration of the British Army”, opublikowanej w 1858 roku.</p> <hr/> <h3 id="john-snow">John Snow</h3> <p>John Snow, angielski lekarz, jest znany z tego, że jako pierwszy zastosował wizualizację danych do badania epidemiologii. W 1854 roku, podczas epidemii cholery w Londynie, Snow stworzył mapę, która przedstawiała lokalizację przypadków zachorowań na cholerę w dzielnicy Soho.</p> <p>Snow zidentyfikował źródło epidemii jako publiczną pompę wodną na Broad Street. Zrobił to, lokalizując przypadki choroby na mapie, co pozwoliło mu zobaczyć skupisko w okolicy tej pompy. Ta wizualizacja była kluczowa dla zrozumienia, jak cholera rozprzestrzenia się przez zanieczyszczoną wodę.</p> <p>Praca Snowa pomogła zmienić podejście do zdrowia publicznego i zrozumieć, jak choroby zakaźne, takie jak cholera, mogą rozprzestrzeniać się w populacji. Jego metoda używania mapy do wizualizacji danych zdrowotnych jest nadal stosowana dzisiaj, na przykład w monitorowaniu rozprzestrzeniania się wirusa COVID-19.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/88b66df5d4c7aa5216284822e6591481-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/88b66df5d4c7aa5216284822e6591481-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/88b66df5d4c7aa5216284822e6591481-1400.webp"/> <img src="/assets/img/88b66df5d4c7aa5216284822e6591481.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Wykres pokazujący temperaturę i śmiertelność Londynu dla każdego tygodnia 11 lat, 1840-50 z Farr's Report on the 1849 epidemic. Numer WI L0039176, Wellcome Library Źródło: <a href="https://wellcomecollection.org/works/yp5q3q3n">Wellcome Collection</a> </div> <hr/> <h2 id="charles-minard-wizualizacja-danych-wojennych">Charles Minard: Wizualizacja danych wojennych</h2> <p>Charles Minard, francuski inżynier i ekonomista, jest sławny z powodu swojej niezwykłej umiejętności prezentowania skomplikowanych danych w prosty i zrozumiały sposób. Minard jest najbardziej znany z wyjątkowego diagramu przedstawiającego katastrofalną kampanię Napoleona w Rosji w 1812 roku. Ta innowacyjna wizualizacja, często uważana za “najlepszy wykres statystyczny wszech czasów”, jednocześnie ilustruje sześć różnych zmiennych: liczbę wojsk, odległość, temperaturę, datę, kierunek ruchu i lokalizację.</p> <p>Minard użył szerokości linii, aby reprezentować liczbę pozostałych sił Napoleona w różnych etapach marszu. Wizualizacja jest nie tylko estetycznie przyjemna, ale również mocno oddziałuje na odbiorcę poprzez pokazanie ogromu strat poniesionych podczas kampanii. W dodatku, dołączony do wykresu wykres liniowy ilustruje temperatury podczas odwrotu armii francuskiej, dodając kolejny wymiar do tej opowieści.</p> <p>Wizualizacja Minarda jest doskonałym przykładem tego, jak skomplikowane zestawy danych można przekształcić w intuicyjne obrazy, które pozwalają odbiorcy szybko zrozumieć kontekst i znaczenie prezentowanych informacji. Ta praca jest do dziś inspiracją dla specjalistów od wizualizacji danych na całym świecie.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/mapa-charles-minard-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/mapa-charles-minard-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/mapa-charles-minard-1400.webp"/> <img src="/assets/img/mapa-charles-minard.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Wykres przedstawiający liczbę wojsk Napoleona w czasie kampanii rosyjskiej w 1812 roku. Źródło: <a href="https://commons.wikimedia.org/wiki/File:Minard.png">Wikimedia Commons</a> </div> <p>Ten mapa pokazuje ruch wojsk podczas kampanii rosyjskiej. Liczba żołnierzy, którzy rozpoczęli kampanię, wynosiła około 442 000 - pokazane po lewej stronie mapy na brązowo. Do Moskwy dotarło 100 000 żołnierzy - prawa strona mapy na brązowo. Na dolnym, prawym, czarnym pasku mapa pokazuje liczbę żołnierzy, którzy opuścili Moskwę - 100 000 - a po prawej stronie na czarno wskazuje, że do Francji wróciło tylko 10 000 żołnierzy. Dolna część wykresu pokazuje skalę temperatury na całej trasie.</p> <p>Dzięki temu wykresowi mamy szczegółowy obraz tego, co zaszło w bitwie. Jeżeli przeanalizujesz wykres, łatwiej będzie zrozumieć i “zwizualizować” liczby niż na podstawie tekstu. Wyjaśnienie tekstowe utrudnia zrozumienie liczb w odpowiedniej kolejności wielkości. Spoglądając na wykres, możemy lepiej zrozumieć katastrofę, jaką była ta bitwa.</p> <hr/> <h2 id="początki-współczesnej-wizualizacji-danych">Początki współczesnej wizualizacji danych</h2> <p>Wizualizacja danych zaczęła się rozwijać wraz z rozwojem technologii komputerowych. W latach 60. XX wieku pojawiły się pierwsze komputery, które umożliwiły przetwarzanie i wizualizację dużych zbiorów danych. W tym samym czasie pojawiły się pierwsze narzędzia do wizualizacji danych, takie jak systemy graficzne, które umożliwiły użytkownikom tworzenie wykresów i diagramów bez konieczności pisania kodu.</p> <hr/> <h3 id="herman-hollerith-maszyna-do-przetwarzania-danych">Herman Hollerith: Maszyna do przetwarzania danych</h3> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/R%20(1)-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/R%20(1)-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/R%20(1)-1400.webp"/> <img src="/assets/img/R%20(1).jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Maszyna do sortowania i liczenia kart perforowanych zaprojektowana przez Hermana Holleritha. Źródło: <a href="https://americanhistory.si.edu/collections/search/object/nmah_694410">National Museum of American History</a> </div> <p>Herman Hollerith, amerykański wynalazca i statystyk, jest postacią, która zasługuje na szczególne uznanie w dziedzinie przetwarzania i wizualizacji danych. To on zaprojektował i skonstruował pierwszą funkcjonalną maszynę do przetwarzania danych - maszynę do sortowania i liczenia kart perforowanych. Ta innowacyjna technologia zrewolucjonizowała sposób, w jaki dane były zbierane i analizowane, stanowiąc punkt zwrotny dla przyszłych generacji komputerów.</p> <p>Dzięki swojemu wynalazkowi, Hollerith znacznie przyspieszył proces spisu powszechnego w Stanach Zjednoczonych w 1890 roku, co wcześniej zajmowało wiele lat. Jego maszyna potrafiła przetworzyć dane o populacji w ciągu zaledwie kilku miesięcy, co było wtedy niewyobrażalne.</p> <p>W 1896 roku Hollerith założył Tabulating Machine Company, firmę, która później przekształciła się w giganta technologicznego, znanego dzisiaj jako IBM. Wykorzystanie kart perforowanych do przechowywania i przetwarzania danych, zapoczątkowane przez Holleritha, stało się fundamentem dla rozwoju technologii informacyjnej. Bez jego przyczynkowego wkładu, historia wizualizacji danych mogłaby wyglądać zupełnie inaczej. Praca Holleritha położyła podwaliny pod nowoczesne metody analizy i wizualizacji danych, które teraz są nieodłączną częścią naszego świata.</p> <hr/> <h3 id="john-tukey-ojciec-eksploracyjnej-analizy-danych">John Tukey: Ojciec eksploracyjnej analizy danych</h3> <p>John Tukey, wybitny amerykański matematyk i statystyk, jest powszechnie uznawany za “ojca eksploracyjnej analizy danych” (EDA - Exploratory Data Analysis). EDA to podejście do analizy danych, które polega na eksploracji i wizualizacji danych przed formalnym testowaniem statystycznym, pozwalając na zrozumienie ich struktury, wykrycie anomalii, sprawdzenie założeń czy identyfikację potencjalnych modeli.</p> <p>Jednym z kluczowych wkładów Tukeya w dziedzinę wizualizacji danych jest wynalezienie box plotu (diagramu pudełkowego). Diagram ten to prosty, ale bardzo efektywny sposób prezentowania rozkładu danych. Dzięki box plotom, możemy łatwo zauważyć medianę, kwartyle i potencjalne wartości odstające, co daje nam podstawowe zrozumienie rozkładu danych.</p> <p>Tukey zawsze podkreślał wagę wizualizacji w procesie analizy danych. W swojej pracy “Eksploracyjna Analiza Danych” z 1977 roku, wyjaśnił jak różne metody wizualizacji, takie jak histogramy, wykresy punktowe czy wykresy Q-Q, mogą pomóc w zrozumieniu danych. Ta praca jest do dziś fundamentalnym źródłem wiedzy na temat EDA.</p> <p>Dziedzictwo Tukeya żyje w każdej analizie danych, która zaczyna się od dokładnego zrozumienia danych poprzez ich wizualizację. Jego wkład w dziedzinę statystyki i wizualizacji danych jest nieoceniony, a jego prace nadal inspirują kolejne generacje analityków danych.</p> <hr/> <h3 id="edward-tufte-wizualizacja-danych-w-xx-wieku">Edward Tufte: Wizualizacja danych w XX wieku</h3> <p>Edward Tufte, amerykański teoretyk informacji, jest niezaprzeczalnie jednym z najbardziej wpływowych pionierów w dziedzinie wizualizacji danych w XX wieku. Zasłynął z tworzenia szczegółowych zasad dotyczących efektywnej prezentacji danych statystycznych, które znalazły odzwierciedlenie w jego licznych publikacjach.</p> <p>Jego książka “The Visual Display of Quantitative Information”, jest kluczowym dziełem w tej dziedzinie, stanowiącym kanon dobrej praktyki wizualizacji danych. Tufte wprowadził tutaj takie pojęcia jak “lie factor” - czynnik kłamstwa, który mierzy stopień zniekształcenia danych prezentowanych na wykresie, czy “data-ink ratio” - stosunek “atramentu danych” do całkowitej ilości “atramentu” użytego do stworzenia wykresu.</p> <p>Kolejne z jego znanych dzieł, “Envisioning Information”, koncentruje się na różnorodnych sposobach prezentacji informacji, wykorzystując przykłady z tak różnych dziedzin jak kartografia, sztuka, projektowanie interfejsów, czy nauki przyrodnicze.</p> <p>Edward Tufte jest również znany z wprowadzenia koncepcji “sparklines” - małych, intensywnych, prostych, wykresów słupkowych, które pozwalają na skondensowane przedstawienie informacji. Wszystkie te idee i koncepcje przyczyniły się do kształtowania nowoczesnej wizualizacji danych, a wkład Tufta jest nieoceniony dla dzisiejszych projektantów i analityków danych.</p> <hr/> <h3 id="jacques-bertin-semiotyka-wizualizacji-danych">Jacques Bertin: Semiotyka wizualizacji danych</h3> <p>Jacques Bertin, wybitny francuski kartograf i teoretyk informacji, jest postacią niezwykle istotną dla dziedziny wizualizacji danych. Jego wkład polegał na stworzeniu semiologii graficznej, czyli nauki o znakach graficznych, ich strukturze i sposobie działania na odbiorcę.</p> <p>W swojej fundamentalnej książce “Semiology of Graphics”, opublikowanej po raz pierwszy w 1967 roku, Bertin przedstawił siedem fundamentalnych zmiennych wizualnych: położenie, kształt, kolor, orientację, wielkość, wartość i teksturę. Każda z tych zmiennych ma specyficzne właściwości i potrafi przekazywać określone informacje w sposób zrozumiały dla odbiorcy.</p> <p>Bertin zwracał uwagę na to, że wizualizacja danych musi być przemyślana i zrozumiała dla odbiorcy. Podkreślał, że skuteczność wizualizacji danych zależy od prawidłowego wyboru i zastosowania zmiennych wizualnych.</p> <p>Nauka Bertina dotycząca semiologii graficznej ma olbrzymie znaczenie dla dzisiejszych praktyk wizualizacji danych. Jego idee nadal inspirują i kształtują sposób, w jaki prezentujemy i interpretujemy informacje. “Semiology of Graphics” Jacques’a Bertina to absolutna klasyka w dziedzinie wizualizacji danych, która pomogła zdefiniować podstawy tej dyscypliny.</p> <hr/> <h2 id="początek-ery-komputerowej-wizualizacji-danych-koniec-lat-60-xx-wieku">Początek ery komputerowej wizualizacji danych (koniec lat 60. XX wieku)</h2> <p>Koniec lat 60. XX wieku to ważny moment w historii wizualizacji danych, który zapoczątkował erę komputerowej wizualizacji danych. To właśnie w tym czasie, dzięki gwałtownemu rozwojowi technologii informatycznej, zaczęto stosować komputery do tworzenia i interpretowania wizualizacji danych.</p> <p>Przełomem były innowacyjne programy takie jak Systat, SPSS i SAS. Te narzędzia, pierwotnie stworzone do analizy statystycznej, umożliwiły automatyczną wizualizację danych. Oferta tych narzędzi szybko się rozrastała, co umożliwiło tworzenie skomplikowanych wykresów i diagramów z dużych zbiorów danych w relatywnie krótkim czasie.</p> <p>Wraz z upowszechnieniem komputerów osobistych i rozwojem technologii graficznych, możliwości wizualizacji danych stały się praktycznie nieograniczone. Rozpoczął się proces tworzenia coraz to nowszych narzędzi do analizy i prezentacji danych, które umożliwiły wizualizację informacji na skalę niewyobrażalną wcześniej.</p> <p>Rozwój technologii komputerowych sprawił, że analiza i wizualizacja danych stała się szybsza, dokładniejsza i bardziej dostępna. To właśnie te lata dały początek nowoczesnej wizualizacji danych, której jesteśmy świadkami dzisiaj. Ewolucja narzędzi do wizualizacji danych, która rozpoczęła się w latach 60., jest nadal w toku, a możliwości jakie daje nam dzisiejsza technologia są niezwykle ekscytujące.</p> <hr/> <h3 id="ben-shneiderman-interaktywna-wizualizacji-danych">Ben Shneiderman: Interaktywna wizualizacji danych</h3> <p>Ben Shneiderman, wybitny amerykański informatyk i profesor na University of Maryland, jest uznawany za pioniera w dziedzinie interaktywnej wizualizacji danych. Jego prace wyznaczyły nowy kierunek w podejściu do prezentacji i interakcji z danymi.</p> <p>Shneiderman jest twórcą koncepcji “direct manipulation”, czyli bezpośredniej manipulacji, co zrewolucjonizowało sposób, w jaki użytkownicy komputerów współdziałają z interfejsami użytkownika. Podkreślał znaczenie interaktywności i angażowania użytkowników w proces analizy danych.</p> <p>Jego publikacja “The Eyes Have It: A Task by Data Type Taxonomy for Information Visualizations” jest fundamentalnym dziełem w tej dziedzinie. W tej pracy, Shneiderman wprowadził koncepcję “Mantra Wizualizacji”, składającą się z czterech zasad: “Przeglądaj pierwszy, zoom i filtruj, następnie szczegół na życzenie”. Ta koncepcja jest do dzisiaj stosowana w projektowaniu interaktywnych wizualizacji danych.</p> <p>Shneiderman miał ogromny wpływ na rozwój interaktywnych wizualizacji danych, a jego koncepcje nadal są stosowane w nowoczesnym projektowaniu UX/UI. Dzięki jego wkładowi, dzisiaj możemy korzystać z narzędzi, które umożliwiają łatwe i intuicyjne poruszanie się po skomplikowanych zestawach danych. Jego prace są nieocenionym źródłem wiedzy dla każdego, kto interesuje się wizualizacją danych.</p> <hr/> <h2 id="podsumowanie">Podsumowanie</h2> <p>Podsumowując, historia wizualizacji danych to niezwykle interesujące i dynamiczne pole, które od starożytności do współczesności przeszło przez wiele faz ewolucji. Od prostych reprezentacji w formie map i wykresów, przez innowacyjne prace Minarda, aż do wynalazku maszyn do przetwarzania danych przez Holleritha, wizualizacja danych zawsze była nieodzownym elementem nauki i biznesu.</p> <p>XX wiek to era ekspansji w dziedzinie wizualizacji danych, kiedy to tacy giganci jak Tukey, Tufte i Bertin zdefiniowali podstawy tej dziedziny. Z biegiem lat, z nadejściem komputerów, możliwości wizualizacji danych znacznie się poszerzyły, czemu przyczyniły się także prace Shneidermana.</p> <p>Obecnie, w dobie cyfryzacji i rosnącej ilości dostępnych danych, wizualizacja danych odgrywa kluczową rolę w wielu dziedzinach życia. Służy do przekazywania skomplikowanych informacji w przystępnej formie, pomaga w podejmowaniu decyzji i jest nieodzowna w świecie nauki, technologii i biznesu.</p> <p>Oczekuje się, że przyszłość przyniesie jeszcze więcej innowacji w dziedzinie wizualizacji danych, a jej znaczenie będzie dalej rosnąć. Jak pokazuje historia, potencjał tej dziedziny jest nieograniczony, a nasza zdolność do wykorzystania danych w celu zrozumienia świata wciąż się rozwija.</p> <hr/>]]></content><author><name></name></author><category term="article"/><category term="analiza-danych"/><category term="narzedzia"/><category term="historia"/><category term="wizualizacje"/><category term="visualization"/><category term="edukacja"/><summary type="html"><![CDATA[Artykuł, który skupia sie na historii wizualizacji danych]]></summary></entry><entry><title type="html">Wykorzystywanie AI w pisaniu artykułów</title><link href="https://szymok.github.io/blog/2023/ai-writing/" rel="alternate" type="text/html" title="Wykorzystywanie AI w pisaniu artykułów"/><published>2023-03-13T00:10:00+00:00</published><updated>2023-03-13T00:10:00+00:00</updated><id>https://szymok.github.io/blog/2023/ai-writing</id><content type="html" xml:base="https://szymok.github.io/blog/2023/ai-writing/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kaitlyn-baker-vZJdYl5JVXY-unsplash-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kaitlyn-baker-vZJdYl5JVXY-unsplash-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kaitlyn-baker-vZJdYl5JVXY-unsplash-1400.webp"/> <img src="/assets/img/kaitlyn-baker-vZJdYl5JVXY-unsplash.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Pisanie artykułów, które są napędzane przez AI, jest coraz bardziej popularne. </div> <h2 id="jak-wykorzystywać-ai-w-pisaniu-tekstów-i-artykułach">Jak wykorzystywać AI w pisaniu tekstów i artykułach?</h2> <p>AI, czyli sztuczna inteligencja, to dziedzina nauki i technologii, która zajmuje się tworzeniem maszyn i systemów zdolnych do wykonywania zadań wymagających ludzkiego intelektu. AI ma coraz większy wpływ na różne aspekty naszego życia, w tym na sposób pisania i czytania tekstów. W tym artykule przedstawię kilka sposobów, w jaki możemy wykorzystywać AI w pisaniu tekstów i artykułach oraz jakie są tego zalety i wady.</p> <p>Generatory tekstu są dostępne od lat, ale coś się zmieniło: w końcu stały się dobre. Tam, gdzie poprzednie iteracje wymagały ciężkiej edycji, najnowsza wersja Chat GPT od OpenAI używa lepszej gramatyki niż ja. Jednakże, mało w nim jest twórczej iskry. Wynika to z faktu, jak działa Chat GPT. Jego uczenie maszynowe opiera się na 570 GB tekstu z Wikipedii, internetu i książek. Przebrnięcie przez 300 miliardów słów nauczyło system jak zbudowane są zdania, ale nie procesu kreatywnego, który doprowadził do ich powstania.</p> <p>Podczas gdy modele AI mogą być trenowane na ogromnych ilościach danych i potrafią rozpoznawać wzorce oraz generować tekst, który jest spójny i konsekwentny stylowo, to nie potrafią w pełni zrozumieć głębszego znaczenia lub implikacji słów, których używają. AI nie jest zdolna do kreatywności w taki sam sposób, jak ludzie. Może generować tekst na podstawie wzorców, które widziała w danych, ale nie potrafi wymyślać nowych pomysłów lub perspektyw w sposób, w jaki może to zrobić człowiek pisarz. To może prowadzić do braku oryginalności i głębi w pisaniu.</p> <p>Mimo to, nauczyciele i wykładowcy są zaniepokojeni i coraz częściej można usłyszeć o zakazie używania Chat GPT przez swoją szkołę(głównie w Ameryce), a australijskie szkoły wracają do egzaminów papierowych i ołówkowych. Ale jak daleko mogą posunąć się w tym kierunku? Uczniowie od dawna są oceniani przez pryzmat swojego pisania na dobrze znanych tematach. Dyskusje o symbolice w Szekspirze już są dostępne w sieci, więc studenci mogą je otworzyć tak samo łatwo, jak Chat GPT. Łatwo jest kupić wstępnie napisane eseje, znaleźć przykładowe teksty do skopiowania lub w inny sposób uzyskać odpowiedzi z internetu - wpisz “tematy z książki xxx” w Google i gotowe.</p> <p>Jednakże, czytanie gotowców lub innych materiałów nie jest oszukiwaniem. Czytanie, myślenie, a potem pisanie tego własnymi słowami to prawdziwa praca. Dla niektórych uczniów pisanie własnymi słowami jest najtrudniejszą częścią. Ale jest mnóstwo algorytmów poza Google, które mogą pomóc w tym zadaniu. Sprawdzanie pisowni jest na wyższym poziomie niż kiedyś</p> <hr/> <h2 id="rodzaje-i-funkcje-ai-w-pisaniu">Rodzaje i funkcje AI w pisaniu</h2> <p>AI może nam pomóc w pisaniu na wiele sposobów, w zależności od celu i rodzaju tekstu, który chcemy stworzyć. Oto niektóre z najczęstszych funkcji AI w pisaniu:</p> <ul> <li> Generowanie tytułów: AI może zaproponować nam kilka tytułów do naszego tekstu, które będą pasować do tematu, treści i stylu pisania. Na przykład, jeśli chcemy napisać artykuł o AI w medycynie, AI może zaproponować nam takie tytuły jak: "AI ratuje życie: jak sztuczna inteligencja zmienia oblicze medycyny", "Jak AI pomaga lekarzom w diagnozowaniu i leczeniu chorób" lub "Przyszłość medycyny: jak AI wpływa na jakość i dostępność opieki zdrowotnej".</li> <li> Generowanie treści: AI może napisać za nas cały tekst lub jego część, bazując na podanych przez nas informacjach, instrukcjach lub pytaniach. Na przykład, jeśli chcemy napisać wprowadzenie do naszego artykułu o AI w medycynie, AI może wygenerować dla nas taką treść: "AI, czyli sztuczna inteligencja, to dziedzina nauki i technologii, która zajmuje się tworzeniem maszyn i systemów zdolnych do wykonywania zadań wymagających ludzkiego intelektu. AI ma coraz większy wpływ na różne aspekty naszego życia, w tym na sposób diagnozowania i leczenia chorób. W tym artykule przedstawię kilka przykładów zastosowań AI w medycynie oraz jakie są tego korzyści i zagrożenia dla pacjentów i lekarzy."</li> <li> Generowanie podsumowań: AI może podsumować dla nas główne punkty naszego tekstu lub tekstu źródłowego, który chcemy zacytować lub sparafrazować. Na przykład, jeśli chcemy podsumować artykuł o AI w edukacji, AI może wygenerować dla nas takie podsumowanie: "Artykuł przedstawia kilka sposobów wykorzystania AI w edukacji, takich jak personalizacja nauki, ocena postępów uczniów, wspomaganie nauczycieli i tworzenie interaktywnych materiałów dydaktycznych. Artykuł podkreśla również potencjalne korzyści i wyzwania związane z wprowadzaniem AI do szkolnictwa."</li> </ul> <hr/> <h2 id="przykłady-konkretnych-narzędzi-i-aplikacji-ai-do-pisania-które-są-dostępne-na-rynku-lub-w-fazie-rozwoju">Przykłady konkretnych narzędzi i aplikacji AI do pisania, które są dostępne na rynku lub w fazie rozwoju</h2> <p>Na rynku istnieje wiele narzędzi i aplikacji AI do pisania, które mają różne funkcje i cele. Oto niektóre z nich:</p> <ul> <li> <a href="https://inkforall.com/">INK for All</a>: to narzędzie łączy w sobie funkcje AI do pisania i SEO. Może pomóc w tworzeniu optymalnych tytułów, treści, słów kluczowych i meta opisów dla stron internetowych.</li> <li> <a href="https://www.copy.ai/">Copy.ai</a>: to narzędzie służy do generowania krótkich form treści, takich jak slogany, nagłówki, opisy produktów, posty na social media i wiele innych.</li> <li> <a href="https://chat.openai.com/">ChatGPT</a>: to narzędzie pozwala na prowadzenie konwersacji z AI na dowolny temat. Może być używane do testowania pomysłów, tworzenia dialogów, zabawy lub nauki.</li> <li> <a href="https://rytr.me/">Rytr</a>: to narzędzie jest przeznaczone do codziennego pisania. Może pomóc w tworzeniu treści na różne cele i style, takie jak blogi, e-maile, opowiadania, listy motywacyjne i wiele innych.</li> <li> <a href="https://www.grammarly.com/">Grammarly</a>: to narzędzie jest znane z korekty gramatyki i ortografii w tekście. Może też pomóc w poprawieniu stylu, tonu i klarowności tekstu oraz w wykrywaniu plagiatu.</li> <li> <a href="https://www.frase.io/">Frase</a>: to narzędzie jest przeznaczone do tworzenia długich form treści, takich jak artykuły, raporty, e-booki i wiele innych. Może pomóc w badaniu tematu, generowaniu struktury tekstu, tworzeniu treści i optymalizacji SEO.</li> <li> <a href="https://www.outranking.io/s">Outranking</a>: to narzędzie jest skierowane do przedsiębiorców, agencji i przedsiębiorstw. Może pomóc w tworzeniu wysokiej jakości treści marketingowych i sprzedażowych oraz w analizie konkurencji i wyników.</li> </ul> <hr/> <h2 id="zalety-i-wady-wykorzystywania-ai-do-pisania">Zalety i wady wykorzystywania AI do pisania</h2> <p>Zalety:</p> <ul> <li> Zwiększenie produktywności i skalowalności: narzędzia AI do pisania mogą pomóc w szybszym i łatwiejszym tworzeniu treści na różne cele i platformy.</li> <li> Zwiększenie kreatywności i jakości: narzędzia AI do pisania mogą pomóc w generowaniu pomysłów, struktur, tytułów, sloganów i innych elementów tekstu, które mogą zwiększyć jego atrakcyjność i zainteresowanie czytelnika.</li> <li> Zwiększenie zasięgu i dostępności: narzędzia AI do pisania mogą pomóc w tłumaczeniu, adaptacji i optymalizacji treści dla różnych języków, kultur i grup docelowych.</li> </ul> <p>Wady:</p> <ul> <li> Ryzyko dezinformacji i manipulacji: narzędzia AI do pisania mogą być wykorzystywane do masowego tworzenia fałszywych lub tendencyjnych informacji, które mogą wpływać na opinie publiczną, politykę i bezpieczeństwo.</li> <li> Utrata autentyczności i osobowości: narzędzia AI do pisania mogą sprawić, że treść będzie brzmiała sztucznie lub nieoryginalnie, co może obniżyć zaufanie i lojalność czytelnika.</li> <li> Naruszenie praw autorskich i etycznych: narzędzia AI do pisania mogą nieświadomie lub celowo kopiować lub plagiatować treści z innych źródeł, co może naruszać prawa własności intelektualnej lub moralne autorów.</li> </ul> <hr/> <h2 id="jak-sprawdzić-czy-dany-tekst-nie-został-wygenerowany-przez-ai">Jak sprawdzić, czy dany tekst nie został wygenerowany przez AI?</h2> <p>Sztuczna inteligencja (AI) jest zdolna do generowania tekstów na różne tematy i w różnych stylach. Niektóre z tych tekstów są tak przekonujące, że trudno je odróżnić od tekstów napisanych przez ludzi. Jednak nie wszystkie teksty wygenerowane przez AI są wiarygodne lub prawdziwe. Mogą one zawierać błędy, niespójności, fałszywe informacje lub manipulacje. Dlatego ważne jest, aby umieć wykrywać teksty napisane przez AI i oceniać ich jakość i wiarygodność. Jednym ze sposobów wykrywania tekstów napisanych przez AI jest analiza różnych cech tekstu, takich jak płynność, spójność, oryginalność czy poprawność językowa. Można do tego używać specjalnego oprogramowania, które porównuje tekst z bazą danych lub modelem językowym i ocenia jego prawdopodobieństwo lub zgodność. Na przykład, narzędzie GLTR podświetla słowa w tekście na różne kolory w zależności od tego, jak często występują one w danym kontekście. Jeśli tekst zawiera wiele rzadkich lub niepasujących słów, oznacza to, że jest on mniej naturalny i prawdopodobnie wygenerowany przez AI. Innym przykładem jest AI Classifier, który wskazuje, czy tekst został wygenerowany przez AI na podstawie tego, jak dobrze model GPT-3 przewiduje kolejne słowa w tekście. Jeśli tekst jest bardzo przewidywalny dla modelu, oznacza to, że jest on bardziej podobny do tekstu wygenerowanego przez AI Wykrywanie tekstów napisanych przez AI jest ważnym i trudnym zadaniem, które wymaga zarówno narzędzi komputerowych, jak i ludzkiego osądu. Nie ma jednego niezawodnego sposobu na odróżnienie tekstu wygenerowanego przez AI od tekstu napisanego przez człowieka, ponieważ AI może naśladować różne style i tematy. Niektóre teksty mogą być również zmodyfikowane lub zmieszane z tekstami ludzkimi, aby uniknąć wykrycia. Dlatego należy być krytycznym i ostrożnym podczas czytania i oceniania tekstów, zwłaszcza tych pochodzących z nieznanych lub niezaufanych źródeł. Wykrywanie tekstów napisanych przez AI ma również znaczenie społeczne i etyczne, ponieważ dotyczy kwestii prawdy, wiarygodności i odpowiedzialności w komunikacji i informacji.</p> <hr/> <p>Podsumowując, AI w pisaniu jest potężnym i obiecującym narzędziem, które ma wiele zalet i wad. Pytanie czy i jak wykorzystać AI w pisaniu w sposób odpowiedzialny i etyczny? Na pewno potrzebne są jasne i spójne wytyczne, standardy i regulacje dotyczące stosowania AI w pisaniu, które będą chronić prawa i interesy zarówno twórców, jak i odbiorców treści. Dalsze kierunki badań lub zastosowań AI w pisaniu mogą obejmować:</p> <ul> <li> Badanie wpływu AI na jakość i styl pisania oraz na postrzeganie i ocenę treści przez czytelników.</li> <li> Badanie możliwości i ograniczeń AI w tworzeniu różnych rodzajów treści, takich jak literatura, dziennikarstwo, marketing, edukacja i inne.</li> <li> Badanie sposobów poprawy współpracy i interakcji między ludźmi a AI w procesie pisania oraz roli ludzkiej kreatywności i kontroli nad treścią.</li> <li> Badanie sposobów wykorzystania AI do promowania różnorodności, inkluzywności i sprawiedliwości w treściach oraz do zwalczania uprzedzeń, stereotypów i dyskryminacji.</li> </ul>]]></content><author><name></name></author><category term="article"/><category term="sztuczna-inteligencja"/><category term="generowanie-tekstu"/><category term="technologie-jezykowe"/><category term="przyszłosc-mediow"/><category term="etyka-regulacje"/><summary type="html"><![CDATA[Artykuł przedstawia zalety i wady wykorzystywania sztucznej inteligencji (AI) w pisaniu artykułów]]></summary></entry><entry><title type="html">Procesory - trendy AI 2023</title><link href="https://szymok.github.io/blog/2023/ai-trends/" rel="alternate" type="text/html" title="Procesory - trendy AI 2023"/><published>2023-03-06T11:59:00+00:00</published><updated>2023-03-06T11:59:00+00:00</updated><id>https://szymok.github.io/blog/2023/ai-trends</id><content type="html" xml:base="https://szymok.github.io/blog/2023/ai-trends/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/ai-trends-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/ai-trends-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/ai-trends-1400.webp"/> <img src="/assets/img/ai-trends.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Przyszłość AI wydaje się być bardzo obiecująca, ale jak wygląda to w praktyce? </div> <p>W 2022 roku obserwowano wzrost popularności zastosowań sztucznej inteligencji wśród konsumentów, takich jak AI art, i ChatGPT. Jednakże, kupowanie nowych laptopów od AMD i Intela z wbudowanymi funkcjami AI nie jest jeszcze opłacalne. Z uwagi na gwałtowny rozwój AI, taki zakup może okazać się bardziej opłacalny w przyszłości, być może już na przyszłorocznym CES.</p> <hr/> <p>AMD wprowadza nową architekturę sprzętową AI o nazwie XDNA w ramach serii Ryzen Mobile 7040 Series jako “Ryzen AI”. Podobne plany ma również Intel, choć na razie używa dyskretnej karty Movidius AI jako zastępczej. Qualcomm oferuje technologię AI jako część swoich opartych na Arm Snapdragon od lat.</p> <hr/> <p>Jedynym powodem, aby kupić komputer z wbudowaną sztuczną inteligencją w tej chwili, jest zbiór technologii kamer internetowych wbudowanych w wyposażonym w Snapdragon Microsoft Surface Pro 9 5G, tzw. Windows Studio Effects. Jest to zbiór funkcji wykorzystujących sztuczną inteligencję w pewnym stopniu, takich jak zintegrowane rozmycie tła, filtrowanie szumów, Eye Contact oraz automatyczne kadrowanie.</p> <hr/> <p>Jednakże, AI wciąż się rozwija na wielu różnych frontach i istnieją pytania dotyczące przyszłych zastosowań i usług AI. Chatboty napędzane przez AI, takie jak ChatGPT, mogą zastąpić lub uzupełnić wyszukiwarki takie jak Bing. Firmy ciężko pracują nad sprzętem do serwerów AI i modelami uczenia się przez ostatnie lata, a owoce tej pracy są zbierane teraz.</p> <hr/> <p>Można powiedzieć, że rok 2022 był rokiem, w którym AI zaczęła pojawiać się w świadomości społecznej. W 2023 roku, prawdopodobnie zaczniemy obserwować rozwój usług AI, jakie będą opłacalne, czego będziemy używać, i czego społeczeństwo będzie wymagać w przyszłości. Oprogramowanie takie jak Stable Diffusion i inne frameworki AI zostaną przekodowane dla Ryzen AI i Movidius, i będziemy mieli lepsze zrozumienie tego, jak XDNA porównuje się do RDNA pod względem tego, co może osiągnąć.</p> <hr/> <p>AMD poinformowało, że jego architektura XDNA została zaprojektowana z wykorzystaniem FPGA (Field Programmable Gate Array), które zostały uzyskane dzięki przejęciu firmy Xilinx. Technologia ta pozwala na szybką rekonfigurację sprzętu i jest sensowna, gdy technologia nie jest w pełni zrozumiała i wymaga poprawek. Kolejne rewizje chipów w latach 2024 i 2025 prawdopodobnie zintegrują AI jeszcze bardziej w nasze życie komputerowe, zwiększając ilość dedykowanej logiki. Możemy nawet użyć AI do “trenowania” cyfrowych modeli nas samych, tak aby stały się one pełnomocnikami AI, np. umawiając wizyty u dentysty, zgodnie z naszym kalendarzem i kontaktami. Ludzie są także zainteresowani metawersem, ale zawsze trudno przewidzieć, jakie nowości pojawią się w przyszłości. Nie zaleca się spieszyć z zakupem nowych procesorów PC napędzanych przez AI i poczekać na ich rozwój. Jednak jestem przekonany, że AI będzie częścią przyszłości naszych komputerów PC, kiedy ta przyszłość nadejdzie.</p>]]></content><author><name></name></author><category term="ai-news"/><category term="sztuczna-inteligencja"/><category term="narzedzia"/><category term="internet-immersywny"/><category term="metawers"/><category term="robotyka"/><category term="edukacja"/><category term="reshoring"/><category term="cyfryzacja"/><summary type="html"><![CDATA[artykul o trendach AI]]></summary></entry></feed>